{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../ancillarydata/logos/LundUniversity_C2line_RGB.png\" width=\"150\" align=\"left\"/>\n",
    "<br>\n",
    "<img src=\"../ancillarydata/logos/Icos_Logo_CMYK_Regular_SMpng.png\" width=\"327\" align=\"right\"/>\n",
    "<br>\n",
    "<a id='introduction'></a>\n",
    "<a id='modules'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# <font color=#B98F57>PhD course</font>\n",
    "### <font color=#000083>From CO$_2$ in situ measurements to carbon balance maps as a tool to support national carbon accounting</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Organized by:** Lund University dept. of Physical Geography & Ecosystem Science and ICOS ERIC <br>\n",
    "**Funded by:**    Lund University dept. of Physical Geography & Ecosystem Science, ICOS ERIC and ClimBEco <br>\n",
    "**Course dates:** March 9th 2020 - March 13th 2020 <br>\n",
    "**Location:** Lund, Sweden\n",
    "\n",
    "**Notebook developed by:** Karolina Pantazatou, Ute Karstens & Claudio D' Onofrio\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook including Python Functions for ClimBEco course\n",
    "This notebook includes ready functions or code snippets for reading, processing and plotting data related to the 2020 ClimBEco course.\n",
    "\n",
    "The notebook is divided in different sections:\n",
    "\n",
    "- [Python Modules](#modules)\n",
    "- [FLUXNET data](#fluxnet)\n",
    "- [LPJ-GUESS (Paul's dataset)](#lpjguess_paul)\n",
    "- [LPJ-GUESS map data](#lpjguess_map)\n",
    "- [LUMIA data](#lumia)\n",
    "- [EDAGR data](#edgar)\n",
    "- [Extract Timeseries from map](#tsmaps)\n",
    "- [Country Masks](#masks)\n",
    "- [Station class](#stclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines){\n",
    "    return false;}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python modules\n",
    "List the Python modules used for the functions and/or code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import netCDF4 as cdf\n",
    "from datetime import datetime, timedelta\n",
    "from ipywidgets import Dropdown, Button, HBox, VBox, Output, RadioButtons, Checkbox, FloatText, interact_manual\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "#Import plotting modules from cartopy:\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.feature import NaturalEarthFeature, LAND, COASTLINE, LAKES\n",
    "\n",
    "#Import plotting modules from matplotlib:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "\n",
    "#Import Bokeh modules:\n",
    "from bokeh.models import Plot, LinearAxis, Grid, BasicTicker, HoverTool, ColorBar, ColumnDataSource, Label, Legend, GeoJSONDataSource\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column\n",
    "import bokeh.io\n",
    "from bokeh.io import show, output_notebook, reset_output, push_notebook\n",
    "\n",
    "#Turn off warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Set the notebook as the default output location:\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_home = '/data/project/'\n",
    "path_climbeco = personal_home+'/climbeco/data/'\n",
    "path_fluxnet_dd = path_climbeco+\"/fluxnet/obs_dd/\"\n",
    "path_fluxnet_hh = path_climbeco+\"/fluxnet/obs_hh/\"\n",
    "path_masks = path_climbeco+'masks/'\n",
    "path_lumia = path_climbeco+'lumia/'\n",
    "path_lpjmaps = path_climbeco+'lpjguess_maps/'\n",
    "path_edgar = path_climbeco+'edgar/'\n",
    "path_lpj = path_climbeco + 'lpjguess/lpj_clipped_2015_2018/'\n",
    "path_lpj_conif = path_lpj +'Conif_output/'\n",
    "path_lpj_decid = path_lpj +'Decid_output/'\n",
    "path_lpj_grass_wet_crop = path_lpj + 'Grasswetcrop_output/'\n",
    "path_lpj_pnv = path_lpj + 'PNV_output_allsites/'\n",
    "path_geo_data = path_climbeco + 'geo_data/'\n",
    "path_geo_natural_earth10m = path_geo_data + 'ne_10m_admin_0_countries/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><a href=\"#introduction\">Back to top</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fluxnet'></a>\n",
    "\n",
    "## FLUXNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries \n",
    "\n",
    "This part includes the dictionaries created for:\n",
    "\n",
    "- climbeco stations \n",
    "    - There are 18 stations in total\n",
    "    - The dictionary includes summarized info per station (i.e. station name, country, country code, station type, latitude, longitude). \n",
    "    - The keys of the dictionary are the station code (3-character string).\n",
    "\n",
    "\n",
    "- FLUXNET variables (daily values dataset)\n",
    "    - The keys are the FLUXNET variable codes, included as column-names in the FLUXNET dataset.\n",
    "    - The dictionary values include the description of the variable code and the variable unit.\n",
    "\n",
    "\n",
    "- FLUXNET variables (half-hourly values dataset)\n",
    "    - The keys are the FLUXNET variable codes, included as column-names in the FLUXNET dataset.\n",
    "    - The dictionary values include the description of the variable code and the variable unit.\n",
    "    \n",
    "    \n",
    "<font color='red'>There might be differences in the types of variables or variable units between the FLUXNET half-hourly dataset and the FLUXNET daily-values dataset.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary for stations:\n",
    "#Every station code is connected to a list, incl.\n",
    "#station name, country, country code, station type, latitude, longitude, url\n",
    "#lpj-guess latitude, lpj-guess longitude.\n",
    "stations_dict = {\"Sor\":[\"Soroe\", \"Denmark\", \"DK\",\"Deciduous forest\", 55.48587, 11.64464,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=DK-Sor\",\n",
    "                        55.25, 11.75],\n",
    "                 \"Let\":[\"Lettosuo\", \"Finland\", \"FI\", \"Peatland\", 60.64183, 23.95952,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=FI-Let\",\n",
    "                        60.75, 23.75],\n",
    "                 \"Sii\":[\"Siikaneva\", \"Finland\", \"FI\", \"Fen\", 61.83265, 24.19285,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=FI-Sii\",\n",
    "                        61.75, 24.25],\n",
    "                 \"Akm\":[\"Anklam\", \"Germany\", \"DE\", \"Wetland\", 53.86617, 13.68342,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=DE-Akm\",\n",
    "                        53.75, 13.75],\n",
    "                 \"Geb\":[\"Gebesee\", \"Germany\", \"DE\", \"Cropland\", 51.09974, 10.91462,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=DE-Geb\",\n",
    "                        51.25, 10.75],\n",
    "                 \"Gri\":[\"Grillenburg\", \"Germany\", \"DE\", \"Grassland\", 50.95004, 13.51259,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=DE-Gri\",\n",
    "                        50.75, 13.75],\n",
    "                 \"Hai\":[\"Hainich\", \"Germany\", \"DE\", \"Deciduous forest\", 51.07921, 10.45216,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=DE-Hai\",\n",
    "                        51.25, 10.25],\n",
    "                 \"HoH\":[\"Hohes Holz\", \"Germany\", \"DE\", \"Deciduous forest\", 52.08656, 11.22235,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=DE-HoH\",\n",
    "                        52.25, 11.25],\n",
    "                 \"Hte\":[\"Huetelmoor\", \"Germany\", \"DE\", \"Wetland\", 54.210278, 12.176111,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=DE-Hte\",\n",
    "                        54.25, 12.25],\n",
    "                 \"RuR\":[\"Rollesbroich\", \"Germany\", \"DE\", \"Grassland\", 50.6219142, 6.3041256,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=DE-RuR\",\n",
    "                        50.75, 6.25],\n",
    "                 \"RuS\":[\"Selhausen Juelich\", \"Germany\", \"DE\", \"Cropland\", 50.86589, 6.44712,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=DE-RuS\",\n",
    "                        50.75, 6.25],\n",
    "                 \"Loo\":[\"Loobos\", \"Netherlands\", \"NL\", \"Coniferous forest\", 52.16648, 5.74355,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=NL-Loo\",\n",
    "                        52.25, 5.75],\n",
    "                 \"Deg\":[\"Degero\", \"Sweden\", \"SE\", \"Wetland\", 64.18203, 19.55654,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=SE-Deg\",\n",
    "                        64.25, 19.75],\n",
    "                 \"Htm\":[\"Hyltemossa\", \"Sweden\", \"SE\", \"Coniferous forest\", 56.09763, 13.41897,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=SE-Htm\",\n",
    "                        56.25, 13.25],\n",
    "                 \"Lnn\":[\"Lanna\", \"Sweden\", \"SE\", \"Cropland\", 58.34063, 13.10177,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=SE-Lnn\",\n",
    "                        58.25, 13.25],\n",
    "                 \"Nor\":[\"Norunda\", \"Sweden\", \"SE\", \"Coniferous forest\", 60.08644, 17.47946,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=SE-Nor\",\n",
    "                        60.25, 17.25],\n",
    "                 \"Ros\":[\"Rosinedal\", \"Sweden\", \"SE\", \"Coniferous forest\", 64.1725, 19.738,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=SE-Ros\",\n",
    "                        64.25, 19.75],\n",
    "                 \"Svb\":[\"Svartberget\", \"Sweden\", \"SE\", \"Coniferous forest\", 64.25609, 19.77457,\n",
    "                        \"http://www.europe-fluxdata.eu/home/site-details?id=SE-Svb\",\n",
    "                        64.25, 19.75]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variable dictionary for daily values:\n",
    "variables_dd_dict = {\"TA_F\":[\"Air temperature\", \"deg C\"],\n",
    "                     \"TA_F_NIGHT\":[\"Average air temperature (nighttime)\", \"deg C\"],\n",
    "                     \"TA_F_DAY\":[\"Average air temperature (daytime)\", \"deg C\"],\n",
    "                     \"SW_IN_F\":[\"Shortwave incoming radiation\", \"W m-2\"],\n",
    "                     \"LW_IN_JSB_F\":[\"Longwave incoming radiation\", \"W m-2\"],\n",
    "                     \"VPD_F\":[\"Vapor Pressure Deficit\", \"hPa\"],\n",
    "                     \"PA_F\":[\"Atmospheric pressure\", \"kPa\"],\n",
    "                     \"P_F\":[\"Precipitation\", \"mm\"],\n",
    "                     \"P_F_QC\":[\"Precipitation quality flag\", \"adimensional\",\n",
    "                               \"fraction between 0-1, indicating percentage of measured data\"],\n",
    "                     \"WS_F\":[\"Wind speed\", \"m s-1\"],\n",
    "                     \"CO2_F_MDS\":[\"CO2 mole fraction, gap-filled with MDS\", \"umolCO2 mol-1\"],\n",
    "                     \"TS_F_MDS_1\":[\"Soil temperature (index=1)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_2\":[\"Soil temperature (index=2)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_3\":[\"Soil temperature (index=3)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_4\":[\"Soil temperature (index=4)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_5\":[\"Soil temperature (index=5)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_6\":[\"Soil temperature (index=6)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_7\":[\"Soil temperature (index=7)\", \"deg C\"],\n",
    "                     \"SWC_F_MDS_1\":[\"Soil water content (index=1)\", \"%\"],\n",
    "                     \"SWC_F_MDS_2\":[\"Soil water content (index=2)\", \"%\"],\n",
    "                     \"SWC_F_MDS_3\":[\"Soil water content (index=3)\", \"%\"],\n",
    "                     \"SWC_F_MDS_4\":[\"Soil water content (index=4)\", \"%\"],\n",
    "                     \"SWC_F_MDS_5\":[\"Soil water content (index=5)\", \"%\"],\n",
    "                     \"SWC_F_MDS_6\":[\"Soil water content (index=6)\", \"%\"],\n",
    "                     \"SWC_F_MDS_7\":[\"Soil water content (index=7)\", \"%\"],\n",
    "                     \"SWC_F_MDS_1_QC\":[\"Soil water content quality flag (index=1)\", \"adimensional\",\n",
    "                                       \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"],\n",
    "                     \"SWC_F_MDS_2_QC\":[\"Soil water content quality flag (index=2)\", \"adimensional\",\n",
    "                                       \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"],\n",
    "                     \"SWC_F_MDS_3_QC\":[\"Soil water content quality flag (index=3)\", \"adimensional\",\n",
    "                                       \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"],\n",
    "                     \"SWC_F_MDS_4_QC\":[\"Soil water content quality flag (index=4)\", \"adimensional\",\n",
    "                                       \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"],\n",
    "                     \"SWC_F_MDS_5_QC\":[\"Soil water content quality flag (index=5)\", \"adimensional\",\n",
    "                                       \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"],\n",
    "                     \"SWC_F_MDS_6_QC\":[\"Soil water content quality flag (index=6)\", \"adimensional\",\n",
    "                                       \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"],\n",
    "                     \"SWC_F_MDS_7_QC\":[\"Soil water content quality flag (index=7)\", \"adimensional\",\n",
    "                                       \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"],\n",
    "                     \"G_F_MDS\":[\"Soil heat flux\", \"W m-2\"],\n",
    "                     \"LE_CORR\":[\"Latent heat flux\", \"W m-2\"],\n",
    "                     \"LE_CORR_JOINTUNC\":[\"Joint uncertainty estimation for latent heat flux\", \"W m-2\"],\n",
    "                     \"H_CORR\":[\"Sensible heat flux\", \"W m-2\"],\n",
    "                     \"H_CORR_JOINTUNC\":[\"Joint uncertainty estimation for sensible heat flux\", \"W m-2\"],\n",
    "                     \"NIGHT_RANDUNC_N\":[\"Number of half hours classified as nighttime\", \"adimensional\", \n",
    "                                        \"number of half-hours\"],\n",
    "                     \"DAY_RANDUNC_N\":[\"Number of half hours classified as daytime\", \"adimensional\",\n",
    "                                      \"number of half-hours\"],\n",
    "                     \"GPP_DT_VUT_MEAN\":[\"Gross Primary Production (daytime)\", \"gC m-2 d-1\"],\n",
    "                     \"GPP_DT_VUT_SE\":[\"Standard Error for Gross Primary Production (daytime)\", \"gC m-2 d-1\"],\n",
    "                     \"GPP_NT_VUT_MEAN\":[\"Gross Primary Production (nighttime)\", \"gC m-2 d-1\"],\n",
    "                     \"GPP_NT_VUT_SE\":[\"Standard Error for Gross Primary Production (nighttime)\", \"gC m-2 d-1\"],\n",
    "                     \"RECO_DT_VUT_MEAN\":[\"Ecosystem Respiration (daytime)\", \"gC m-2 d-1\"],\n",
    "                     \"RECO_DT_VUT_SE\":[\"Standard Error for Ecosystem Respiration (daytime)\", \"gC m-2 d-1\"],\n",
    "                     \"RECO_NT_VUT_MEAN\":[\"Ecosystem Respiration (nighttime)\", \"gC m-2 d-1\"],\n",
    "                     \"RECO_NT_VUT_SE\":[\"Standard Error for Ecosystem Respiration (nighttime)\", \"gC m-2 d-1\"],\n",
    "                     \"NEE_VUT_USTAR50\":[\"Net Ecosystem Exchange (USTAR50)\", \"gC m-2 d-1\"],\n",
    "                     \"NEE_VUT_USTAR50_QC\":[\"Quality flag for Net Ecosystem Exchange (USTAR50)\", \"adimensional\",\n",
    "                                           \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"],\n",
    "                     \"NEE_VUT_MEAN\":[\"Net Ecosystem Exchange (VUT MEAN)\", \"gC m-2 d-1\"],\n",
    "                     \"NEE_VUT_MEAN_QC\":[\"Quality flag for Net Ecosystem Exchange (VUT MEAN)\", \"adimensional\",\n",
    "                                        \"average of 40 NEE_VUT_XX_QC for the period\"],\n",
    "                     \"NEE_VUT_SE\":[\"Standard Error for Net Ecosystem Exchange (VUT MEAN)\", \"gC m-2 d-1\"],\n",
    "                     \"NEE_VUT_REF_NIGHT\":[\"Average Net Ecosystem Exchange (nighttime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"NEE_VUT_REF_NIGHT_SD\":[\"Standard Deviation for Net Ecosystem Exchange (nighttime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"NEE_VUT_REF_NIGHT_QC\":[\"Quality flag for Net Ecosystem Exchange (nighttime)\", \"adimensional\",\n",
    "                                             \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"],\n",
    "                     \"NEE_VUT_REF_DAY\":[\"Average Net Ecosystem Exchange (daytime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"NEE_VUT_REF_DAY_SD\":[\"Standard Deviation for Net Ecosystem Exchange (daytime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"NEE_VUT_REF_DAY_QC\":[\"Quality flag for Net Ecosystem Exchange (daytime)\", \"adimensional\",\n",
    "                                           \"fraction between 0-1, indicating percentage of measured and good quality gapfill data\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variable dictionary for half-hourly values:\n",
    "variables_hh_dict = {\"TA_F\":[\"Air temperature\", \"deg C\"],\n",
    "                     \"SW_IN_F\":[\"Shortwave incoming radiation\", \"W m-2\"],\n",
    "                     \"LW_IN_JSB_F\":[\"Longwave incoming radiation\", \"W m-2\"],\n",
    "                     \"VPD_F\":[\"Vapor Pressure Deficit\", \"hPa\"],\n",
    "                     \"PA_F\":[\"Atmospheric pressure\", \"kPa\"],\n",
    "                     \"P_F\":[\"Precipitation\", \"mm\"],\n",
    "                     \"P_F_QC\":[\"Precipitation quality flag\", \"adimensional\",\n",
    "                               \"0 = measured; 2 = downscaled from ERA\"],\n",
    "                     \"WS_F\":[\"Wind speed\", \"m s-1\"],\n",
    "                     \"CO2_F_MDS\":[\"CO2 mole fraction, gap-filled with MDS\", \"umolCO2 mol-1\"],\n",
    "                     \"TS_F_MDS_1\":[\"Soil temperature (index=1)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_2\":[\"Soil temperature (index=2)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_3\":[\"Soil temperature (index=3)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_4\":[\"Soil temperature (index=4)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_5\":[\"Soil temperature (index=5)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_6\":[\"Soil temperature (index=6)\", \"deg C\"],\n",
    "                     \"TS_F_MDS_7\":[\"Soil temperature (index=7)\", \"deg C\"],\n",
    "                     \"SWC_F_MDS_1\":[\"Soil water content (index=1)\", \"%\"],\n",
    "                     \"SWC_F_MDS_2\":[\"Soil water content (index=2)\", \"%\"],\n",
    "                     \"SWC_F_MDS_3\":[\"Soil water content (index=3)\", \"%\"],\n",
    "                     \"SWC_F_MDS_4\":[\"Soil water content (index=4)\", \"%\"],\n",
    "                     \"SWC_F_MDS_5\":[\"Soil water content (index=5)\", \"%\"],\n",
    "                     \"SWC_F_MDS_6\":[\"Soil water content (index=6)\", \"%\"],\n",
    "                     \"SWC_F_MDS_7\":[\"Soil water content (index=7)\", \"%\"],\n",
    "                     \"SWC_F_MDS_1_QC\":[\"Soil water content quality flag (index=1)\", \"adimensional\",\n",
    "                                       \"0 = measured; 1 = good quality gapfill; 2 = medium; 3 = poor\"],\n",
    "                     \"SWC_F_MDS_2_QC\":[\"Soil water content quality flag (index=2)\", \"adimensional\",\n",
    "                                       \"0 = measured; 1 = good quality gapfill; 2 = medium; 3 = poor\"],\n",
    "                     \"SWC_F_MDS_3_QC\":[\"Soil water content quality flag (index=3)\", \"adimensional\",\n",
    "                                       \"0 = measured; 1 = good quality gapfill; 2 = medium; 3 = poor\"],\n",
    "                     \"SWC_F_MDS_4_QC\":[\"Soil water content quality flag (index=4)\", \"adimensional\",\n",
    "                                       \"0 = measured; 1 = good quality gapfill; 2 = medium; 3 = poor\"],\n",
    "                     \"SWC_F_MDS_5_QC\":[\"Soil water content quality flag (index=5)\", \"adimensional\",\n",
    "                                       \"0 = measured; 1 = good quality gapfill; 2 = medium; 3 = poor\"],\n",
    "                     \"SWC_F_MDS_6_QC\":[\"Soil water content quality flag (index=6)\", \"adimensional\",\n",
    "                                       \"0 = measured; 1 = good quality gapfill; 2 = medium; 3 = poor\"],\n",
    "                     \"SWC_F_MDS_7_QC\":[\"Soil water content quality flag (index=7)\", \"adimensional\",\n",
    "                                       \"0 = measured; 1 = good quality gapfill; 2 = medium; 3 = poor\"],\n",
    "                     \"G_F_MDS\":[\"Soil heat flux\", \"W m-2\"],\n",
    "                     \"LE_CORR\":[\"Latent heat flux\", \"W m-2\"],\n",
    "                     \"LE_CORR_JOINTUNC\":[\"Joint uncertainty estimation for latent heat flux\", \"W m-2\"],\n",
    "                     \"H_CORR\":[\"Sensible heat flux\", \"W m-2\"],\n",
    "                     \"H_CORR_JOINTUNC\":[\"Joint uncertainty estimation for sensible heat flux\", \"W m-2\"],\n",
    "                     \"GPP_DT_VUT_MEAN\":[\"Gross Primary Production (daytime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"GPP_DT_VUT_SE\":[\"Standard Error for Gross Primary Production (daytime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"GPP_NT_VUT_MEAN\":[\"Gross Primary Production (nighttime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"GPP_NT_VUT_SE\":[\"Standard Error for Gross Primary Production (nighttime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"RECO_DT_VUT_MEAN\":[\"Ecosystem Respiration (daytime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"RECO_DT_VUT_SE\":[\"Standard Error for Ecosystem Respiration (daytime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"RECO_NT_VUT_MEAN\":[\"Ecosystem Respiration (nighttime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"RECO_NT_VUT_SE\":[\"Standard Error for Ecosystem Respiration (nighttime)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"NEE_VUT_USTAR50\":[\"Net Ecosystem Exchange (USTAR50)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"NEE_VUT_USTAR50_QC\":[\"Quality flag for Net Ecosystem Exchange (USTAR50)\", \"adimensional\",\n",
    "                                           \"0 = measured; 1 = good quality gapfill; 2 = medium; 3 = poor\"],\n",
    "                     \"NEE_VUT_MEAN\":[\"Net Ecosystem Exchange (VUT MEAN)\", \"umolCO2 m-2 s-1\"],\n",
    "                     \"NEE_VUT_MEAN_QC\":[\"Quality flag for Net Ecosystem Exchange (VUT MEAN)\", \"adimensional\",\n",
    "                                        \"average of percentages of good data (NEE_VUT_XX_QC is 0 or 1) from 40 NEE_VUT_XX_QC\"],\n",
    "                     \"NEE_VUT_SE\":[\"Standard Error for Net Ecosystem Exchange (VUT MEAN)\", \"umolCO2 m-2 s-1\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpj_var_dict = {'gpp':'dgpp.out',\n",
    "                'npp':'dnpp.out',\n",
    "                'nee':'dnee.out',\n",
    "                'rtot':'drtot.out',\n",
    "                'prec':'dprec.out',\n",
    "                'swrad':'dswrad.out',\n",
    "                'temp':'dtemp.out'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpj_veg_type_dict = {'coniferous':path_lpj_conif,\n",
    "                     'conif':path_lpj_conif,\n",
    "                     'deciduous':path_lpj_decid,\n",
    "                     'decid':path_lpj_decid,\n",
    "                     'pnv':path_lpj_pnv,\n",
    "                     'grass_wet_crop':path_lpj_grass_wet_crop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary to assign variable to FLUXNET variable name:\n",
    "fluxnet_dict = {'NEE':'NEE_VUT_MEAN',\n",
    "                'GPP':'GPP_DT_VUT_MEAN',\n",
    "                'RTOT':'RECO_DT_VUT_MEAN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary to assign station vegetation type to lpj output directory:\n",
    "veg_type_to_lpjpath_dict = {'Coniferous forest':'conif',\n",
    "                            'Cropland':'grass_wet_crop',\n",
    "                            'Deciduous forest':'decid',\n",
    "                            'Fen':'grass_wet_crop',\n",
    "                            'Grassland':'grass_wet_crop',\n",
    "                            'Peatland':'grass_wet_crop',\n",
    "                            'Wetland':'grass_wet_crop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to read FLUXNET-file with half-hourly values:\n",
    "def read_fluxnet_hh(path, st_code):\n",
    "      \n",
    "    #Define file name:\n",
    "    file = \"FLX_\"+stations_dict[st_code][2]+\"-\"+st_code+\"_HH_2015_2018.csv\"\n",
    "    \n",
    "    #Create full path to file:\n",
    "    fullpath = path + file\n",
    "    \n",
    "    #Read csv to pandas dataframe:\n",
    "    df = pd.read_csv(fullpath,\n",
    "                     header = 0,\n",
    "                     sep = \",\",\n",
    "                     parse_dates = [\"TIMESTAMP_START\", \"TIMESTAMP_END\"])\n",
    "\n",
    "    #Return dataframe:\n",
    "    return df.loc[df.NEE_VUT_MEAN_QC>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to read FLUXNET-file with daily values:\n",
    "def read_fluxnet_dd(path, st_code):\n",
    "      \n",
    "    #Define file name:\n",
    "    file = \"FLX_\"+stations_dict[st_code][2]+\"-\"+st_code+\"_DD_2015_2018.csv\"\n",
    "    \n",
    "    #Create full path to file:\n",
    "    fullpath = path + file\n",
    "    \n",
    "    #Read csv to pandas dataframe:\n",
    "    df = pd.read_csv(fullpath,\n",
    "                     header = 0,\n",
    "                     sep = \",\",\n",
    "                     parse_dates = [\"TIMESTAMP\"])\n",
    "\n",
    "    #Return dataframe:\n",
    "    return df.loc[df.NEE_VUT_MEAN_QC>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmap_climbeco(stations_df, selected_station):\n",
    "    \n",
    "    \"\"\"\n",
    "    Project:         'ICOS Carbon Portal'\n",
    "    Created:          Tue Feb 04 10:40:00 2020\n",
    "    Last Changed:     Tue Feb 04 10:40:00 2020\n",
    "    Version:          1.0.0\n",
    "    Author(s):        Karolina\n",
    "    \n",
    "    Description:      Function that takes a dataframe containing info about ICOS Stations and the 3-character\n",
    "                      station code of a selected station as input and returns an interactive Folium Map, with\n",
    "                      the location of the selected station highlighted in red. \n",
    "                      Folium (URL): https://python-visualization.github.io/folium/quickstart.html\n",
    "                      \n",
    "    Input parameters: 1. Dataframe with Information regarding ICOS Stations\n",
    "                         (var_name: 'stations_df', var_type: Pandas Dataframe)\n",
    "                      2. Station 3-character Code\n",
    "                         (var_name: 'selected_station', var_type: String)\n",
    "\n",
    "    Output:           Folium Map (Folium Map Object)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Import modules:\n",
    "    import folium\n",
    "\n",
    "    #Create folium map-object:\n",
    "    m = folium.Map(\n",
    "        location=[60.07921, 9.0000],\n",
    "        zoom_start=4)\n",
    "\n",
    "    #Add marker-tooltip:\n",
    "    tooltip = 'Click to view station info'\n",
    "\n",
    "    def add_marker(map_obj, station_code, marker_color):\n",
    "\n",
    "        #Add popup text:\n",
    "        popup=folium.Popup('Name: <b>'+stations_df.name.loc[stations_df.index==station_code].values[0]+'</b><br>'+\n",
    "                           'Code: <b>'+station_code+'</b><br>'+\n",
    "                           'Country: <b>'+stations_df.country.loc[stations_df.index==station_code].values[0]+'</b><br>'+\n",
    "                           'Country code: <b>'+stations_df.country_code.loc[stations_df.index==station_code].values[0]+'</b><br>'+\n",
    "                           'Vegetation: <b>'+stations_df.vegetation.loc[stations_df.index==station_code].values[0]+'</b><br>'+\n",
    "                           'Latitude: <b>'+str(stations_df.lat.loc[stations_df.index==station_code].values[0])+'</b><br>'+\n",
    "                           'Longitude: <b>'+str(stations_df.lon.loc[stations_df.index==station_code].values[0])+'</b><br>'+\n",
    "                           'URL: <a href=\"'+stations_df.url.loc[stations_df.index==station_code].values[0]+\n",
    "                           '\"target=\"_blank\">link</a>',\n",
    "                           max_width=450)\n",
    "\n",
    "        #Create marker and add it to the map:\n",
    "        folium.Marker(location=[float(stations_df.lat.loc[stations_df.index==station_code].values[0]),\n",
    "                                float(stations_df.lon.loc[stations_df.index==station_code].values[0])],\n",
    "                      popup=popup,\n",
    "                      icon=folium.Icon(color=marker_color, icon='leaf'),\n",
    "                      tooltip=tooltip).add_to(map_obj)\n",
    "\n",
    "\n",
    "    #Get list of stations (not incl. selected station):\n",
    "    station_ls = [i for i in stations_df.index.values if i!=selected_station]  \n",
    "\n",
    "    #Create markers for all stations except selected station:\n",
    "    for st in station_ls:\n",
    "        add_marker(m, st, 'green') \n",
    "\n",
    "    #Add marker for selected station:\n",
    "    add_marker(m, selected_station, 'darkred')\n",
    "\n",
    "    #Show map:\n",
    "    display(m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    \n",
    "    \"\"\"\n",
    "    Project:         'ICOS Carbon Portal'\n",
    "    Created:          Fri May 10 12:00:00 2019\n",
    "    Last Changed:     Fri May 10 12:00:00 2019\n",
    "    Version:          1.0.0\n",
    "    Author(s):        Karolina\n",
    "    \n",
    "    Description:      Function that allows you to print the string input parameter using\n",
    "                      markdown formatting code.\n",
    "                      \n",
    "    Input parameters: String of characters\n",
    "                      (var_name: 'string', var_type: String)\n",
    "\n",
    "    Output:           String     \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #import module:\n",
    "    from IPython.display import Markdown, display\n",
    "    \n",
    "    #Enable displaying string with markdown code:\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to plot FLUXNET-variables:\n",
    "def plot_fluxnet_var(df, var, st_name, var_dict, stations_dict, color):\n",
    "\n",
    "    #Create a new plot with a datetime axis type:\n",
    "    p = figure(plot_width=900, plot_height=500, x_axis_type=\"datetime\")\n",
    "\n",
    "\n",
    "    #Check if variable includes a adimensional quality-values:\n",
    "    if(var_dict[var][1]!=\"adimensional\"): \n",
    "\n",
    "        #Add renderers:\n",
    "        r0 = p.circle(df[df.columns.values[0]].values, df[var].values, size=4, color=color, alpha=0.2)\n",
    "        r1 = p.line(df[df.columns.values[0]].values, df[var].values, color=color)\n",
    "\n",
    "        #Create legend:\n",
    "        legend = Legend(items=[(var_dict[var][0] + \" sample\", [r0]),\n",
    "                               (var_dict[var][0] + \" continuous\", [r1])], location= 'bottom_center')\n",
    "        legend.click_policy='hide'\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        #Add renderers:\n",
    "        r0 = p.circle(df[df.columns.values[0]].values, df[var].values, size=4, color=color, alpha=0.2)\n",
    "\n",
    "        #Create legend:\n",
    "        legend = Legend(items=[(var_dict[var][0], [r0])], location= 'bottom_center')\n",
    "\n",
    "\n",
    "    #Add tooltip:\n",
    "    p.add_tools(HoverTool(tooltips=[('Time (UTC)','@x{%Y-%m-%d %H:%M:%S}'),\n",
    "                                    (var,'@y{0.f}'),],\n",
    "                          formatters={'@x'      : 'datetime',},\n",
    "                          # visa ett tooltip när musen är i lodrätt-linje med motsvarande glyph\n",
    "                          mode='vline'))  \n",
    "\n",
    "\n",
    "    # NEW: customize by setting attributes\n",
    "    p.title.text = var_dict[var][0] +': '+ stations_dict[st_name][0]+', '+stations_dict[st_name][1]+ \" (2015 - 2018)\"\n",
    "    p.grid.grid_line_alpha = 0\n",
    "    p.xaxis.axis_label = 'Time'\n",
    "    p.yaxis.axis_label = var_dict[var][0] +\"\\n(\"+var_dict[var][1]+\")\"\n",
    "    p.ygrid.band_fill_color = \"olive\"\n",
    "    p.ygrid.band_fill_alpha = 0.1\n",
    "    p.title.align = 'center'\n",
    "    p.title.text_font_size = '13pt'\n",
    "    p.title.offset = 15\n",
    "\n",
    "\n",
    "    #Definiera font för x-axel och y-axel titlarna :\n",
    "    p.xaxis.axis_label_text_font_style = 'normal'\n",
    "    p.yaxis.axis_label_text_font_style = 'normal'\n",
    "    p.xaxis.axis_label_standoff = 15 #Sets the distance of the label from the x-axis in screen units\n",
    "    p.yaxis.axis_label_standoff = 15 #Sets the distance of the label from the y-axis in screen units\n",
    "\n",
    "    #Set legend format:\n",
    "    legend.orientation = 'horizontal'\n",
    "    legend.spacing = 10 #sets the distance between legend entries\n",
    "\n",
    "\n",
    "    #Set location of copyright-label:\n",
    "    label_opts = dict(x=0, y=10,\n",
    "                      x_units='screen', y_units='screen')    \n",
    "\n",
    "    #Create copyright-label:\n",
    "    caption1 = Label(text=\"© ICOS ERIC\", **label_opts)\n",
    "    caption1.text_font_size = '8pt'\n",
    "\n",
    "    #Add copyright-label to plot:\n",
    "    p.add_layout(caption1, 'below')\n",
    "\n",
    "    #Add legend to figure:\n",
    "    p.add_layout(legend, 'below')\n",
    "\n",
    "    #Deactivate hover-tool:\n",
    "    p.toolbar.active_inspect = None\n",
    "\n",
    "    \n",
    "    #Return plot:\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to display widgets for plotting FLUXNET-files with daily-values:\n",
    "def create_fluxnet_dd_widgets():\n",
    "\n",
    "    #Import modules:\n",
    "    from ipywidgets import Dropdown, Checkbox, ColorPicker, interact_manual\n",
    "\n",
    "    #Create tuples for widgets labels:\n",
    "    st_list = [(i[1][0], [i[0], i[1][0], i[1][1], i[1][2], i[1][3], i[1][4], i[1][5]])\n",
    "               for i in stations_dict.items()]\n",
    "\n",
    "    var_list = [(i[1][0], [i[0], i[1][0],  i[1][1]])\n",
    "                for i in variables_dd_dict.items()]\n",
    "\n",
    "    #Sort station list: \n",
    "    st_list.sort(reverse=False)\n",
    "    var_list.sort(reverse=False)\n",
    "\n",
    "    #Create widgets:\n",
    "    stations = Dropdown(options = st_list)\n",
    "    variables_dd = Dropdown(options = var_list)\n",
    "    citation = Checkbox(value=True, description='Citation', disabled=False)\n",
    "    colors = ColorPicker(concise=False, description='Plot color', value='navy', disabled=False)\n",
    "\n",
    "    #Function to update plot:\n",
    "    def update_plot_dd(Station, Variable, color, cit):\n",
    "\n",
    "        #Read FLUXNET file:\n",
    "        df = read_fluxnet_dd(path_fluxnet_dd, Station[0])\n",
    "\n",
    "        #Check if variable is included in dataframe:\n",
    "        if(Variable[0] in df.columns.values):\n",
    "\n",
    "            #Call function to plot variable values:\n",
    "            plot = plot_fluxnet_var(df, Variable[0], Station[0], variables_dd_dict, stations_dict, color)\n",
    "            \n",
    "            #Convert stations dictionary to pandas dataframe:\n",
    "            stations_df = pd.DataFrame.from_dict(stations_dict,\n",
    "                                                 orient='index',\n",
    "                                                 columns=['name', 'country', 'country_code', 'vegetation', 'lat', 'lon', 'url', 'lpj_lat', 'lpj_lon'])\n",
    "\n",
    "            #Show plot\n",
    "            show(plot, notebook_handle=True)\n",
    "            \n",
    "            #If citation-checkbox is checked:\n",
    "            if(cit):\n",
    "\n",
    "                #Citation in APA-format:\n",
    "                apa_cit = 'Drought 2018 Team & ICOS Ecosystem Thematic Centre (2020). Drought-2018 ecosystem eddy covariance flux product in FLUXNET-Archive format - release 2019-2 (Version 1.0). ICOS Carbon Portal. https://doi.org/10.18160/yvr0-4898'\n",
    "\n",
    "                #Print citation title:\n",
    "                print('\\n\\n\\033[1m' + 'Data Citation:' +  '\\033[0m')\n",
    "\n",
    "                #Print APA-style citation:\n",
    "                printmd(\"<sub>\"+apa_cit+\"</sub>\")\n",
    "                \n",
    "                print()\n",
    "                print()\n",
    "            \n",
    "            #Show map:\n",
    "            plotmap_climbeco(stations_df, Station[0])\n",
    "            \n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"\\033[0;31;1m \"+'There are no '+Variable[1]+'-values for '+Variable[0]+\n",
    "                  \" included in this file!\"+\"\\033[0;31;0m\\n\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "\n",
    "    #Create function that contains a box of widgets:\n",
    "    interact_c = interact_manual(update_plot_dd,\n",
    "                                 Station = stations,\n",
    "                                 Variable = variables_dd,\n",
    "                                 color = colors,\n",
    "                                 cit = citation)\n",
    "\n",
    "\n",
    "    #Set the font of the widgets included in interact_manual:\n",
    "    interact_c.widget.children[0].layout.width = '430px'\n",
    "    interact_c.widget.children[0].layout.margin = '40px 2px 2px 202px'\n",
    "    interact_c.widget.children[1].layout.width = '430px'\n",
    "    interact_c.widget.children[1].layout.margin = '2px 2px 2px 202px'\n",
    "    interact_c.widget.children[2].layout.width = '430px'\n",
    "    interact_c.widget.children[2].layout.margin = '2px 2px 2px 202px'\n",
    "    interact_c.widget.children[3].layout.width = '430px'\n",
    "    interact_c.widget.children[3].layout.margin = '2px 2px 2px 202px'\n",
    "    interact_c.widget.children[4].description = 'Update Plot'\n",
    "    interact_c.widget.children[4].button_style = 'danger'\n",
    "    interact_c.widget.children[4].style.button_color = '#3973ac'\n",
    "    interact_c.widget.children[4].layout.margin = '10px 10px 40px 385px' # top/right/bottom/left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><a href=\"#introduction\">Back to top</a></div>\n",
    "<a id='lpjguess_paul'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LPJ-GUESS (Paul's dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lpjguess_st(vegetation, eco_variable, station, st_dict=stations_dict):\n",
    "    \n",
    "    '''\n",
    "    Description: Function that reads LPJ-GUESS output for given station.\n",
    "    '''\n",
    "    \n",
    "    path = lpj_veg_type_dict[vegetation.lower()]\n",
    "    filename = lpj_var_dict[eco_variable.lower()]\n",
    "    \n",
    "    #Set offset:\n",
    "    offset = 1460\n",
    "    \n",
    "    #Read file:\n",
    "    df = pd.read_csv(path+filename,\n",
    "                     header=0,\n",
    "                     sep=',',\n",
    "                     engine='python',\n",
    "                     parse_dates=['time'])\n",
    "    \n",
    "    #Extract data for input station based on its corresponding LPJ-GUESS coordinates:\n",
    "    st_df = df.loc[(df.Lon==stations_dict[station][8]) & (df.Lat==stations_dict[station][7])]\n",
    "    \n",
    "    \n",
    "    #############################################################################\n",
    "    #Some stations have been assigned with the same lpj-guess grid-coordinates.\n",
    "    #The lpj-guess output does not include a station name column.\n",
    "    #Lpj-guess output values can be related to a station based on coordinates.\n",
    "    #The following code sepparates values for stations being assigned with the \n",
    "    #same coordinate. This is possible due to the order the output is produced in.\n",
    "    #############################################################################\n",
    "    \n",
    "    #Check if output-files include PNV-data:\n",
    "    if((path[-20:-17]=='PNV')):\n",
    "        \n",
    "        #Check if station is \"Degerö\":\n",
    "        if(station=='Deg'):\n",
    "            \n",
    "            #\n",
    "            st_df = st_df.iloc[:offset]\n",
    "            \n",
    "            \n",
    "        elif(station=='Ros'):\n",
    "            print('Svb PNV')\n",
    "            \n",
    "            st_df = st_df.iloc[offset:2*offset]\n",
    "            \n",
    "        elif(station=='Svb'):\n",
    "            \n",
    "            \n",
    "            st_df = st_df.iloc[(2*offset):]\n",
    "            \n",
    "            \n",
    "    elif((path[-20:-17]!='PNV')):\n",
    "        \n",
    "        if((station=='Ros') | (station=='RuR')):\n",
    "\n",
    "            st_df = st_df.iloc[:offset]\n",
    "\n",
    "        if((station=='Svb') | (station=='RuS')):\n",
    "\n",
    "            st_df = st_df.iloc[offset:]\n",
    "    \n",
    "    #Add entry for the 29th of Feb 2016 (Leap Year)\n",
    "    #Same value as 28th of Feb\n",
    "    listOfSeries = [pd.Series([st_df.Lon.iloc[0], st_df.Lon.iloc[0], 2016, 60, st_df.Value.loc[st_df.time==datetime(2016,2,28)].values[0], datetime.strptime(str(2016)+' '+str(60), '%Y %j')], index=st_df.columns)]\n",
    "    \n",
    "    #Pass a list of series to the append() to add multiple rows\n",
    "    mod_df = st_df.append(listOfSeries , ignore_index=True)\n",
    "    \n",
    "    #Sort values by the column \"time\":\n",
    "    mod_df.sort_values(by=['time'])\n",
    "    \n",
    "    #Return dataframe:\n",
    "    return mod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that calculates monthly values for a certain column of a pandas dataframe.\n",
    "#The dataframe should have a datetime index:\n",
    "def calc_monthly_values(df, col):\n",
    "    \n",
    "    return df[col].resample('M', label='left', loffset='15d').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that creates a plot object:\n",
    "def plot_lpj_var(station, var, veg_type, lpj_var_dict, veg_type_to_lpjpath_dict, fluxnet_dict, monthly_values):\n",
    "    \n",
    "    #Compute monthly values\n",
    "    if(monthly_values):\n",
    "        \n",
    "        #Read lpj-data for selected variable to a pandas dataframe:\n",
    "        fluxnet_df = calc_monthly_values(read_fluxnet_dd(path_fluxnet_dd, station).set_index('TIMESTAMP'), fluxnet_dict[var])\n",
    "        read_pnv_df = read_lpjguess_st('pnv', var, station).set_index('time')\n",
    "        read_pnv_df.sort_index(inplace=True)\n",
    "        pnv_df = calc_monthly_values(read_pnv_df, 'Value')\n",
    "        read_veg_df = read_lpjguess_st(veg_type_to_lpjpath_dict[veg_type], var, station).set_index('time')\n",
    "        read_veg_df.sort_index(inplace=True)\n",
    "        veg_df = calc_monthly_values(read_veg_df, 'Value')\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        fluxnet_df = read_fluxnet_dd(path_fluxnet_dd, station).set_index('TIMESTAMP')[fluxnet_dict[var]]\n",
    "        pnv_df = read_lpjguess_st('pnv', var, station).set_index('time').Value\n",
    "        pnv_df.sort_index(inplace=True)\n",
    "        veg_df = read_lpjguess_st(veg_type_to_lpjpath_dict[veg_type], var, station).set_index('time').Value\n",
    "        veg_df.sort_index(inplace=True)\n",
    "        \n",
    "    if(var=='NEE'):\n",
    "        \n",
    "        #Extract \"var\" data from every vegetation-type dataframe:\n",
    "        x1 = fluxnet_df.index.values\n",
    "        y1 = fluxnet_df.values\n",
    "        x2 = pnv_df.index.values\n",
    "        y2 = pnv_df.values*1000*(-1)\n",
    "        x3 = veg_df.index.values\n",
    "        y3 = veg_df.values*1000*(-1)\n",
    "            \n",
    "    else:\n",
    "        #Extract \"var\" data from every vegetation-type dataframe:\n",
    "        x1 = fluxnet_df.index.values\n",
    "        y1 = fluxnet_df.values\n",
    "        x2 = pnv_df.index.values\n",
    "        y2 = pnv_df.values*1000\n",
    "        x3 = veg_df.index.values\n",
    "        y3 = veg_df.values*1000\n",
    "\n",
    "    #Create a figure object:\n",
    "    p = figure(plot_width = 900,\n",
    "               plot_height = 500,\n",
    "               x_axis_label = 'Time',\n",
    "               y_axis_label = var +' ('+variables_dd_dict[fluxnet_dict[var]][1]+')',\n",
    "               x_axis_type = 'datetime',\n",
    "               title = var + ' per Vegetation Type ('+stations_dict[station][0]+', '+stations_dict[station][1]+')',\n",
    "               min_border_top= 100)\n",
    "\n",
    "    #Create an empty list that will store the legend info:\n",
    "    legend_it = []\n",
    "\n",
    "    #Add circle/line glyphs\n",
    "    r0 = p.circle(x1, y1, radius=.12, color='DodgerBlue')\n",
    "    r1 = p.circle(x2, y2, radius=.12, color='firebrick')\n",
    "    r2 = p.circle(x3, y3, radius=.12, color='gold')\n",
    "    \n",
    "    l0 = p.line(x1, y1, line_width=2, color='DodgerBlue', name='FLUXNET Observations')\n",
    "    l1 = p.line(x2, y2, line_width=2, color='firebrick', name='LPJ - PNV')\n",
    "    l2 = p.line(x3, y3, line_width=2, color='gold', name='LPJ - '+veg_type)\n",
    "\n",
    "    #Add the name and glyph info (i.e. colour and marker type) to the legend:\n",
    "    legend_it.append((l0.name, [r0, l0]))\n",
    "    legend_it.append((l1.name, [r1, l1]))\n",
    "    legend_it.append((l2.name, [r2, l2]))\n",
    "\n",
    "     #Create legend:\n",
    "    legend = Legend(items=legend_it, location= 'bottom_center')\n",
    "    legend.orientation = 'horizontal'\n",
    "    legend.click_policy='hide'\n",
    "    legend.spacing = 10 #sets the distance between legend entries\n",
    "\n",
    "    #Add tooltip on hover:\n",
    "    p.add_tools(HoverTool(tooltips=[('Type','$name'),\n",
    "                                    ('Time (UTC)','@x{%Y-%m-%d %H:%M:%S}'),\n",
    "                                    (var,'@y{0.000f}'),\n",
    "            ],\n",
    "            formatters={\n",
    "                '@x'      : 'datetime', # use 'datetime' formatter for 'date' field\n",
    "                },\n",
    "            # display a tooltip whenever the cursor is vertically in line with a glyph\n",
    "            mode='vline'\n",
    "            ))    \n",
    "\n",
    "    #Set title attributes:\n",
    "    p.title.align = 'center'\n",
    "    p.title.text_font_size = '13pt'\n",
    "    p.title.offset = 15\n",
    "\n",
    "    #Set axis label font style:\n",
    "    p.xaxis.axis_label_text_font_style = 'normal'\n",
    "    p.yaxis.axis_label_text_font_style = 'normal'\n",
    "    p.xaxis.axis_label_standoff = 15 #Sets the distance of the label from the x-axis in screen units\n",
    "    p.yaxis.axis_label_standoff = 15 #Sets the distance of the label from the y-axis in screen units\n",
    "\n",
    "    #Add legend to figure:\n",
    "    p.add_layout(legend, 'below')\n",
    "\n",
    "    #Deactivate hover-tool, which is by default active:\n",
    "    p.toolbar.active_inspect = None\n",
    "\n",
    "    #Return plot:\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpj_var_dropdown(lpj_var_dict):\n",
    "    \n",
    "    #Create dropdown list for stations:\n",
    "    stations = Dropdown(options=sorted([(i[1][0], [i[0], i[1][0], i[1][1], i[1][2], i[1][3], i[1][4], i[1][5]])\n",
    "                                        for i in stations_dict.items()]))\n",
    "    \n",
    "    #Create checkbox for monthly values:\n",
    "    checkbx = Checkbox(value=False, description='Monthly values', disabled=False, indent=False)\n",
    "    \n",
    "    #Function that updates plot:\n",
    "    def update_func(Station, Checkbox):\n",
    "        \n",
    "        #Call function to plot NEE:\n",
    "        nee_plot = plot_lpj_var(Station[0], 'NEE', Station[4], lpj_var_dict, veg_type_to_lpjpath_dict, fluxnet_dict, Checkbox)\n",
    "        \n",
    "        #Call function to plot GPP:\n",
    "        gpp_plot = plot_lpj_var(Station[0], 'GPP', Station[4], lpj_var_dict, veg_type_to_lpjpath_dict, fluxnet_dict, Checkbox)\n",
    "        \n",
    "        #Call function to plot RTOT:\n",
    "        rtot_plot = plot_lpj_var(Station[0], 'RTOT', Station[4], lpj_var_dict, veg_type_to_lpjpath_dict, fluxnet_dict, Checkbox)\n",
    "        \n",
    "        \n",
    "        #Show plots:\n",
    "        show(column(nee_plot, gpp_plot, rtot_plot))\n",
    "        \n",
    "        \n",
    "    \n",
    "    #Create widget form:\n",
    "    interact_c = interact_manual(update_func,\n",
    "                                 Station=stations,\n",
    "                                 Checkbox = checkbx)\n",
    "    \n",
    "    #Format widgets:\n",
    "    interact_c.widget.children[0].layout.width = '430px'\n",
    "    interact_c.widget.children[0].layout.margin = '40px 2px 2px 200px'\n",
    "    interact_c.widget.children[1].layout.width = '430px'\n",
    "    interact_c.widget.children[1].layout.margin = '2px 2px 2px 287px'\n",
    "    interact_c.widget.children[2].description = 'Update Plots'\n",
    "    interact_c.widget.children[2].button_style = 'danger'\n",
    "    interact_c.widget.children[2].style.button_color = '#3973ac'\n",
    "    interact_c.widget.children[2].layout.margin = '10px 10px 40px 390px' # top/right/bottom/left\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><a href=\"#introduction\">Back to top</a></div>\n",
    "<a id='lpjguess_map'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LPJ-GUESS Map data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the geographical extend of all maps\n",
    "map_latmin=35.0\n",
    "map_latmax=71.0\n",
    "map_lonmin=-10.0\n",
    "map_lonmax=35.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version to read all netcdf files because we want to extract timeseries for 2015-2018\n",
    "# need to adjust fluxes\n",
    "# \n",
    "\n",
    "def read_LPJ_fluxmap_2():\n",
    "\n",
    "    time = []\n",
    "    nee = []\n",
    "    gpp = []\n",
    "    rtot = []\n",
    "    first = True\n",
    "    for year in range(2015,2018+1):\n",
    "        for month in range(1,12+1):\n",
    "            filename=path_lpjmaps+'/lpj_'+str(year)+str(month).zfill(2)+'.nc4'\n",
    "            ncfile = cdf.Dataset(filename)\n",
    "            #print(ncfile)\n",
    "            #print(ncfile.variables)\n",
    "            if first:\n",
    "                #print(ncfile)\n",
    "                lon = ncfile.variables['lons'][:]\n",
    "                lat = ncfile.variables['lats'][:]\n",
    "                cell_area = ncfile.variables['area'][:,:]\n",
    "                flux_units = ncfile.variables['nee'].units\n",
    "                #print(flux_units)\n",
    "                description = ncfile.Notes\n",
    "                #print(description)\n",
    "                first = False\n",
    "            for m in range(ncfile.dimensions['nt'].size):\n",
    "                time.append(cdf.num2date(ncfile.variables['times'][m],units=ncfile.variables['times'].units))\n",
    "                nee.append(ncfile.variables['nee'][m,:,:]*1000.)\n",
    "                gpp.append(ncfile.variables['gpp'][m,:,:]*1000.)\n",
    "                rtot.append(ncfile.variables['rtot'][m,:,:]*-1.*1000.)    \n",
    "            ncfile.close()\n",
    "\n",
    "    nee = np.array(nee,dtype='float32')\n",
    "    gpp = np.array(gpp,dtype='float32')\n",
    "    rtot = np.array(rtot,dtype='float32')\n",
    "            \n",
    "    return lon, lat, time, nee, gpp, rtot, cell_area, flux_units, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that reads a LPJ-netcdf for given year and month:\n",
    "def read_LPJ_fluxmap(filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    Project:      EUROCOM\n",
    "    Created:      Fri Apr 13 09:00:00 2018\n",
    "    Last Changed: Fri Feb 13 10:00:00 2020\n",
    "    Version:      1.1.0\n",
    "    Author(s):    Ute Karstens, Karolina Pantazatou\n",
    "    \n",
    "    Definition:   Function that takes a string as input, signifying the path to a netCDF-datafile,\n",
    "                  reads the netcdf and returns its content.\n",
    "    \n",
    "    Input:        1. Full path to netCDF file (data type: String)\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "                  1. a list of longitudes\n",
    "                  2. a list of latitudes\n",
    "                  3. a list of time instances (i.e. Python datetime objects)\n",
    "                  4. a 3-dimensional array with NEE values (one month time period)\n",
    "                  5. a 3-dimensional array with GPP values\n",
    "                  6. a 3-dimensional array with RESPIRATION values \n",
    "                  7. cell_area, flux_units, description\n",
    "    \"\"\"\n",
    "    \n",
    "    #Declare and initialize lists:\n",
    "    time = [] #store sequence of timepoints\n",
    "    nee = []  #store nee-arrays\n",
    "    gpp = []  #store\n",
    "    rtot = []\n",
    "    \n",
    "    #Open netcdf-file with data:\n",
    "    ncfile = cdf.Dataset(filename)\n",
    "    \n",
    "    #Get longitudes and latitudes:\n",
    "    lon = ncfile.variables['lons'][:]\n",
    "    lat = ncfile.variables['lats'][:]\n",
    "    \n",
    "    #Get the cell-area of ever grid-cell:\n",
    "    cell_area = ncfile.variables['area'][:,:]\n",
    "    \n",
    "    #Get NEE flux units:\n",
    "    flux_units = ncfile.variables['nee'].units\n",
    "    \n",
    "    #Get file description:\n",
    "    description = ncfile.Notes\n",
    "\n",
    "    #Loop through all timepoints:        \n",
    "    for m in range(ncfile.dimensions['nt'].size):\n",
    "        \n",
    "        #Get time, nee, gpp and rtot values for every timepoint:\n",
    "        time.append(cdf.num2date(ncfile.variables['times'][m],units=ncfile.variables['times'].units))\n",
    "        nee.append(ncfile.variables['nee'][m,:,:])\n",
    "        gpp.append(ncfile.variables['gpp'][m,:,:])\n",
    "        rtot.append(ncfile.variables['rtot'][m,:,:])    \n",
    "    \n",
    "    #Close netcdf-file:\n",
    "    ncfile.close()\n",
    "    \n",
    "    #Convert nee/gpp/rtot lists to numpy arrays:\n",
    "    nee = np.array(nee,dtype='float32')\n",
    "    gpp = np.array(gpp,dtype='float32')\n",
    "    rtot = np.array(rtot,dtype='float32')\n",
    "    \n",
    "    #Return output:\n",
    "    return lon, lat, time, nee, gpp, rtot, cell_area, flux_units, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that creates a grid based on a list or numpy array of lat/lon values:\n",
    "def get_mesh(lon,lat):\n",
    "    \n",
    "    \"\"\"\n",
    "    Project:      EUROCOM\n",
    "    Created:      Fri Apr 13 09:00:00 2018\n",
    "    Last Changed: Fri Apr 13 09:00:00 2018\n",
    "    Version:      1.0.0\n",
    "    Author(s):    Ute Karstens\n",
    "    \n",
    "    Definition:   Function that takes two list of longitudes and latitudes as input and\n",
    "                  and returns NumPy meshgrids of longitudes and latitudes.\n",
    "    \n",
    "    Input:        1. Longitudes (data type: List or NumPy array of ints or floats)\n",
    "                  2. Latitudes  (data type: List or NumPy array of ints or floats)\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "                  1. Meshgrid of longitudes (data type: Numpy array of ints or floats) \n",
    "                  2. Meshgrid of latitudes  (data type: Numpy array of ints or floats) \n",
    "                  \n",
    "    \"\"\"\n",
    "    \n",
    "    #Shift the longitudes and latitudes:\n",
    "    dlat2=abs(lat[2]-lat[1])/2.\n",
    "    plat=np.append((lat-dlat2),(lat[-1]+(dlat2)))\n",
    "    dlon2=abs(lon[2]-lon[1])/2.\n",
    "    plon=np.append((lon-dlon2),(lon[-1]+(dlon2)))\n",
    "    \n",
    "    #Create meshgrid:\n",
    "    xx, yy = np.meshgrid(plon, plat)\n",
    "    \n",
    "    #Return meshgrid:\n",
    "    return xx,yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that plots a single LPJ-GUESS map for a given timepoint:\n",
    "def plot_map(fig, xx,yy,zz,nr,nc,iplot,title,vmin=-3,vmax=3,units='gC/m2/d',cb_name='PiYG_r',extend='both'):\n",
    "    \n",
    "    \n",
    "#    'PiYG', 'PRGn', 'BrBG', 'PuOr', 'RdGy', 'RdBu',\n",
    "#            'RdYlBu', 'RdYlGn', 'Spectral', 'coolwarm', 'bwr', 'seismic']\n",
    "    \n",
    "    \n",
    "    #Set scale for features from Natural Earth:\n",
    "    NEscale = '50m'    \n",
    "    \n",
    "    #Create a feature for Countries at 1:50m from Natural Earth:\n",
    "    countries = cfeature.NaturalEarthFeature(category='cultural',\n",
    "                                             name='admin_0_countries',\n",
    "                                             scale=NEscale,facecolor='none')\n",
    "    \n",
    "    #Create a feature for Lakes at 1.50m from Natural Earth:\n",
    "    lakes = cfeature.NaturalEarthFeature(category='physical', name='lakes', scale=NEscale, facecolor='none')\n",
    "    \n",
    "    #Set up a map:\n",
    "    ax = fig.add_subplot(nr+1, nc, iplot, projection=ccrs.PlateCarree())\n",
    "    \n",
    "    #Define the spatial extent of the map (min/max lat/lon):\n",
    "    img_extent = [xx.min(), xx.max(), yy.min(), yy.max()]\n",
    "    \n",
    "    #Set the spatial extent and the coordinate system:\n",
    "    ax.set_extent(img_extent, crs=ccrs.PlateCarree())\n",
    "    \n",
    "    #Add gridlines:\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=False, linewidth=0.3, color='gray', alpha=0.5)\n",
    "    \n",
    "    #Set gridline-parameters (spatial extent (min/max values of lat/lon) and interval(here=10))\n",
    "    gl.ylocator = mticker.FixedLocator(np.arange(-90.,90.,10.))\n",
    "    gl.xlocator = mticker.FixedLocator(np.arange(-180.,180.,10.))\n",
    "    \n",
    "    #Add Natural Earth countries:\n",
    "    ax.add_feature(countries, edgecolor='black', linewidth=0.3)\n",
    "    \n",
    "    #Add Natural Earth lakes:\n",
    "    ax.add_feature(lakes, edgecolor='black', linewidth=0.3)\n",
    "    \n",
    "    #Add raster with values:\n",
    "    \n",
    "    im = ax.pcolormesh(xx,yy,zz,cmap=cb_name,vmin=vmin,vmax=vmax)\n",
    "    \n",
    "    #Add colorbar:\n",
    "    cbar=plt.colorbar(im,orientation='horizontal',pad=0.03,fraction=0.055,extend=extend)\n",
    "    \n",
    "    \n",
    "    #Define colorbar parameters:\n",
    "    cbar.outline.set_linewidth(1.0)\n",
    "    cbar.ax.tick_params(labelsize=10) \n",
    "    cbar.set_label(units,fontsize=10)\n",
    "    \n",
    "    #Add plot title:\n",
    "    ax.set_title(title,fontsize=14)\n",
    "    \n",
    "    #Add explanatory text under the colorbar (raster dataset min value):\n",
    "    ax.text(0.01, -0.27, 'min: %.2f' % np.nanmin(zz),\n",
    "            horizontalalignment='left',transform=ax.transAxes,fontsize=11)\n",
    "    \n",
    "    #Add explanatory text under the colorbar (raster dataset max value):\n",
    "    ax.text(0.99, -0.27, 'max: %.2f' % np.nanmax(zz),\n",
    "            horizontalalignment='right',transform=ax.transAxes,fontsize=11)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dates(y, m, d):\n",
    "    \n",
    "    \"\"\"\n",
    "    Project:      ClimBEco Research School - 2020\n",
    "    Created:      Fri Feb 13 10:00:00 2020\n",
    "    Last Changed: Fri Feb 13 10:00:00 2020\n",
    "    Version:      1.0.0\n",
    "    Author(s):    Karolina Pantazatou\n",
    "    \n",
    "    Definition:   Function that takes 3 strings as input parameters (i.e. year, month, day)\n",
    "                  controls if the date is valid and returns a boolean value.\n",
    "    \n",
    "    Input:        1. Year (data type: String)\n",
    "                  2. Month (data type: String)\n",
    "                  3. Day (data type: String)\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "                  1. True/False (data type: Boolean)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #Define & initialize help variable:\n",
    "    check = False\n",
    "   \n",
    "    #Control for February (Leap Year and normal year):\n",
    "    if(((int(y)%4==0) & (int(m)==2) & (int(d)<=29)) | ((int(m)==2) & (int(d)<=28))):\n",
    "        \n",
    "        #Set help-variable to \"true\":\n",
    "        check = True\n",
    "    \n",
    "    \n",
    "    #Control for months with 31 days (Jan, Mar, May, Jul, Aug, Oct, Dec):\n",
    "    elif((int(m) in [1, 3, 5, 7, 8, 10, 12]) & (int(d)<32)):\n",
    "        \n",
    "        #Set help-variable to \"true\":\n",
    "        check = True\n",
    "        \n",
    "        \n",
    "    #Control for months with 30 days (Apr, Jun, Sep, Nov):\n",
    "    elif((int(m) in [4, 6, 9, 11]) & (int(d)<31)):\n",
    "        \n",
    "        #Set help-variable to \"true\":\n",
    "        check = True\n",
    "    \n",
    "    \n",
    "    #If none above the above conditions is true:\n",
    "    else:\n",
    "        \n",
    "        #Set help-variable to \"false\":\n",
    "        check = False\n",
    "    \n",
    "    \n",
    "    #Return boolean variable:\n",
    "    return check\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpathtofile(pathtofile):\n",
    "    \n",
    "    \"\"\"\n",
    "    Project:      ClimBEco Research School - 2020\n",
    "    Created:      Fri Feb 13 10:00:00 2020\n",
    "    Last Changed: Fri Feb 13 10:00:00 2020\n",
    "    Version:      1.0.0\n",
    "    Author(s):    Karolina Pantazatou\n",
    "    \n",
    "    Definition:   Function that checks if a file exists in given directory.\n",
    "                  It takes a string, containing the full path to a datafile, as input and \n",
    "                  controls if that filename exists. It returns a boolean value as output.\n",
    "                  If the file exists, it returns \"True\", otherwise \"False\".\n",
    "    \n",
    "    Input:        1. Full path to datafile (data type: String)\n",
    "                  \n",
    "    Output:\n",
    "                  1. True/False (data type: Boolean)\n",
    "    \"\"\"\n",
    "\n",
    "    #Control if path to file exists:\n",
    "    if(os.path.exists(pathtofile)):\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "        #Print error-message:\n",
    "        print(\"\\033[0;31;1m\"+'File not found...'+\"\\033[0;31;0m\\n\\n\")\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that creates a widget-form:\n",
    "def create_widget_form_multi_maps():\n",
    "    \n",
    "    \"\"\"\n",
    "    Project:      ClimBEco Research School - 2020\n",
    "    Created:      Fri Feb 13 15:00:00 2020\n",
    "    Last Changed: Fri Feb 13 15:00:00 2020\n",
    "    Version:      1.0.0\n",
    "    Author(s):    Karolina Pantazatou\n",
    "    \n",
    "    Definition:   Function that creates a form of widgets to select the year,\n",
    "                  the month, the day and the time (hour) for which the user\n",
    "                  wishes to get the corresponding NEE, GPP and RESPIRATION \n",
    "                  maps. The user imay select 2 different timepoints and\n",
    "                  visually compare the maps.\n",
    "    \n",
    "    Input:        No input parameters\n",
    "                  \n",
    "    Output:       Widget form\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    #Set style for widget descriptions:\n",
    "    style = {'description_width': 'initial'}\n",
    "\n",
    "    #Create dropdown-lists for time variables (year, month, day and hour) timepoint 1:\n",
    "    years1 = Dropdown(options=['2015', '2016', '2017', '2018'],\n",
    "                      value='2015',\n",
    "                      description='Year:',\n",
    "                      disabled=False)\n",
    "\n",
    "    months1 = Dropdown(options=[str(i) for i in list(np.arange(1,13,1))],\n",
    "                       value='1',\n",
    "                       description='Month:',\n",
    "                       disabled=False)\n",
    "\n",
    "    days1 = Dropdown(options=[str(i) for i in list(np.arange(1,32,1))],\n",
    "                     value='1',\n",
    "                     description='Day:',\n",
    "                     disabled=False)\n",
    "\n",
    "    hours1 = Dropdown(options=['03:00', '09:00', '15:00', '21:00'],\n",
    "                      value='03:00',\n",
    "                      description='Hour:',\n",
    "                      disabled=False)\n",
    "    \n",
    "    #Add FloatText-widgets for setting the colorbar limits:\n",
    "    cbar_min1 = FloatText(value=-3.0,\n",
    "                          description='Colorbar (min value):',\n",
    "                          style=style,\n",
    "                          disabled=False)\n",
    "\n",
    "    cbar_max1= FloatText(value=3.0,\n",
    "                         description='Colorbar (max value):',\n",
    "                         style=style,\n",
    "                         disabled=False)\n",
    "    \n",
    "    \n",
    "    #Create dropdown-lists for time variables (year, month, day and hour) timepoint 2:\n",
    "    years2 = Dropdown(options=['2015', '2016', '2017', '2018'],\n",
    "                      value='2015',\n",
    "                      description='Year:',\n",
    "                      disabled=False)\n",
    "\n",
    "    months2 = Dropdown(options=[str(i) for i in list(np.arange(1,13,1))],\n",
    "                       value='1',\n",
    "                       description='Month:',\n",
    "                       disabled=False)\n",
    "\n",
    "    days2 = Dropdown(options=[str(i) for i in list(np.arange(1,32,1))],\n",
    "                     value='1',\n",
    "                     description='Day:',\n",
    "                     disabled=False)\n",
    "\n",
    "    hours2 = Dropdown(options=['03:00', '09:00', '15:00', '21:00'],\n",
    "                      value='03:00',\n",
    "                      description='Hour:',\n",
    "                      disabled=False)\n",
    "    \n",
    "    #Add FloatText-widgets for setting the colorbar limits:\n",
    "    cbar_min2 = FloatText(value=-3.0,\n",
    "                          description='Colorbar (min value):',\n",
    "                          style=style,\n",
    "                          disabled=False)\n",
    "\n",
    "    cbar_max2= FloatText(value=3.0,\n",
    "                         description='Colorbar (max value):',\n",
    "                         style=style,\n",
    "                         disabled=False)\n",
    "\n",
    "\n",
    "    #Create a Button-widget to control execution:\n",
    "    update_button = Button(description='Run',\n",
    "                           disabled=False,\n",
    "                           button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                           tooltip='Click me')\n",
    "    \n",
    "    \n",
    "    header_time_1 = Output()\n",
    "    with header_time_1:\n",
    "        display(HTML('<p style=\"font-size:13px;font-weight:bold;color:#6495ed;\">Select values for 1st timepoint: </p>'))\n",
    "\n",
    "    header_time_2 = Output()\n",
    "    with header_time_2:\n",
    "        display(HTML('<p style=\"font-size:13px;font-weight:bold;color:#6495ed;\">Select values for 2nd timepoint: </p>'))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    #Add the time-related dropdown-widgets to a HBox:\n",
    "    time_hbox1 = HBox([years1, months1, days1, hours1])\n",
    "    \n",
    "    #Add the colorbar-limit-related widgets to a HBox:\n",
    "    cbar_hbox1 = HBox([cbar_min1, cbar_max1])\n",
    "    \n",
    "    #Add time1-header, time_hbox1 & cbar_hbox1 to a VBox:\n",
    "    time_vbox1 = VBox([header_time_1, time_hbox1, cbar_hbox1])\n",
    "    \n",
    "    #Add the time-related dropdown-widgets to a HBox:\n",
    "    time_hbox2 = HBox([years2, months2, days2, hours2])\n",
    "    \n",
    "    #Add the colorbar-limit-related widgets to a HBox:\n",
    "    cbar_hbox2 = HBox([cbar_min2, cbar_max2])\n",
    "    \n",
    "    #Add time2-header, time_hbox2 & cbar_hbox2 to a VBox:\n",
    "    time_vbox2 = VBox([header_time_2, time_hbox2, cbar_hbox2])\n",
    "\n",
    "    #Add all widgets to a VBox:\n",
    "    form = VBox([time_vbox1, time_vbox2, update_button])\n",
    "\n",
    "    #Set font of all widgets in the form:\n",
    "    update_button.style.button_color = '#1f78b4'\n",
    "\n",
    "\n",
    "    #Initialize form output:\n",
    "    form_out = Output()\n",
    "\n",
    "    #Initialize results output:\n",
    "    results_out = Output()\n",
    "\n",
    "\n",
    "    #Define update function:\n",
    "    def update_plot(button_c):\n",
    "\n",
    "        #Control input:\n",
    "        control_dates1 = check_dates(years1.value, months1.value, days1.value)\n",
    "        control_dates2 = check_dates(years2.value, months2.value, days2.value)\n",
    "        \n",
    "        \n",
    "        #Create path to files:        \n",
    "        filename1=path_lpjmaps+'/lpj_'+years1.value+months1.value.zfill(2)+'.nc4'\n",
    "        filename2=path_lpjmaps+'/lpj_'+years2.value+months2.value.zfill(2)+'.nc4'\n",
    "        \n",
    "        #Check if file exists in given path:\n",
    "        control_file1 = checkpathtofile(filename1)\n",
    "        control_file2 = checkpathtofile(filename2)\n",
    "        \n",
    "\n",
    "        #If the input is correct:\n",
    "        if(control_dates1 & control_dates2 & control_file1 & control_file2):\n",
    "            \n",
    "            \n",
    "            #Get data from netcdf-file:\n",
    "            lon_LPJ1, lat_LPJ1, time_LPJ1, nee_LPJ_map1, gpp_LPJ_map1, rtot_LPJ_map1, cell_area_LPJ1, flux_units_LPJ1, description_LPJ1 = read_LPJ_fluxmap(filename1)\n",
    "            lon_LPJ2, lat_LPJ2, time_LPJ2, nee_LPJ_map2, gpp_LPJ_map2, rtot_LPJ_map2, cell_area_LPJ2, flux_units_LPJ2, description_LPJ2 = read_LPJ_fluxmap(filename2)\n",
    "            \n",
    "            #Get index number for selected date:\n",
    "            i1 = [i for i in range(len(time_LPJ1))\n",
    "                 if time_LPJ1[i]==datetime.strptime(years1.value+'/'+months1.value+'/'+days1.value+' '+hours1.value, '%Y/%m/%d %H:%M' )]\n",
    "            \n",
    "            #Get index number for selected date:\n",
    "            i2 = [i for i in range(len(time_LPJ2))\n",
    "                 if time_LPJ2[i]==datetime.strptime(years2.value+'/'+months2.value+'/'+days2.value+' '+hours2.value, '%Y/%m/%d %H:%M' )]\n",
    "            \n",
    "            #Check that data exist for given timepoint:\n",
    "            if((len(i1)>0) & (len(i2)>0)):\n",
    "                \n",
    "                #Convert latitude/longitude lists to meshgrid:\n",
    "                xx_LPJ1,yy_LPJ1 = get_mesh(lon_LPJ1,lat_LPJ1)\n",
    "                xx_LPJ2,yy_LPJ2 = get_mesh(lon_LPJ2,lat_LPJ2)\n",
    "\n",
    "                #Change units:\n",
    "                fact = 1000.*1000.*4.*(12./44.)\n",
    "\n",
    "                #Set unit labels:\n",
    "                units_bio='gC/m2/d'\n",
    "                cb_name_bio='PiYG_r'\n",
    "\n",
    "                #Create titles:\n",
    "                time_title_1=time_LPJ1[i1[0]].strftime(\"%Y-%m-%d %H:%M\") #1st timepoint\n",
    "                time_title_2=time_LPJ2[i2[0]].strftime(\"%Y-%m-%d %H:%M\") #2nd timepoint\n",
    "                \n",
    "                nee_title_1='LPJ-GUESS NEE'+'   '+time_title_1 #1st timepoint\n",
    "                nee_title_2='LPJ-GUESS NEE'+'   '+time_title_2 #2nd timepoint\n",
    "                \n",
    "                gpp_title_1='LPJ-GUESS GPP'+'   '+time_title_1 #1st timepoint\n",
    "                gpp_title_2='LPJ-GUESS GPP'+'   '+time_title_2 #2nd timepoint\n",
    "                \n",
    "                rtot_title_1='LPJ-GUESS RTOT'+'   '+time_title_1 #1st timepoint\n",
    "                rtot_title_2='LPJ-GUESS RTOT'+'   '+time_title_2 #2nd timepoint\n",
    "\n",
    "                #Change units of raster dataset:\n",
    "                zz_nee_1 = nee_LPJ_map1[i1[0],:,:] * fact / cell_area_LPJ1[:,:]\n",
    "                zz_gpp_1 = gpp_LPJ_map1[i1[0],:,:] * fact / cell_area_LPJ1[:,:]\n",
    "                zz_rtot_1 = (rtot_LPJ_map1[i1[0],:,:] * fact / cell_area_LPJ1[:,:])*(-1)\n",
    "                zz_nee_2 = nee_LPJ_map2[i2[0],:,:] * fact / cell_area_LPJ2[:,:]\n",
    "                zz_gpp_2 = gpp_LPJ_map2[i2[0],:,:] * fact / cell_area_LPJ2[:,:]\n",
    "                zz_rtot_2 = (rtot_LPJ_map2[i2[0],:,:] * fact / cell_area_LPJ2[:,:])*(-1)\n",
    "\n",
    "                \n",
    "                #Display selection:\n",
    "                with results_out:\n",
    "\n",
    "                    #Clear previous results:\n",
    "                    clear_output()\n",
    "                    \n",
    "                    #Plot maps:\n",
    "                    fig = plt.figure(figsize=(18,20))\n",
    "                    plot_map(fig,xx_LPJ1,yy_LPJ1,zz_nee_1,2,3,1,nee_title_1,vmin=cbar_min1.value,vmax=cbar_max1.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    plot_map(fig,xx_LPJ1,yy_LPJ1,zz_gpp_1,2,3,2,gpp_title_1,vmin=cbar_min1.value,vmax=cbar_max1.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    plot_map(fig,xx_LPJ1,yy_LPJ1,zz_rtot_1,2,3,3,rtot_title_1,vmin=cbar_min1.value,vmax=cbar_max1.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    \n",
    "                    plot_map(fig,xx_LPJ2,yy_LPJ2,zz_nee_2,2,3,4,nee_title_2,vmin=cbar_min2.value,vmax=cbar_max2.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    plot_map(fig,xx_LPJ2,yy_LPJ2,zz_gpp_2,2,3,5,gpp_title_2,vmin=cbar_min2.value,vmax=cbar_max2.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    plot_map(fig,xx_LPJ2,yy_LPJ2,zz_rtot_2,2,3,6,rtot_title_2,vmin=cbar_min2.value,vmax=cbar_max2.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    \n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "\n",
    "            #No data for given timepoint: \n",
    "            else:\n",
    "\n",
    "                #Display selection:\n",
    "                with results_out:\n",
    "\n",
    "                    #Clear previous results:\n",
    "                    clear_output()\n",
    "\n",
    "                    #Print error-message:\n",
    "                    print(\"\\033[0;31;1m\"+'No data available for given timepoint...\\nTry again!'+\"\\033[0;31;0m\\n\\n\")\n",
    "\n",
    "\n",
    "        #Invalid input values: \n",
    "        else:\n",
    "\n",
    "            #Display selection:\n",
    "            with results_out:\n",
    "\n",
    "                #Clear previous results:\n",
    "                clear_output()\n",
    "\n",
    "                #Print error-message:\n",
    "                print(\"\\033[0;31;1m\"+'Invalid date...\\nTry again!'+\"\\033[0;31;0m\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    #Call update-function when button is clicked:\n",
    "    update_button.on_click(update_plot)\n",
    "    update_button.layout.margin = '50px 100px 40px 400px' #top, right, bottom, left\n",
    "    time_vbox1.layout.margin = '25px 0px 0px 0px'\n",
    "    time_vbox2.layout.margin = '50px 0px 0px 0px'\n",
    "    cbar_hbox1.layout.margin = '20px 0px 0px 203px'\n",
    "    cbar_max1.layout.margin = '0px 0px 0px 160px'\n",
    "    cbar_min1.layout.width='180px'\n",
    "    cbar_max1.layout.width='180px'\n",
    "    cbar_hbox2.layout.margin = '20px 0px 0px 203px'\n",
    "    cbar_max2.layout.margin = '0px 0px 0px 160px'\n",
    "    cbar_min2.layout.width='180px'\n",
    "    cbar_max2.layout.width='180px'\n",
    "\n",
    "    #Open form object:\n",
    "    with form_out:\n",
    "\n",
    "        #Clear previous selections in form:\n",
    "        clear_output()\n",
    "\n",
    "        #Display form and results:\n",
    "        display(form, results_out)\n",
    "\n",
    "\n",
    "    #Display form:\n",
    "    display(form_out)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><a href=\"#introduction\">Back to top</a></div>\n",
    "<a id='lumia'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LUMIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_EUROCOM_drought_fluxmap(filename):\n",
    "\n",
    "    import cdo \n",
    "    cdo = cdo.Cdo()    \n",
    "        \n",
    "    ncfile = cdf.Dataset(filename)\n",
    "\n",
    "    #print(ncfile)\n",
    "    #print(ncfile.variables)\n",
    "    \n",
    "    lon = ncfile.variables['longitude'][:]\n",
    "    lat = ncfile.variables['latitude'][:]\n",
    "    time = cdf.num2date(ncfile.variables['time'][:],units=ncfile.variables['time'].units)+timedelta(14)\n",
    "    bio_prior = ncfile.variables['fnee_prior'][:,:,:]\n",
    "    bio_posterior = ncfile.variables['fnee_post'][:,:,:]\n",
    "    oce = ncfile.variables['focn'][:,:,:]\n",
    "    fossil = ncfile.variables['fff'][:,:,:]\n",
    "    flux_units = ncfile.variables['fnee_prior'].units\n",
    "    #print(flux_units)\n",
    "    description = ncfile.comment\n",
    "    #print(description)\n",
    "    \n",
    "    ncfile.close()\n",
    "    \n",
    "    # get cell area using cdo commands\n",
    "    cell_area = cdo.gridarea(input=filename,  returnArray = 'cell_area') \n",
    "\n",
    "    # restrict to common region\n",
    "\n",
    "    ind_lat=np.where((lat >= map_latmin) & (lat <= map_latmax))\n",
    "    ind_lon=np.where((lon >= map_lonmin) & (lon <= map_lonmax))\n",
    "    lon_min=np.min(ind_lon)\n",
    "    lon_max=np.max(ind_lon)\n",
    "    lat_min=np.min(ind_lat)\n",
    "    lat_max=np.max(ind_lat)\n",
    "    lat=lat[lat_min:lat_max+1]\n",
    "    lon=lon[lon_min:lon_max+1]\n",
    "    bio_prior = bio_prior[:,lat_min:lat_max+1,lon_min:lon_max+1]\n",
    "    bio_posterior = bio_posterior[:,lat_min:lat_max+1,lon_min:lon_max+1]\n",
    "    oce = oce[:,lat_min:lat_max+1,lon_min:lon_max+1]\n",
    "    fossil = fossil[:,lat_min:lat_max+1,lon_min:lon_max+1]\n",
    "    cell_area = cell_area[lat_min:lat_max+1,lon_min:lon_max+1]\n",
    "    \n",
    "    # should we restrict to 2015-2018 here?\n",
    "    \n",
    "    return lon, lat, time, bio_prior, bio_posterior, oce, fossil, cell_area, flux_units, description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that creates a widget-form:\n",
    "def create_widget_form_multi_maps_lumia():\n",
    "    \n",
    "    \"\"\"\n",
    "    Project:      ClimBEco Research School - 2020\n",
    "    Created:      Fri Feb 13 15:00:00 2020\n",
    "    Last Changed: Fri Feb 13 15:00:00 2020\n",
    "    Version:      1.0.0\n",
    "    Author(s):    Karolina Pantazatou\n",
    "    \n",
    "    Definition:   Function that creates a form of widgets to select the year,\n",
    "                  the month, the day and the time (hour) for which the user\n",
    "                  wishes to get the corresponding NEE, GPP and RESPIRATION \n",
    "                  maps. The user imay select 2 different timepoints and\n",
    "                  visually compare the maps.\n",
    "    \n",
    "    Input:        No input parameters\n",
    "                  \n",
    "    Output:       Widget form\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    #Set style for widget descriptions:\n",
    "    style = {'description_width': 'initial'}\n",
    "\n",
    "    #Create dropdown-lists for time variables (year, month, day and hour) timepoint 1:\n",
    "    years1 = Dropdown(options=[2015, 2016, 2017, 2018],\n",
    "                      value=2015,\n",
    "                      description='Year:',\n",
    "                      disabled=False)\n",
    "\n",
    "    months1 = Dropdown(options=[i for i in list(np.arange(1,13,1))],\n",
    "                       value=1,\n",
    "                       description='Month:',\n",
    "                       disabled=False)\n",
    "\n",
    "    \n",
    "    #Add FloatText-widgets for setting the colorbar limits:\n",
    "    cbar_min1 = FloatText(value=-3.0,\n",
    "                          description='Colorbar (min value):',\n",
    "                          style=style,\n",
    "                          disabled=False)\n",
    "\n",
    "    cbar_max1= FloatText(value=3.0,\n",
    "                         description='Colorbar (max value):',\n",
    "                         style=style,\n",
    "                         disabled=False)\n",
    "    \n",
    "    \n",
    "    #Create dropdown-lists for time variables (year, month, day and hour) timepoint 2:\n",
    "    years2 = Dropdown(options=[2015, 2016, 2017, 2018],\n",
    "                      value=2015,\n",
    "                      description='Year:',\n",
    "                      disabled=False)\n",
    "\n",
    "    months2 = Dropdown(options=[i for i in list(np.arange(1,13,1))],\n",
    "                       value=1,\n",
    "                       description='Month:',\n",
    "                       disabled=False)\n",
    "    \n",
    "    #Add FloatText-widgets for setting the colorbar limits:\n",
    "    cbar_min2 = FloatText(value=-3.0,\n",
    "                          description='Colorbar (min value):',\n",
    "                          style=style,\n",
    "                          disabled=False)\n",
    "\n",
    "    cbar_max2= FloatText(value=3.0,\n",
    "                         description='Colorbar (max value):',\n",
    "                         style=style,\n",
    "                         disabled=False)\n",
    "\n",
    "\n",
    "    #Create a Button-widget to control execution:\n",
    "    update_button = Button(description='Run',\n",
    "                           disabled=False,\n",
    "                           button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                           tooltip='Click me')\n",
    "    \n",
    "    \n",
    "    header_time_1 = Output()\n",
    "    with header_time_1:\n",
    "        display(HTML('<p style=\"font-size:13px;font-weight:bold;color:#6495ed;\">Select values for 1st timepoint: </p>'))\n",
    "\n",
    "    header_time_2 = Output()\n",
    "    with header_time_2:\n",
    "        display(HTML('<p style=\"font-size:13px;font-weight:bold;color:#6495ed;\">Select values for 2nd timepoint: </p>'))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    #Add the time-related dropdown-widgets to a HBox:\n",
    "    time_hbox1 = HBox([years1, months1])\n",
    "    \n",
    "    #Add the colorbar-limit-related widgets to a HBox:\n",
    "    cbar_hbox1 = HBox([cbar_min1, cbar_max1])\n",
    "    \n",
    "    #Add time1-header, time_hbox1 & cbar_hbox1 to a VBox:\n",
    "    time_vbox1 = VBox([header_time_1, time_hbox1, cbar_hbox1])\n",
    "    \n",
    "    #Add the time-related dropdown-widgets to a HBox:\n",
    "    time_hbox2 = HBox([years2, months2])\n",
    "    \n",
    "    #Add the colorbar-limit-related widgets to a HBox:\n",
    "    cbar_hbox2 = HBox([cbar_min2, cbar_max2])\n",
    "    \n",
    "    #Add time2-header, time_hbox2 & cbar_hbox2 to a VBox:\n",
    "    time_vbox2 = VBox([header_time_2, time_hbox2, cbar_hbox2])\n",
    "\n",
    "    #Add all widgets to a VBox:\n",
    "    form = VBox([time_vbox1, time_vbox2, update_button])\n",
    "\n",
    "    #Set font of all widgets in the form:\n",
    "    update_button.style.button_color = '#1f78b4'\n",
    "\n",
    "\n",
    "    #Initialize form output:\n",
    "    form_out = Output()\n",
    "\n",
    "    #Initialize results output:\n",
    "    results_out = Output()\n",
    "\n",
    "\n",
    "    #Define update function:\n",
    "    def update_plot(button_c):\n",
    "        \n",
    "        \n",
    "        #Create path to files:        \n",
    "        filename1=path_lumia+'co2flux_monthly_lumia_core_2009_2018.nc'\n",
    "\n",
    "        \n",
    "        #Check if file exists in given path:\n",
    "        control_file1 = checkpathtofile(filename1)\n",
    "        \n",
    "\n",
    "        #If the input is correct:\n",
    "        if(control_file1):\n",
    "            \n",
    "            \n",
    "            #Get data from netcdf-file:\n",
    "            lon_LUMIA,lat_LUMIA,time_LUMIA,bio_prior_LUMIA_map,bio_poste_LUMIA_map,oce_LUMIA_map,ff_LUMIA_map,cell_area_LUMIA_map,flux_units_LUMIA,comment = read_EUROCOM_drought_fluxmap(filename1)\n",
    "            \n",
    "            #Get index number for selected date:\n",
    "            i1 = [n for n in range(len(time_LUMIA)) if ((time_LUMIA[n].year==years1.value)& (time_LUMIA[n].month==months1.value))]\n",
    "            i2 = [m for m in range(len(time_LUMIA)) if ((time_LUMIA[m].year==years2.value)& (time_LUMIA[m].month==months2.value))]\n",
    "            \n",
    "            #Check that data exist for given timepoint:\n",
    "            if((len(i1)>0) & (len(i2)>0)):\n",
    "                \n",
    "                #Convert latitude/longitude lists to meshgrid:\n",
    "                xx_LUMIA,yy_LUMIA = get_mesh(lon_LUMIA,lat_LUMIA)\n",
    "\n",
    "                #Change units:\n",
    "                fact = 1000.*24.\n",
    "\n",
    "                #Set unit labels:\n",
    "                units_bio='gC/m2/d'\n",
    "                cb_name_bio='PiYG_r'\n",
    "\n",
    "                #Create titles:\n",
    "                time_title_1=time_LUMIA[i1[0]].strftime(\"%Y-%m-%d %H:%M\") #1st timepoint\n",
    "                time_title_2=time_LUMIA[i2[0]].strftime(\"%Y-%m-%d %H:%M\") #2nd timepoint\n",
    "                \n",
    "                prior_title_1='LUMIA PRIOR'+'   '+time_title_1 #1st timepoint\n",
    "                prior_title_2='LUMIA PRIOR'+'   '+time_title_2 #2nd timepoint\n",
    "                \n",
    "                post_title_1='LUMIA POSTERIOR'+'   '+time_title_1 #1st timepoint\n",
    "                post_title_2='LUMIA POSTERIOR'+'   '+time_title_2 #2nd timepoint\n",
    "                \n",
    "                diff_title_1='LUMIA DIFF'+'   '+time_title_1 #1st timepoint\n",
    "                diff_title_2='LUMIA DIFF'+'   '+time_title_2 #2nd timepoint\n",
    "\n",
    "                #Change units of raster dataset:\n",
    "                zz_prior_1 = bio_prior_LUMIA_map[i1[0],:,:] * fact\n",
    "                zz_post_1 = bio_poste_LUMIA_map[i1[0],:,:] * fact\n",
    "                zz_diff_1 = (bio_prior_LUMIA_map[i1[0],:,:]- bio_poste_LUMIA_map[i1[0],:,:])* fact\n",
    "                zz_prior_2 = bio_prior_LUMIA_map[i2[0],:,:] * fact\n",
    "                zz_post_2 = bio_poste_LUMIA_map[i2[0],:,:] * fact\n",
    "                zz_diff_2 = (bio_prior_LUMIA_map[i2[0],:,:]- bio_poste_LUMIA_map[i2[0],:,:])* fact\n",
    "\n",
    "                \n",
    "                #Display selection:\n",
    "                with results_out:\n",
    "\n",
    "                    #Clear previous results:\n",
    "                    clear_output()\n",
    "                    \n",
    "                    #Plot maps:\n",
    "                    fig = plt.figure(figsize=(18,20))\n",
    "                    plot_map(fig,xx_LUMIA,yy_LUMIA,zz_prior_1,2,3,1,prior_title_1,vmin=cbar_min1.value,vmax=cbar_max1.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    plot_map(fig,xx_LUMIA,yy_LUMIA,zz_post_1,2,3,2,post_title_1,vmin=cbar_min1.value,vmax=cbar_max1.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    plot_map(fig,xx_LUMIA,yy_LUMIA,zz_diff_1,2,3,3,diff_title_1,vmin=cbar_min1.value,vmax=cbar_max1.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    \n",
    "                    plot_map(fig,xx_LUMIA,yy_LUMIA,zz_prior_2,2,3,4,prior_title_2,vmin=cbar_min2.value,vmax=cbar_max2.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    plot_map(fig,xx_LUMIA,yy_LUMIA,zz_post_2,2,3,5,post_title_2,vmin=cbar_min2.value,vmax=cbar_max2.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    plot_map(fig,xx_LUMIA,yy_LUMIA,zz_diff_2,2,3,6,diff_title_2,vmin=cbar_min2.value,vmax=cbar_max2.value,units=units_bio,cb_name=cb_name_bio)\n",
    "                    \n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "\n",
    "            #No data for given timepoint: \n",
    "            else:\n",
    "\n",
    "                #Display selection:\n",
    "                with results_out:\n",
    "\n",
    "                    #Clear previous results:\n",
    "                    clear_output()\n",
    "\n",
    "                    #Print error-message:\n",
    "                    print(\"\\033[0;31;1m\"+'No data available for given timepoint...\\nTry again!'+\"\\033[0;31;0m\\n\\n\")\n",
    "\n",
    "\n",
    "        #Invalid input values: \n",
    "        else:\n",
    "\n",
    "            #Display selection:\n",
    "            with results_out:\n",
    "\n",
    "                #Clear previous results:\n",
    "                clear_output()\n",
    "\n",
    "                #Print error-message:\n",
    "                print(\"\\033[0;31;1m\"+'Invalid date...\\nTry again!'+\"\\033[0;31;0m\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    #Call update-function when button is clicked:\n",
    "    update_button.on_click(update_plot)\n",
    "    update_button.layout.margin = '50px 100px 40px 270px' #top, right, bottom, left\n",
    "    time_vbox1.layout.margin = '25px 0px 0px 0px'\n",
    "    time_vbox2.layout.margin = '50px 0px 0px 0px'\n",
    "    cbar_hbox1.layout.margin = '20px 0px 0px 120px'\n",
    "    cbar_max1.layout.margin = '0px 0px 0px 120px'\n",
    "    cbar_min1.layout.width='180px'\n",
    "    cbar_max1.layout.width='180px'\n",
    "    cbar_hbox2.layout.margin = '20px 0px 0px 120px'\n",
    "    cbar_max2.layout.margin = '0px 0px 0px 120px'\n",
    "    cbar_min2.layout.width='180px'\n",
    "    cbar_max2.layout.width='180px'\n",
    "    form.layout.margin = '0px 0px 0px 100px'\n",
    "\n",
    "    #Open form object:\n",
    "    with form_out:\n",
    "\n",
    "        #Clear previous selections in form:\n",
    "        clear_output()\n",
    "\n",
    "        #Display form and results:\n",
    "        display(form, results_out)\n",
    "\n",
    "\n",
    "    #Display form:\n",
    "    display(form_out)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><a href=\"#introduction\">Back to top</a></div><a id='tsmaps'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract time series from maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert station longitude and latitude (slat, slon) to indices of STILT model grid (ix,jy)\n",
    "def lonlat_2_ixjy(slon,slat,mlon,mlat):\n",
    "    #slon, slat: longitude and latitude of station\n",
    "    #mlon, mlat: 1-dim. longitude and latitude of model grid\n",
    "    ix = (np.abs(mlon-slon)).argmin()\n",
    "    jy = (np.abs(mlat-slat)).argmin()\n",
    "    return ix,jy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that converts a list of cftime-objects to\n",
    "#a list of datetime-objects:\n",
    "def cftime_to_datetime(cftime_ls):\n",
    "    \n",
    "    #Convert list of cftime objects to list of datetime objects:\n",
    "    return [pd.to_datetime(str(cftime_ls[i].year) + '/'+ str(cftime_ls[i].month)+ '/'+ str(cftime_ls[i].day) +' '+ str(cftime_ls[i].hour)+':'+str(cftime_ls[i].minute)+':'+str(cftime_ls[i].second))\n",
    "            for i in range(len(cftime_ls))]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#introduction\">Back to top</a></div><a id='edgar'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read edgar anthropogenic emissions on specified grid resolution\n",
    "def read_edgar(path_edgar,resolution):\n",
    "    \n",
    "    str_resolution = '{:03.1f}'.format(resolution)\n",
    "    #print('Anthropogenic emissions on '+str_resolution+'x'+str_resolution+' grid')\n",
    "    filename = path_edgar+'v432_CO2_TOT_C_2010.'+str_resolution+'x'+str_resolution+'.europe.nc'\n",
    "    f_edgar = cdf.Dataset(filename,'r')\n",
    "    #print(f_edgar)\n",
    "    lat = f_edgar.variables['lat'][:]\n",
    "    lon = f_edgar.variables['lon'][:]\n",
    "    emis = f_edgar.variables['emi_co2'][:,:]\n",
    "    flux_units = f_edgar.variables['emi_co2'].units\n",
    "    #print(flux_units)\n",
    "    f_edgar.close()\n",
    "\n",
    "    ind_lat=np.where((lat >= map_latmin) & (lat <= map_latmax))\n",
    "    ind_lon=np.where((lon >= map_lonmin) & (lon <= map_lonmax))\n",
    "    lon_min=np.min(ind_lon)\n",
    "    lon_max=np.max(ind_lon)\n",
    "    lat_min=np.min(ind_lat)\n",
    "    lat_max=np.max(ind_lat)\n",
    "    lat=lat[lat_min:lat_max+1]\n",
    "    lon=lon[lon_min:lon_max+1]\n",
    "    emis = emis[lat_min:lat_max+1,lon_min:lon_max+1]\n",
    "\n",
    "    return lon, lat, emis, flux_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <a href=\"#introduction\">Back to top</a></div>\n",
    "<a id='masks'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Country masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read country masks\n",
    "def read_country_masks(filename_countrymask, map_latmin=35.0, map_latmax=71.0, map_lonmin=-10.0, map_lonmax=35.0):\n",
    "    \n",
    "    #Read netCDF:\n",
    "    f_MASK = cdf.Dataset(filename_countrymask,'r')\n",
    "   \n",
    "    #Get lists with latitude and longitude values:\n",
    "    lat=f_MASK.variables['latitude'][:]\n",
    "    lon=f_MASK.variables['longitude'][:]\n",
    "    \n",
    "    #Get country mask multidimensional array:\n",
    "    countryMask=f_MASK.variables['country_mask'][:,:,:]\n",
    "    \n",
    "    #Get list of country codes:\n",
    "    countryCode=cdf.chartostring(f_MASK.variables['country_code'][:,:])\n",
    "    \n",
    "    #Get list of country names:\n",
    "    countryName=cdf.chartostring(f_MASK.variables['country_name'][:,:])\n",
    "    \n",
    "    #Close netCDF:\n",
    "    f_MASK.close()\n",
    "    \n",
    "    #Get an array of index-values for latitudes inside the study area:\n",
    "    ind_lat=np.where((lat >= map_latmin) & (lat <= map_latmax))\n",
    "    \n",
    "    #Get an array of index-values for longitudes inside the study area:\n",
    "    ind_lon=np.where((lon >= map_lonmin) & (lon <= map_lonmax))\n",
    "    \n",
    "    #Get min/max longitudes and latitudes:\n",
    "    lon_min=np.min(ind_lon)\n",
    "    lon_max=np.max(ind_lon)\n",
    "    lat_min=np.min(ind_lat)\n",
    "    lat_max=np.max(ind_lat)\n",
    "    \n",
    "    #Extract latitudes and longitudes that are within the study area:\n",
    "    lat=lat[lat_min:lat_max+1]\n",
    "    lon=lon[lon_min:lon_max+1]\n",
    "    \n",
    "    #Clip country-mask to the defined spatial extent:\n",
    "    countryMask = countryMask[:,lat_min:lat_max+1,lon_min:lon_max+1]\n",
    "\n",
    "    #Return values:\n",
    "    return lon, lat, countryMask, countryCode, countryName "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the countries included in the country-mask netCDF:\n",
    "def get_cmask_cname(filename_countrymask):\n",
    "    \n",
    "    #Read netCDF:\n",
    "    f_MASK = cdf.Dataset(filename_countrymask,'r')\n",
    "    \n",
    "    #Get list of country names:\n",
    "    countryName=cdf.chartostring(f_MASK.variables['country_name'][:,:])\n",
    "    \n",
    "    #Close netCDF:\n",
    "    f_MASK.close()\n",
    "\n",
    "    #Return values:\n",
    "    return countryName "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cell area\n",
    "def read_cellarea(filename_cellarea, map_latmin=35.0, map_latmax=71.0, map_lonmin=-10.0, map_lonmax=35.0):\n",
    "    \n",
    "    #Read netCDF:    \n",
    "    f_area = cdf.Dataset(path_masks +filename_cellarea,'r')\n",
    "    #print(f_area)\n",
    "    #Get lists with latitude and longitude values:\n",
    "    lat=f_area.variables['lat'][:]\n",
    "    lon=f_area.variables['lon'][:]\n",
    "    \n",
    "    #Get cell area multidimensional array:\n",
    "    cellarea=f_area.variables['cell_area'][:,:]\n",
    "        \n",
    "    #Close netCDF:\n",
    "    f_area.close()\n",
    "    \n",
    "    #Get an array of index-values for latitudes inside the study area:\n",
    "    ind_lat=np.where((lat >= map_latmin) & (lat <= map_latmax))\n",
    "    \n",
    "    #Get an array of index-values for longitudes inside the study area:\n",
    "    ind_lon=np.where((lon >= map_lonmin) & (lon <= map_lonmax))\n",
    "    \n",
    "    #Get min/max longitudes and latitudes:\n",
    "    lon_min=np.min(ind_lon)\n",
    "    lon_max=np.max(ind_lon)\n",
    "    lat_min=np.min(ind_lat)\n",
    "    lat_max=np.max(ind_lat)\n",
    "    \n",
    "    #Extract latitudes and longitudes that are within the study area:\n",
    "    lat=lat[lat_min:lat_max+1]\n",
    "    lon=lon[lon_min:lon_max+1]\n",
    "    \n",
    "    #Clip cellarea to the defined spatial extent:\n",
    "    cellarea = cellarea[lat_min:lat_max+1,lon_min:lon_max+1]\n",
    "\n",
    "    #Return values:\n",
    "    return lon, lat, cellarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Country Masks - Read Country Boundaries as arrays of lats and longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that returns a pandas dataframe of country boundaries in lat/lon:\n",
    "def country_boundaries_lat_lon(path):\n",
    "\n",
    "    #Import functions:\n",
    "    import csv\n",
    "    import codecs\n",
    "    import gzip\n",
    "    import xml.etree.cElementTree as et\n",
    "    from os.path import dirname, join\n",
    "\n",
    "    #Set NaN:\n",
    "    nan = float('NaN')\n",
    "\n",
    "    #Create a dictionary to store lats/lons per country:\n",
    "    data = {}\n",
    "\n",
    "    #Open csv with country-boundary info:\n",
    "    with gzip.open(path) as f:\n",
    "\n",
    "        #Set encoding to utf-8:\n",
    "        decoded = codecs.iterdecode(f, \"utf-8\")\n",
    "        next(decoded)\n",
    "\n",
    "        #Read csv-file:\n",
    "        reader = csv.reader(decoded, delimiter=',', quotechar='\"')\n",
    "\n",
    "        #Loop through every row in the csv-file:\n",
    "        for row in reader:\n",
    "\n",
    "            #Get the geometry, the country code and the country name:\n",
    "            geometry, code, name = row\n",
    "\n",
    "            #Get geometry:\n",
    "            xml = et.fromstring(geometry)\n",
    "\n",
    "            #Create lists to store tuples of lats and lons for current country:\n",
    "            lats = []\n",
    "            lons = []\n",
    "\n",
    "            #Loop through geometry coordinates:\n",
    "            for i, poly in enumerate(xml.findall('.//outerBoundaryIs/LinearRing/coordinates')):\n",
    "\n",
    "                #Get coordinates for all points in a country polygon (geometry):\n",
    "                coords = (c.split(',')[:2] for c in poly.text.split())\n",
    "\n",
    "                #Split lats from lons for every point coordinate:\n",
    "                lats, lons = list(zip(*[(float(lat), float(lon)) for lon, lat in\n",
    "                    coords]))\n",
    "\n",
    "                #Populate dictionary with country name and tuples of latitudes and longitudes:\n",
    "                data[code + str(i)] = {\n",
    "                    'name'   : name,\n",
    "                    'lats'   : lats,\n",
    "                    'lons'   : lons,\n",
    "                }\n",
    "\n",
    "    #Convert dictionary to Pandas DataFrame:\n",
    "    worldmap = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "    #Return dataframe:\n",
    "    return worldmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Country Masks - Create a grid for Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_lats_lons(max_lat, min_lat, max_lon, min_lon, step):\n",
    "    \n",
    "    \"\"\"\n",
    "    Project:         'ICOS Carbon Portal'\n",
    "    Created:          Tue Feb 26 17:27:00 2020\n",
    "    Last Changed:     Tue Feb 26 17:27:00 2020\n",
    "    Version:          1.0.0\n",
    "    Author(s):        Karolina\n",
    "    \n",
    "    Description:      Function that takes five numeric variables as input and returns\n",
    "                      two lists of lists with longitudes and latitudes(representing a\n",
    "                      grid). The output is used for plotting a grid in Bokeh. \n",
    "                      \n",
    "    Input:            1. Max latitude of grid (var_name: 'max_lat', var_type: Float)\n",
    "                      2. Min latitude of grid (var_name: 'min_lat', var_type: Float)\n",
    "                      3. Max longitude of grid (var_name: 'max_lon', var_type: Float)\n",
    "                      4. Min longitude of grid (var_name: 'min_lon', var_type: Float)\n",
    "                      5. Grid resolution (var_name: 'step', var_type: Float)\n",
    "    \n",
    "    Output:           1. list of lists of longitudes (var_name: 'xx', var_type: Float)\n",
    "                      2. list of lists of latitudes (var_name: 'yy', var_type: Float)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #Import modules:\n",
    "    import numpy as np\n",
    "\n",
    "    #Create a numpy array of values ranging from min-longitude\n",
    "    #to max-longitude with a predefined step:\n",
    "    xx_arr = np.arange(min_lon, max_lon + step, step)\n",
    "\n",
    "    #Create a numpy array of values ranging from min-latitude\n",
    "    #to max-latitude with a predefined step:\n",
    "    yy_arr = np.arange(min_lat, max_lat + step, step)\n",
    "\n",
    "    #Round floats to one decimal degree:\n",
    "    xx_row = [round(xx_arr[k],1) for k in range(len(xx_arr))]\n",
    "    yy_row = [round(yy_arr[l],1) for l in range(len(yy_arr))]\n",
    "\n",
    "    #Create list of longitudes:\n",
    "    xx = [xx_row for k in range(len(yy_row))]\n",
    "\n",
    "    #Create list of latitudes:\n",
    "    yy = [[y for j in range(len(xx_row))] for y in yy_row]\n",
    "    \n",
    "    #Return lists:\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Country Masks - Plot Country Mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that plots a cmask:\n",
    "def plot_cmask(countries, cmask, cmask_type):\n",
    "    \n",
    "    #Convert geopandas dataframe to geojson:\n",
    "    countries_source = GeoJSONDataSource(geojson=countries.to_json())\n",
    "    \n",
    "    #Create plot object:\n",
    "    p = figure(width=900, height=500, x_axis_type=None, y_axis_type=None,\n",
    "               x_range=[-10,35], y_range=[35,70])\n",
    "    \n",
    "    #Add country-layer:\n",
    "    p.patches('xs','ys', source = countries_source, line_color = 'black', line_width = 0.25, fill_color=None)\n",
    "    \n",
    "    #Add country-mask:\n",
    "    p.image_rgba(image=[cmask[cmask_type]],\n",
    "                 x=[-10.0], y=[35],\n",
    "                 dw=[45.0], dh=[36.0],\n",
    "                 name='image')\n",
    "\n",
    "    #Set x-axis layout parameters:\n",
    "    xaxis = LinearAxis()   \n",
    "    p.add_layout(xaxis, 'below')\n",
    "    \n",
    "    #Set y-axis layout parameters:\n",
    "    yaxis = LinearAxis()\n",
    "    p.add_layout(yaxis, 'left')\n",
    "    \n",
    "    #Add Bokeh Grid:\n",
    "    p.add_layout(Grid(dimension=0, ticker=xaxis.ticker))\n",
    "    p.add_layout(Grid(dimension=1, ticker=yaxis.ticker))\n",
    "    \n",
    "    #Create hover-tool:\n",
    "    p.add_tools(HoverTool(names=[\"image\"],\n",
    "                          tooltips=[(\"cell partition\", \"@image{0.00}\"),\n",
    "                                    (\"lat\", \"$y\"),\n",
    "                                    (\"lon\", \"$x\")]))\n",
    "    \n",
    "    #Deactivate hover-tool, which is by default active:\n",
    "    p.toolbar.active_inspect = None\n",
    "\n",
    "    #Show plot:\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Country Masks - Widget Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create widget-form:\n",
    "def cmask_widget_form():\n",
    "    \n",
    "    #Get shapefile from Natural Earth (10m resolution) with country boundaries:\n",
    "    shapefile = path_geo_natural_earth10m+'ne_10m_admin_0_countries.shp'\n",
    "    \n",
    "    #Read shapefile to Geopandas DataFrame:\n",
    "    gdf = gpd.read_file(shapefile)[['ADMIN', 'ADM0_A3', 'CONTINENT','geometry']]\n",
    "    \n",
    "    #Extract polygons for European countries and Turkey:\n",
    "    countries_map = gdf.loc[(gdf.CONTINENT==\"Europe\") | (gdf.ADMIN==\"Turkey\")| (gdf.ADMIN==\"Cyprus\")]\n",
    "\n",
    "    #Rename columns:\n",
    "    countries_map.columns = ['country', 'country_code', 'continent','geometry']\n",
    "    \n",
    "    \n",
    "    #Get the country name for all EEZ country-masks:\n",
    "    eez_cname_array = get_cmask_cname(path_masks + 'eurocomCountryMaskEEZ_0.5x0.5.nc')\n",
    "\n",
    "    #Create a list of tuples like ('Sweden', 47) --- >(cname, ind_num) for EEZ cmasks\n",
    "    eez_cname_ls = [(eez_cname_array[i], i) for i in range(len(eez_cname_array))]\n",
    "\n",
    "    #Get the country name for all country-masks:\n",
    "    cname_array = get_cmask_cname(path_masks  + 'eurocomCountryMask_0.5x0.5.nc')\n",
    "\n",
    "    #Create a list of tuples like ('Sweden', 47) --- >(cname, ind_num)\n",
    "    cname_ls = [(cname_array[i], i) for i in range(len(cname_array))]\n",
    "\n",
    "    cnames_ls = sorted([(cname_ls[i][0], [eez_cname_ls[j][1], i])\n",
    "                 for i in range(len(cname_ls))\n",
    "                 for j in range(len(eez_cname_ls))\n",
    "                 if cname_ls[i][0]==eez_cname_ls[j][0]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Add dropdown list for the selection of country:\n",
    "    countries = Dropdown(options=cnames_ls,\n",
    "                         layout={'width': 'max-content'},\n",
    "                         description='Country:',\n",
    "                         style={'description_width': 'initial'},\n",
    "                         disabled=False)\n",
    "\n",
    "    #Add dropdown list for the selection of country mask:\n",
    "    cmasks = Dropdown(options=['No EEZ', 'EEZ'],\n",
    "                      layout={'width': 'max-content'},\n",
    "                      description='Country mask:',\n",
    "                      style={'description_width': 'initial'},\n",
    "                      disabled=False)\n",
    "\n",
    "    #Add dropdown for selection of different grid resolutions:\n",
    "    cresolutions = Dropdown(options=['0.1', '0.5'],\n",
    "                            #layout={'width': 'max-content'},\n",
    "                            description='Mask-resolution (in degrees):',\n",
    "                            style={'description_width': 'initial'},\n",
    "                            disabled=False)\n",
    "\n",
    "    #Create a Button-widget to control execution:\n",
    "    exe_button = Button(description='Run',\n",
    "                        disabled=False,\n",
    "                        button_style='danger',\n",
    "                        tooltip='Click me')\n",
    "\n",
    "\n",
    "    #Add the widgets for \"cmasks\", countries\" and \"country mask resolutions\" to a VBox:\n",
    "    country_box = VBox([cmasks, countries, cresolutions])\n",
    "\n",
    "    #Store country_box and button in a VBox (final widget-form):\n",
    "    form = VBox([country_box, exe_button])\n",
    "\n",
    "    #Initialize form output:\n",
    "    form_out = Output()\n",
    "\n",
    "    #Initialize results output:\n",
    "    results_out = Output()\n",
    "\n",
    "\n",
    "    #Define update function:\n",
    "    def update_func(button_c):\n",
    "\n",
    "\n",
    "        #Check choice of country mask type:\n",
    "        if(cmasks.value == 'EEZ'):\n",
    "\n",
    "            #Construct path to cmask:\n",
    "            pathtocmask=path_masks + 'eurocomCountryMaskEEZ_'+cresolutions.value+'x'+cresolutions.value+'.nc'\n",
    "\n",
    "            #Get country index:\n",
    "            c_ind = countries.value[0]\n",
    "\n",
    "\n",
    "        #if cmaks.value=='No EEZ'    \n",
    "        else:\n",
    "\n",
    "            #Construct path to cmask:\n",
    "            pathtocmask=path_masks + 'eurocomCountryMask_'+cresolutions.value+'x'+cresolutions.value+'.nc'\n",
    "\n",
    "            #Get country index:\n",
    "            c_ind = countries.value[1]\n",
    "\n",
    "\n",
    "        #Get cmask-data from netcdf:\n",
    "        lon, lat, cMask, cCode, cName = read_country_masks(pathtocmask)\n",
    "\n",
    "\n",
    "        #Open output object:\n",
    "        with results_out:\n",
    "\n",
    "            #Clear previous results:\n",
    "            clear_output()     \n",
    "\n",
    "            #plot_cmask(worldmap, cMask, countries.value)\n",
    "            plot_cmask(countries_map, cMask, c_ind)\n",
    "\n",
    "\n",
    "    #Call update-function when button is clicked:\n",
    "    exe_button.on_click(update_func)\n",
    "\n",
    "    #Set font of all widgets in the form:\n",
    "    exe_button.style.button_color = '#1f78b4'\n",
    "    exe_button.layout.margin = '50px 100px 40px 290px' #top, right, bottom, left\n",
    "    country_box.layout.margin = '25px 0px 0px 65px'\n",
    "    form.layout.margin = '25px 0px 0px 0px'\n",
    "    countries.layout.margin = '0px 0px 0px 36px'\n",
    "    countries.layout.width = '300px'\n",
    "    cmasks.layout.width = '335px'\n",
    "    cmasks.layout.margin = '0px 0px 5px 85px'\n",
    "    countries.layout.margin = '0px 0px 5px 120px'\n",
    "    cresolutions.layout.width = '418px'\n",
    "    form.layout.margin = '0px 0px 0px 110px'\n",
    "\n",
    "    \n",
    "    #Open form object:\n",
    "    with form_out:\n",
    "\n",
    "        #Clear previous selections in form:\n",
    "        clear_output()\n",
    "\n",
    "        #Display form and results:\n",
    "        display(form, results_out)\n",
    "\n",
    "\n",
    "    #Display form:\n",
    "    display(form_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_table(table_list, table_names=[]):\n",
    "    \"\"\" Accept a list of Pandas Dataframes                 \n",
    "        returns an HTML table where the data frames are side by side\n",
    "        if table_names are provided add additional row with names\n",
    "    \"\"\"\n",
    "    if len(table_list)==len(table_names):\n",
    "        th = '<tr>'+ ''.join(['<th style=\"text-align:left; border:1px solid grey\">' + name + '</th>' for name in table_names]) + '</tr>'        \n",
    "    else:\n",
    "        th = ''\n",
    "                \n",
    "    return HTML(\n",
    "        '<table style=\"border:1px solid black\"><tr style=\"background-color:white\">' + th +\n",
    "        ''.join(['<td style=\"border:1px solid grey\">' + table.to_html() + '</td>' for table in table_list]) +\n",
    "        '</tr></table>'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmission(country, unit):\n",
    "    e = []\n",
    "    e.append(df_grid01[unit][df_grid01['c_code'] == country].iloc[0])\n",
    "    e.append(df_grid01EEZ[unit][df_grid01EEZ['c_code'] == country].iloc[0])\n",
    "    e.append(df_grid05[unit][df_grid05['c_code'] == country].iloc[0])\n",
    "    e.append(df_grid05EEZ[unit][df_grid05EEZ['c_code'] == country].iloc[0])\n",
    "    return e \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmissions(df, country, unit):\n",
    "    e = []\n",
    "    for d in df:\n",
    "        e.append(d[unit][d['c_code'] == country].iloc[0])\n",
    "    return e \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stclass'></a>\n",
    "\n",
    "\n",
    "# Station class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Station():\n",
    "    \n",
    "    '''\n",
    "    Description: Class that represents \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, station_code, eco_var_name=''):\n",
    "        \n",
    "        self._code = station_code\n",
    "        self._eco_var = eco_var_name\n",
    "        self.info = None\n",
    "        self._latitude = None\n",
    "        self._longitude = None\n",
    "        self._lpj = None\n",
    "        self._lpjmap = None\n",
    "        self._fluxnet = None\n",
    "        self._lumia = None      \n",
    "        \n",
    "        self.read_info()\n",
    "    \n",
    "    def read_info(self):\n",
    "        self.info = stations_dict[self.code]\n",
    "    \n",
    "    @property\n",
    "    def code(self):\n",
    "        return self._code\n",
    "    \n",
    "    @property\n",
    "    def eco_var_name(self):\n",
    "        return self._eco_var\n",
    "    \n",
    "    @eco_var_name.setter\n",
    "    def eco_var_name(self, eco_var_name):\n",
    "        self._eco_var=eco_var_name \n",
    "    \n",
    "    @property\n",
    "    def lat(self):\n",
    "        return self.info[4]\n",
    "    \n",
    "    @property\n",
    "    def lon(self):\n",
    "        return self.info[5]  \n",
    "    \n",
    "    @property\n",
    "    def lpj(self):\n",
    "        return self._lpj\n",
    "    \n",
    "    @lpj.setter\n",
    "    def lpj(self, data):\n",
    "        self._lpj=data\n",
    "     \n",
    "    @property\n",
    "    def fluxnet(self):\n",
    "        return self._fluxnet\n",
    "    \n",
    "    @fluxnet.setter\n",
    "    def fluxnet(self, data):\n",
    "        self._fluxnet=data\n",
    "        \n",
    "    @property\n",
    "    def lpjmap(self):\n",
    "        return self._lpjmap\n",
    "    \n",
    "    @lpjmap.setter\n",
    "    def lpjmap(self, data):\n",
    "        self._lpjmap=data\n",
    "    \n",
    "    @property\n",
    "    def lumia(self):\n",
    "        return self._lumia\n",
    "    \n",
    "    @lumia.setter\n",
    "    def lumia(self, data):\n",
    "        self._lumia=data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"../ancillarydata/logos/sponsors_climbeco_course_2020.PNG\" width=\"1000\" align=\"left\"/>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
