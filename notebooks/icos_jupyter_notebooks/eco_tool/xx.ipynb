{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4337c4cb-5d4a-4afc-a73b-26f5fd6c1914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdaae98537e46f2b21cd36d05e3a52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(button_style='success', icons=('area-chart', 'list', 'info-circle'), index=1, opt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pi.gui.AnalysisGui at 0x2e270e87af0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "from pi import gui\n",
    "\n",
    "\n",
    "gui.AnalysisGui() #debug = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "086cb999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\dashboard\\lib\\site-packages\\icoscp\\cpauth\\exceptions.py:53: UserWarning: \n",
      "Your authentication at the ICOS Carbon Portal was unsuccessful due to: Incorrect user name or password.\n",
      "Falling back to anonymous data access. Please, revisit your authentication configuration\n",
      "(https://icos-carbon-portal.github.io/pylib/modules/#authentication).\n",
      "Authentication will become mandatory (icoscp >= 0.1.19) for external users.\n",
      "  warnings.warn(warning, category=UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ETC NRT Fluxes'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = s.get_ts(pid = pid_ls[0])\n",
    "d = IcosFrame.trim_icos_meta(df.icos_meta)\n",
    "d['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fdc4e29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m icos2latex\n\u001b[0;32m      3\u001b[0m t \u001b[38;5;241m=\u001b[39m icos2latex\u001b[38;5;241m.\u001b[39mTranslator()\n\u001b[1;32m----> 4\u001b[0m t\u001b[38;5;241m.\u001b[39mvar_unit_to_latex (\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39micos_var_unit_ls)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from pi import icos2latex\n",
    "\n",
    "t = icos2latex.Translator()\n",
    "t.var_unit_to_latex (df.icos_var_unit_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be2e33-99c6-41d1-a27d-1abf82e1978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gui.AnalysisGui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892e065a-8cbb-4817-ab59-d8028bbd42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pi import icos_data\n",
    "from pi.icos_timeseries import IcosFrame\n",
    "from icoscp.cpb.dobj import Dobj\n",
    "s = icos_data.StationData()\n",
    "df = s.stations_df\n",
    "\n",
    "pid_ls = list(df.dobj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1ef8996-9087-4576-aaa4-6d40191754f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = 'CO2'\n",
    "v2 = 'H'\n",
    "v3 = 'H2O'\n",
    "var_tuple_ls = [(v1, pid_ls[0]),(v2, pid_ls[3]), (v3, pid_ls[6]),(v2, pid_ls[0]),(v3, pid_ls[3]), (v1, pid_ls[6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62f7d2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\dashboard\\lib\\site-packages\\icoscp\\cpauth\\exceptions.py:53: UserWarning: \n",
      "Your authentication at the ICOS Carbon Portal was unsuccessful due to: Incorrect user name or password.\n",
      "Falling back to anonymous data access. Please, revisit your authentication configuration\n",
      "(https://icos-carbon-portal.github.io/pylib/modules/#authentication).\n",
      "Authentication will become mandatory (icoscp >= 0.1.19) for external users.\n",
      "  warnings.warn(warning, category=UserWarning)\n",
      "C:\\Users\\Anders Dahlner\\AppData\\Local\\Temp\\ipykernel_18496\\2678681666.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={v1:f'{x}_{v1}', v2:f'{x}_{v2}'}, inplace=True)\n",
      "C:\\Miniconda3\\envs\\dashboard\\lib\\site-packages\\icoscp\\cpauth\\exceptions.py:53: UserWarning: \n",
      "Your authentication at the ICOS Carbon Portal was unsuccessful due to: Incorrect user name or password.\n",
      "Falling back to anonymous data access. Please, revisit your authentication configuration\n",
      "(https://icos-carbon-portal.github.io/pylib/modules/#authentication).\n",
      "Authentication will become mandatory (icoscp >= 0.1.19) for external users.\n",
      "  warnings.warn(warning, category=UserWarning)\n",
      "C:\\Users\\Anders Dahlner\\AppData\\Local\\Temp\\ipykernel_18496\\2678681666.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={v1:f'{x}_{v1}', v2:f'{x}_{v2}'}, inplace=True)\n",
      "C:\\Miniconda3\\envs\\dashboard\\lib\\site-packages\\icoscp\\cpauth\\exceptions.py:53: UserWarning: \n",
      "Your authentication at the ICOS Carbon Portal was unsuccessful due to: Incorrect user name or password.\n",
      "Falling back to anonymous data access. Please, revisit your authentication configuration\n",
      "(https://icos-carbon-portal.github.io/pylib/modules/#authentication).\n",
      "Authentication will become mandatory (icoscp >= 0.1.19) for external users.\n",
      "  warnings.warn(warning, category=UserWarning)\n",
      "C:\\Users\\Anders Dahlner\\AppData\\Local\\Temp\\ipykernel_18496\\2678681666.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={v1:f'{x}_{v1}', v2:f'{x}_{v2}'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_CO2</th>\n",
       "      <th>0_H</th>\n",
       "      <th>1_CO2</th>\n",
       "      <th>1_H</th>\n",
       "      <th>2_CO2</th>\n",
       "      <th>2_H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-17 23:30:00</th>\n",
       "      <td>401.269989</td>\n",
       "      <td>-53.040001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 00:00:00</th>\n",
       "      <td>400.920013</td>\n",
       "      <td>-65.230003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 00:30:00</th>\n",
       "      <td>400.899994</td>\n",
       "      <td>-68.080002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 01:00:00</th>\n",
       "      <td>400.980011</td>\n",
       "      <td>-43.720001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 01:30:00</th>\n",
       "      <td>400.529999</td>\n",
       "      <td>-43.669998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 21:00:00</th>\n",
       "      <td>427.600006</td>\n",
       "      <td>-21.160000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 21:30:00</th>\n",
       "      <td>427.429993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.130005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 22:00:00</th>\n",
       "      <td>427.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.630005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 22:30:00</th>\n",
       "      <td>428.440002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.920013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 23:00:00</th>\n",
       "      <td>427.579987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.480011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14544 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0_CO2        0_H  1_CO2  1_H       2_CO2  2_H\n",
       "TIMESTAMP                                                              \n",
       "2022-05-17 23:30:00  401.269989 -53.040001    NaN  NaN         NaN  NaN\n",
       "2022-05-18 00:00:00  400.920013 -65.230003    NaN  NaN         NaN  NaN\n",
       "2022-05-18 00:30:00  400.899994 -68.080002    NaN  NaN         NaN  NaN\n",
       "2022-05-18 01:00:00  400.980011 -43.720001    NaN  NaN         NaN  NaN\n",
       "2022-05-18 01:30:00  400.529999 -43.669998    NaN  NaN         NaN  NaN\n",
       "...                         ...        ...    ...  ...         ...  ...\n",
       "2023-03-16 21:00:00  427.600006 -21.160000    NaN  NaN  416.250000  NaN\n",
       "2023-03-16 21:30:00  427.429993        NaN    NaN  NaN  417.130005  NaN\n",
       "2023-03-16 22:00:00  427.600006        NaN    NaN  NaN  417.630005  NaN\n",
       "2023-03-16 22:30:00  428.440002        NaN    NaN  NaN  417.920013  NaN\n",
       "2023-03-16 23:00:00  427.579987        NaN    NaN  NaN  418.480011  NaN\n",
       "\n",
       "[14544 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m = None\n",
    "for x in range(3):\n",
    "    do = Dobj(pid_ls[3*x])\n",
    "    df = do.data[[v1,v2, 'TIMESTAMP']]\n",
    "    df.rename(columns={v1:f'{x}_{v1}', v2:f'{x}_{v2}'}, inplace=True)\n",
    "    if df_m is None:\n",
    "        df_m = df\n",
    "    else:\n",
    "        df_m = df_m.merge(df,how='outer')\n",
    "df_m.set_index(keys ='TIMESTAMP', inplace=True)    \n",
    "columns = df_m.columns\n",
    "# do1 = Dobj(pid_ls[6])\n",
    "# df = do.data[[v1,v2, 'TIMESTAMP']]\n",
    "# df1 = do1.data[[v3,v2, 'TIMESTAMP']]\n",
    "\n",
    "# df2 = df.copy()\n",
    "# df.rename(columns={v1:'111',v2:'222'}, inplace=True)\n",
    "# df\n",
    "# df2\n",
    "# df = df.merge(df2, how='outer')\n",
    "# df3 = df.merge(df1, how='outer')\n",
    "# df1.rename(columns = {v3:'v3', v2:'v2'}, inplace = True)\n",
    "# df4 = df.merge(df1, how='outer')\n",
    "# df3, df4\n",
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccca1605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_CO2</th>\n",
       "      <th>0_H</th>\n",
       "      <th>2_CO2</th>\n",
       "      <th>0_CO2</th>\n",
       "      <th>2_H</th>\n",
       "      <th>1_H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-17 23:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-53.040001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>401.269989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-65.230003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.920013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 00:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-68.080002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.899994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 01:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-43.720001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.980011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 01:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-43.669998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.529999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 21:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.160000</td>\n",
       "      <td>416.250000</td>\n",
       "      <td>427.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 21:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.130005</td>\n",
       "      <td>427.429993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 22:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.630005</td>\n",
       "      <td>427.600006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 22:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.920013</td>\n",
       "      <td>428.440002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 23:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.480011</td>\n",
       "      <td>427.579987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14544 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1_CO2        0_H       2_CO2       0_CO2  2_H  1_H\n",
       "TIMESTAMP                                                              \n",
       "2022-05-17 23:30:00    NaN -53.040001         NaN  401.269989  NaN  NaN\n",
       "2022-05-18 00:00:00    NaN -65.230003         NaN  400.920013  NaN  NaN\n",
       "2022-05-18 00:30:00    NaN -68.080002         NaN  400.899994  NaN  NaN\n",
       "2022-05-18 01:00:00    NaN -43.720001         NaN  400.980011  NaN  NaN\n",
       "2022-05-18 01:30:00    NaN -43.669998         NaN  400.529999  NaN  NaN\n",
       "...                    ...        ...         ...         ...  ...  ...\n",
       "2023-03-16 21:00:00    NaN -21.160000  416.250000  427.600006  NaN  NaN\n",
       "2023-03-16 21:30:00    NaN        NaN  417.130005  427.429993  NaN  NaN\n",
       "2023-03-16 22:00:00    NaN        NaN  417.630005  427.600006  NaN  NaN\n",
       "2023-03-16 22:30:00    NaN        NaN  417.920013  428.440002  NaN  NaN\n",
       "2023-03-16 23:00:00    NaN        NaN  418.480011  427.579987  NaN  NaN\n",
       "\n",
       "[14544 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df_m.columns\n",
    "cols2 = [cols[j] for j in [2,1,4,0,5,3]]\n",
    "#df_m = df_m[cols2]\n",
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3883c015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CO2', 'SE-Sto_CO2'), ('H', 'SE-Sto_H')]\n",
      "('CO2', 'SE-Sto_CO2') ('H', 'SE-Sto_H')\n",
      "['CO2', 'H']\n",
      "[0, 3]\n",
      "[(0, 'CO2', ('CO2', 'SE-Sto_CO2')), (3, 'H', ('H', 'SE-Sto_H'))] \n",
      "\n",
      "[('H', 'UK-AMo_H'), ('H2O', 'UK-AMo_H2O')]\n",
      "('H', 'UK-AMo_H') ('H2O', 'UK-AMo_H2O')\n",
      "['H', 'H2O']\n",
      "[1, 4]\n",
      "[(1, 'H', ('H', 'UK-AMo_H')), (4, 'H2O', ('H2O', 'UK-AMo_H2O'))] \n",
      "\n",
      "[('H2O', 'FR-Bil_H2O'), ('CO2', 'FR-Bil_CO2')]\n",
      "('H2O', 'FR-Bil_H2O') ('CO2', 'FR-Bil_CO2')\n",
      "['H2O', 'CO2']\n",
      "[2, 5]\n",
      "[(2, 'H2O', ('H2O', 'FR-Bil_H2O')), (5, 'CO2', ('CO2', 'FR-Bil_CO2'))] \n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(ind,cols,col_names)),\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m ls\n\u001b[1;32m---> 28\u001b[0m ls2 \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m d[p][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()  \u001b[38;5;28;01mif\u001b[39;00m d[p][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcols\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;241m==\u001b[39m k ]\n",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(ind,cols,col_names)),\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m ls\n\u001b[1;32m---> 28\u001b[0m ls2 \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m d[p][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()  \u001b[38;5;28;01mif\u001b[39;00m \u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcols\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m k ]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "d = {'https://meta.icos-cp.eu/objects/QLk2MGR5Zv_KPmN07Z0ZNSHe': \n",
    "     {'cols': ['CO2', 'H'], \n",
    "     'index': [0, 3], 'dobj': 1, 'product': 'ETC NRT Fluxes', 'stn_id': 'SE-Sto', \n",
    "      'columns': {'CO2': 'SE-Sto_CO2', 'H': 'SE-Sto_H'}}, \n",
    "     'https://meta.icos-cp.eu/objects/StAoU7ciukup4HmijO4J92sV': \n",
    "     {'cols': ['H', 'H2O'], 'index': [1, 4], 'dobj': 33, \n",
    "       'product': 'ETC NRT Fluxes', 'stn_id': 'UK-AMo', \n",
    "      'columns': {'H': 'UK-AMo_H', 'H2O': 'UK-AMo_H2O'}}, \n",
    "     'https://meta.icos-cp.eu/objects/9ISyDWIvPhNwbFGaqp6rwSP3': \n",
    "     {'cols': ['H2O', 'CO2'], 'index': [2, 5], 'dobj': 2, 'product': \n",
    "      'ETC NRT Fluxes', 'stn_id': 'FR-Bil', 'columns': {'H2O': 'FR-Bil_H2O', 'CO2': 'FR-Bil_CO2'}}}\n",
    "\n",
    "dd = {}\n",
    "ls = [ c for j,c in d[k]['columns'].items() for k in d.keys()]\n",
    "\n",
    "for k in d.keys():\n",
    "    \n",
    "    col_names = [x for x in d[k]['columns'].items()]\n",
    "    cols = d[k]['cols']\n",
    "    ind = d[k]['index']\n",
    "    print(col_names)\n",
    "    print(*col_names)\n",
    "    print(cols)\n",
    "    print(ind)\n",
    "    print(list(zip(ind,cols,col_names)),'\\n')\n",
    "    \n",
    "ls\n",
    "for i in [0,1,2,3,4,5]:\n",
    "    ls2 = [v for p in d.keys() for i in [0,1,2,3,4,5] for k, v in d[p]['columns'].items()  if d[p]['cols'][i] == k ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efc2852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\dashboard\\lib\\site-packages\\icoscp\\cpauth\\exceptions.py:53: UserWarning: \n",
      "Your authentication at the ICOS Carbon Portal was unsuccessful due to: Incorrect user name or password.\n",
      "Falling back to anonymous data access. Please, revisit your authentication configuration\n",
      "(https://icos-carbon-portal.github.io/pylib/modules/#authentication).\n",
      "Authentication will become mandatory (icoscp >= 0.1.19) for external users.\n",
      "  warnings.warn(warning, category=UserWarning)\n",
      "C:\\Users\\Anders Dahlner\\AppData\\Local\\Temp\\ipykernel_18496\\929280048.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns=order_dict[p]['columns'], inplace=True)\n",
      "C:\\Miniconda3\\envs\\dashboard\\lib\\site-packages\\icoscp\\cpauth\\exceptions.py:53: UserWarning: \n",
      "Your authentication at the ICOS Carbon Portal was unsuccessful due to: Incorrect user name or password.\n",
      "Falling back to anonymous data access. Please, revisit your authentication configuration\n",
      "(https://icos-carbon-portal.github.io/pylib/modules/#authentication).\n",
      "Authentication will become mandatory (icoscp >= 0.1.19) for external users.\n",
      "  warnings.warn(warning, category=UserWarning)\n",
      "C:\\Users\\Anders Dahlner\\AppData\\Local\\Temp\\ipykernel_18496\\929280048.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns=order_dict[p]['columns'], inplace=True)\n",
      "C:\\Miniconda3\\envs\\dashboard\\lib\\site-packages\\icoscp\\cpauth\\exceptions.py:53: UserWarning: \n",
      "Your authentication at the ICOS Carbon Portal was unsuccessful due to: Incorrect user name or password.\n",
      "Falling back to anonymous data access. Please, revisit your authentication configuration\n",
      "(https://icos-carbon-portal.github.io/pylib/modules/#authentication).\n",
      "Authentication will become mandatory (icoscp >= 0.1.19) for external users.\n",
      "  warnings.warn(warning, category=UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://meta.icos-cp.eu/objects/QLk2MGR5Zv_KPmN07Z0ZNSHe': {'cols': ['CO2', 'H'], 'index': [0, 3], 'dobj': <icoscp.cpb.dobj.Dobj object at 0x000001EEF77286D0>, 'product': 'ETC NRT Fluxes', 'stn_id': 'SE-Sto', 'columns': {'CO2': 'SE-Sto_CO2', 'H': 'SE-Sto_H'}}, 'https://meta.icos-cp.eu/objects/StAoU7ciukup4HmijO4J92sV': {'cols': ['H', 'H2O'], 'index': [1, 4], 'dobj': <icoscp.cpb.dobj.Dobj object at 0x000001EEF6C793D0>, 'product': 'ETC NRT Fluxes', 'stn_id': 'UK-AMo', 'columns': {'H': 'UK-AMo_H', 'H2O': 'UK-AMo_H2O'}}, 'https://meta.icos-cp.eu/objects/9ISyDWIvPhNwbFGaqp6rwSP3': {'cols': ['H2O', 'CO2'], 'index': [2, 5], 'dobj': <icoscp.cpb.dobj.Dobj object at 0x000001EEF7728880>, 'product': 'ETC NRT Fluxes', 'stn_id': 'FR-Bil', 'columns': {'H2O': 'FR-Bil_H2O', 'CO2': 'FR-Bil_CO2'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anders Dahlner\\AppData\\Local\\Temp\\ipykernel_18496\\929280048.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns=order_dict[p]['columns'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "group_ts(var_tuple_ls=var_tuple_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43d61b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'               col_meta_ls = do.meta[\\'specificInfo\\'][\\n                    \\'columns\\'] if \\'specificInfo\\' in do.meta.keys() and \\'columns\\' in                                   do.meta[\\'specificInfo\\'] else None\\n\\n                var_meta = {}\\n                for v in var_ls:\\n                    for col in col_meta_ls:\\n                        if col[\\'label\\'] == v:\\n                            var_meta[v] = {}\\n                            try:\\n                                var_meta[v][\\'unit\\'] = col[\\'valueType\\'][\\'unit\\']\\n                            except:\\n                                var_meta[v][\\'unit\\'] = \\'No unit\\'\\n                            try:\\n                                label = col[\\'valueType\\'][\\'quantityKind\\'][\\n                                    \\'label\\']\\n                                var_meta[v][\\'label\\'] = label[\\n                                                           0].upper() + label[\\n                                                                        1:]\\n                            except:\\n                                var_meta[v][\\'label\\'] = \\'\\'\\n                data_dict[stn][spec][\\'meta\\'] = var_meta\\n\\n        # Rename columns if there are stations or products involved\\n        # Are the more than 1 station?\\n        if len(data_dict.keys()) > 1:\\n            for stn in data_dict.keys():\\n                stn_short = data_dict[stn][\\'id\\']\\n\\n                # are there more than one speces?\\n                if len(data_dict[stn].keys()) > 2:\\n                    for spec in data_dict[stn]:\\n                        if spec != \\'id\\':\\n                            spec_short = spec.split(\\' \\')[-1]\\n\\n                            new_col_names = {\\n                                var: f\\'{stn_short}_{spec_short}_{var}\\'\\n                                for var in data_dict[stn][spec][\\'vars\\']\\n                                if var != \\'TIMESTAMP\\'}\\n                            # new_col_names[\\'TIMESTAMP\\'] = \\'TIMESTAMP\\'\\n\\n                            df = data_dict[stn][spec][\\'data\\']\\n                            data_dict[stn][spec][\\'data\\'] = df.rename(\\n                                columns=new_col_names)\\n\\n                else:\\n                    for spec in data_dict[stn]:\\n                        if spec != \\'id\\':\\n                            new_col_names = {var: f\\'{stn_short}_{var}\\'\\n                                             for var in\\n                                             data_dict[stn][spec][\\'vars\\']\\n                                             if var != \\'TIMESTAMP\\'}\\n                            # \"new_col_names[\\'TIMESTAMP\\'] = \\'TIMESTAMP\\'\\n\\n                            df = data_dict[stn][spec][\\'data\\']\\n                            data_dict[stn][spec][\\'data\\'] = df.rename(\\n                                columns=new_col_names)\\n        else:\\n            for stn in data_dict.keys():\\n                # are there more than one speces?\\n                if len(data_dict[stn].keys()) > 2:\\n                    for spec in data_dict[stn]:\\n                        if spec != \\'id\\':\\n                            spec_short = spec.split(\\' \\')[-1]\\n                            new_col_names = {var: f\\'{spec_short}_{var}\\'\\n                                             for var in\\n                                             data_dict[stn][spec][\\'vars\\']\\n                                             if var != \\'TIMESTAMP\\'}\\n\\n                            df = data_dict[stn][spec][\\'data\\']\\n                            data_dict[stn][spec][\\'data\\'] = df.rename(\\n                                columns=new_col_names)\\n\\n        return data_dict\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_ts(var_tuple_ls: list = None, **kwargs) -> IcosFrame:\n",
    "    \"\"\"\n",
    "    Returns a pandas dataframe df with an ICOS timeseries\n",
    "    and attached metadata (an instance of IcosFrame which\n",
    "    inherits pandas dataframe). In case there are more than\n",
    "    one matching products, the latest will be returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    var_tuple_ls a list of tuples\n",
    "        each tuple in the list is assumed to be of the form\n",
    "            (<variable>, <pid>)\n",
    "        where the <variable> belongs to the ICOS product/file with pid <pid>\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    IcosFrame (see above)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Before we merge the data we need to take care of the order of the variables\n",
    "    order_dict = {}\n",
    "    for i in range(len(var_tuple_ls)):\n",
    "        v, p = var_tuple_ls[i]\n",
    "        if p in order_dict.keys():\n",
    "            order_dict[p]['cols'].append(v)\n",
    "            order_dict[p]['index'].append(i)\n",
    "        else:\n",
    "            order_dict[p]  = {'cols': [v], 'index': [i], 'dobj': Dobj(p)}\n",
    "    \n",
    "    # 2. We might also have to rename duplicate variables.\n",
    "    products = set()\n",
    "    stations = set()\n",
    "    if len(order_dict.keys()) > 1: \n",
    "        # in this case we will rename columns\n",
    "        for p in order_dict.keys():            \n",
    "            p_meta = IcosFrame.trim_icos_meta(order_dict[p]['dobj'].meta)\n",
    "            products.add(p_meta['product'])\n",
    "            stations.add(p_meta['stationId'])\n",
    "            order_dict[p]['product'] = p_meta['product']\n",
    "            order_dict[p]['stn_id'] = p_meta['stationId']\n",
    "    if len(products) > 1:\n",
    "        for p in order_dict.keys():\n",
    "            prod = order_dict[p]['product']\n",
    "            order_dict[p]['columns'] = {c: f'{prod}_{c}' for c in order_dict[p]['cols']}\n",
    "    if len(stations) > 1:\n",
    "        for p in order_dict.keys():\n",
    "            stn_id = order_dict[p]['stn_id']\n",
    "            if 'columns' in order_dict[p].keys():\n",
    "                order_dict[p]['columns'] = {c: f'{stn_id}_{v}' for c, v in order_dict[p]['columns'].items()}\n",
    "            else:\n",
    "                order_dict[p]['columns'] = {c: f'{stn_id}_{c}' for c in order_dict[p]['cols']}\n",
    "    \n",
    "    # 3. Gather data.\n",
    "    df_m = None\n",
    "    for p in order_dict.keys():\n",
    "        do = order_dict[p]['dobj']\n",
    "        col_ls = order_dict[p]['cols']\n",
    "        df = do.data[col_ls]\n",
    "        if 'columns' in order_dict[p].keys():\n",
    "            df.rename(columns=order_dict[p]['columns'], inplace=True)\n",
    "        if df_m is None:\n",
    "            df_m = df\n",
    "        else:\n",
    "            df_m = df_m.merge(df, how = 'outer')\n",
    "        \n",
    "    df_m.set_index(keys ='TIMESTAMP', inplace=True)\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "    print(order_dict)         \n",
    "    \n",
    "    \n",
    "#     stations = {x[2] for x in var_tuple_ls}\n",
    "#     st_df = self.stations_df\n",
    "\n",
    "#     data_dict = {}\n",
    "#     for st_id in stations:\n",
    "#         data_dict[st_id] = {}\n",
    "#         data_dict[st_id]['st_name'] = st_df.loc[(st_df.id ==\n",
    "#                                                  st_id)].name.values[0]\n",
    "#         files = {x[1] for x in var_tuple_ls if x[2] == st_id}\n",
    "#         for spec in files:\n",
    "#             data_dict[st_id][spec] = {}\n",
    "#             pid = st_df.loc[(st_df.id == st_id) & (\n",
    "#                     st_df.specLabel == spec)].dobj.values[0]\n",
    "\n",
    "#             # variables of pid\n",
    "#             var_ls = [x[0] for x in var_tuple_ls if\n",
    "#                       x[2] == st_id and x[1] == spec]\n",
    "#             data_dict[st_id][spec]['vars'] = var_ls\n",
    "\n",
    "#             df = self.get_ts(pid=pid, col_ls=var_ls)\n",
    "#             #do = Dobj(pid)\n",
    "#             #df = do.data\n",
    "#             #cols = var_ls\n",
    "#             #if 'TIMESTAMP' not in var_ls:\n",
    "#             #    cols.append('TIMESTAMP')\n",
    "\n",
    "#             data_dict[st_id][spec]['data'] = df   #df[cols]\n",
    "\n",
    "#     return data_dict\n",
    "\n",
    "\"\"\"               col_meta_ls = do.meta['specificInfo'][\n",
    "                    'columns'] if 'specificInfo' in do.meta.keys() and 'columns' in \\\n",
    "                                  do.meta['specificInfo'] else None\n",
    "\n",
    "                var_meta = {}\n",
    "                for v in var_ls:\n",
    "                    for col in col_meta_ls:\n",
    "                        if col['label'] == v:\n",
    "                            var_meta[v] = {}\n",
    "                            try:\n",
    "                                var_meta[v]['unit'] = col['valueType']['unit']\n",
    "                            except:\n",
    "                                var_meta[v]['unit'] = 'No unit'\n",
    "                            try:\n",
    "                                label = col['valueType']['quantityKind'][\n",
    "                                    'label']\n",
    "                                var_meta[v]['label'] = label[\n",
    "                                                           0].upper() + label[\n",
    "                                                                        1:]\n",
    "                            except:\n",
    "                                var_meta[v]['label'] = ''\n",
    "                data_dict[stn][spec]['meta'] = var_meta\n",
    "\n",
    "        # Rename columns if there are stations or products involved\n",
    "        # Are the more than 1 station?\n",
    "        if len(data_dict.keys()) > 1:\n",
    "            for stn in data_dict.keys():\n",
    "                stn_short = data_dict[stn]['id']\n",
    "\n",
    "                # are there more than one speces?\n",
    "                if len(data_dict[stn].keys()) > 2:\n",
    "                    for spec in data_dict[stn]:\n",
    "                        if spec != 'id':\n",
    "                            spec_short = spec.split(' ')[-1]\n",
    "\n",
    "                            new_col_names = {\n",
    "                                var: f'{stn_short}_{spec_short}_{var}'\n",
    "                                for var in data_dict[stn][spec]['vars']\n",
    "                                if var != 'TIMESTAMP'}\n",
    "                            # new_col_names['TIMESTAMP'] = 'TIMESTAMP'\n",
    "\n",
    "                            df = data_dict[stn][spec]['data']\n",
    "                            data_dict[stn][spec]['data'] = df.rename(\n",
    "                                columns=new_col_names)\n",
    "\n",
    "                else:\n",
    "                    for spec in data_dict[stn]:\n",
    "                        if spec != 'id':\n",
    "                            new_col_names = {var: f'{stn_short}_{var}'\n",
    "                                             for var in\n",
    "                                             data_dict[stn][spec]['vars']\n",
    "                                             if var != 'TIMESTAMP'}\n",
    "                            # \"new_col_names['TIMESTAMP'] = 'TIMESTAMP'\n",
    "\n",
    "                            df = data_dict[stn][spec]['data']\n",
    "                            data_dict[stn][spec]['data'] = df.rename(\n",
    "                                columns=new_col_names)\n",
    "        else:\n",
    "            for stn in data_dict.keys():\n",
    "                # are there more than one speces?\n",
    "                if len(data_dict[stn].keys()) > 2:\n",
    "                    for spec in data_dict[stn]:\n",
    "                        if spec != 'id':\n",
    "                            spec_short = spec.split(' ')[-1]\n",
    "                            new_col_names = {var: f'{spec_short}_{var}'\n",
    "                                             for var in\n",
    "                                             data_dict[stn][spec]['vars']\n",
    "                                             if var != 'TIMESTAMP'}\n",
    "\n",
    "                            df = data_dict[stn][spec]['data']\n",
    "                            data_dict[stn][spec]['data'] = df.rename(\n",
    "                                columns=new_col_names)\n",
    "\n",
    "        return data_dict\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86c8a13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set()\n",
    "a.add(8) #dir(a)\n",
    "a.add(8)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1aa65671",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "len(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1ed85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
