{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d91472a-fd22-47f5-aa06-e9ae5c334723",
   "metadata": {},
   "source": [
    "<img src='https://www.icos-cp.eu/sites/default/files/2017-11/ICOS_CP_logo.png' width=400 align=right>\n",
    "\n",
    "# ICOS Carbon Portal Python Libraries: icoscp_core\n",
    "\n",
    "This example uses a foundational library called `icoscp_core` which can be used to access time-series ICOS data that are <i>previewable</i> in the ICOS Data Portal. \"Previewable\" means that it is possible to visualize the data variables in the preview plot. The library can also be used to access (meta-)data from [ICOS Cities](http\n",
    "s://citydata.icos-cp.eu/portal/) and [SITES](https://data.fieldsites.se/portal/) data repositories. \n",
    "\n",
    "Documentation of the library, including information on running it locally, can be found on [PyPI.org](https://pypi.org/project/icoscp_core/).\n",
    "\n",
    "# Example: Access and work with atmospheric data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de460f0-1516-493f-8d79-12deded0fc0f",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb8e94-2b2c-48bf-8bde-60191e27a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icoscp_core.icos import data, meta, ATMO_STATION, ECO_STATION, OCEAN_STATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165704b-de55-4ae4-b8ce-c52781c63b65",
   "metadata": {},
   "source": [
    "### List stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c176133-d59f-4d59-a09f-cd922c2bb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations specific for the atmosphere domain (see example 1b and 1c for examples for the ecosystem and ocean domains) \n",
    "stations = meta.list_stations(ATMO_STATION)\n",
    "\n",
    "# Filter stations by country (e.g., Sweden, 'SE')\n",
    "country_code = 'SE'\n",
    "filtered_stations = [\n",
    "    s for s in stations\n",
    "    if s.country_code == country_code\n",
    "]\n",
    "\n",
    "# Display available stations in selected country for the atmospheric domain\n",
    "print(\"Available stations:\")\n",
    "for station in filtered_stations:\n",
    "    print(f\"Station ID: {station.id}, Name: {station.name}, URI: {station.uri}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fec332-1a46-4f25-b504-c72069a74cdc",
   "metadata": {},
   "source": [
    "### View metadata for a selected station \n",
    "\n",
    "The example shows how to access some of the metadata associated with the station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e605437-0d45-4433-adff-0929c01933a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a station uri from list above\n",
    "station_uri = 'http://meta.icos-cp.eu/resources/stations/AS_HTM'\n",
    "station_meta = meta.get_station_meta(station_uri)\n",
    "\n",
    "# Print the station name\n",
    "print('Name:', station_meta.org.name)\n",
    "\n",
    "print('Staff:')\n",
    "# Loop over all staff members and print their first name, last name, and email\n",
    "for staff_member in station_meta.staff:\n",
    "    first_name = staff_member.person.firstName\n",
    "    last_name = staff_member.person.lastName\n",
    "    email = staff_member.person.email\n",
    "    print(f\"{first_name} {last_name} ({email})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e082e-2f12-444f-85b9-33fa31dcc947",
   "metadata": {
    "tags": []
   },
   "source": [
    "### See a list of data types\n",
    "\n",
    "There are data types that in combination with the selected station make it possible to access specific data objects. In the example, filters are applied so that only data types associated with ICOS Level 2 data from the atmospheric domain that are previewable are shown. See more information [about data levels](https://www.icos-cp.eu/data-services/data-collection/data-levels-quality) here. Additional filters can be applied. Please refer to the documentation for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439711aa-fe18-481c-bf45-8b680ce87966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available datatypes\n",
    "data_types = meta.list_datatypes()\n",
    "\n",
    "# filters applied:\n",
    "# data types with data access (possible to view with Python)\n",
    "# data types with level 2 data\n",
    "# data types associated with stations from the atmospheric domain\n",
    "data_level = 2\n",
    "previewable_datatypes = [\n",
    "    dt for dt in data_types\n",
    "    if dt.has_data_access and dt.data_level==data_level and dt.theme.label == 'Atmospheric data'\n",
    "]\n",
    "\n",
    "for data_type in previewable_datatypes:\n",
    "    datatype_uri = data_type.uri\n",
    "    datatype_label = data_type.label\n",
    "    \n",
    "    print(f\"{datatype_label} ({datatype_uri})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fee990-be4e-40cf-9a5f-33e72d9aafab",
   "metadata": {},
   "source": [
    "### Find data objects based on the selected station and a specified data type\n",
    "\n",
    "This example shows how to get a list of data objects associated with the selected station and the data type \"ICOS ATC/CAL Flask Release\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f17fd-b918-4200-9f32-e527f9f0b2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify a data type from the list above \n",
    "data_type = 'http://meta.icos-cp.eu/resources/cpmeta/atcFlaskDataObject'\n",
    "\n",
    "station_data_objects = meta.list_data_objects(datatype = data_type, \n",
    "                                         station = station_uri)\n",
    "for station_data_object in station_data_objects:\n",
    "    station_object_filename = station_data_object.filename\n",
    "\n",
    "    print(station_object_filename)\n",
    "\n",
    "if len(station_data_objects) == 0:\n",
    "    print(f'No available objects with data type {data_type} at station {station_uri}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbda2ca-dc1e-41d2-b807-427c91dd3e69",
   "metadata": {},
   "source": [
    "### Access data for a single data object \n",
    "\n",
    "This example shows how to access the data and metadata from ICOS_ATC_L2_L2-2024.1_HTM_150.0_CTS_FLASK_CO2.zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af3541-a30e-4e22-aad4-259c391cc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a filename from the list above\n",
    "filename = 'ICOS_ATC_L2_L2-2024.1_HTM_150.0_CTS_FLASK_CO2.zip'\n",
    "selected_data_object = next((station_data_object for station_data_object in station_data_objects if station_data_object.filename == filename), None)\n",
    "\n",
    "if selected_data_object is not None:\n",
    "    # Access metadata associated with the object\n",
    "    dobj_meta = meta.get_dobj_meta(selected_data_object)\n",
    "\n",
    "    # Access the object's data\n",
    "    dobj_arrays = data.get_columns_as_arrays(dobj_meta)\n",
    "\n",
    "    # Convert to a pandas dataframe\n",
    "    df = pd.DataFrame(dobj_arrays)\n",
    "\n",
    "    display(df)\n",
    "else:\n",
    "    print('Check filename')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae5b52-b023-4bc1-b1d2-384fedf9c376",
   "metadata": {},
   "source": [
    "### Make a plot: single data column\n",
    "\n",
    "The selected data_object that has been accessed contains data for CO2 (stored in the \"co2\" column in the DataFrame above). If you access a different data object, the data may be stored in a column with a different name. Additionally, the names of the columns containing the observation timestamp and quality flag may also differ.\n",
    "\n",
    "Before the data is plotted, the \"Flag\" column is used to exclude data that has been marked as poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92c2b8-5ccc-4319-8382-627f5bf4f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to see available all columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc56ddf-adf0-4cd3-a45a-89ac9a7d4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column = 'SamplingStart'\n",
    "data_column = 'co2'\n",
    "quality_flag = 'Flag'\n",
    "value_accept_quality = 'O'\n",
    "\n",
    "# apply flag to excluded poor data (maked \"U\" in column \"Flag\")\n",
    "df_quality = df[df[quality_flag] == value_accept_quality]\n",
    "\n",
    "# dobj_meta accessed in \"Access data\" section\n",
    "columns_meta = dobj_meta.specificInfo.columns\n",
    "\n",
    "if data_column in df_quality.columns and time_column in df_quality.columns:\n",
    "\n",
    "    # find metadata associated with the selected column (data_column)\n",
    "    dobj_value_type = [col for col in columns_meta if col.label==data_column][0].valueType\n",
    "\n",
    "    # create label for y-axis based on the metadata\n",
    "    y_axis_label = f\"{dobj_value_type.self.label} [{dobj_value_type.unit}]\"\n",
    "    station = dobj_meta.specificInfo.acquisition.station.org.name\n",
    "\n",
    "    plot = df_quality.plot(x=time_column, y=data_column, grid=True, title=station, style='o', markersize=3)\n",
    "    plot.set(ylabel=y_axis_label)\n",
    "\n",
    "else:\n",
    "    print(f'The selected data_column or time_column is not one of the columns in df. Choose among {list(df.columns)}.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6b6f9-b63c-4ec2-9ef7-060a411a626f",
   "metadata": {},
   "source": [
    "### Combine data for all data objects given the station and data type\n",
    "\n",
    "Combination of selected data columns from objects in the list \"station_data_objects\".\n",
    "\n",
    "All objects will be considered, but will only be added if they have data stored in columns with the names listed in \"data_columns\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ff576-15b7-4cbb-a45c-b6ff0b22bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c4e1a-0f7c-403b-9b23-ad1344937ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column = 'SamplingStart'\n",
    "# In the example list of station_data_objects, additional columns include 'co', 'sf6', 'ch4', and 'h2'. These can be added to this list.\n",
    "# For other selections, consider the print statements in the output of this cell.\n",
    "data_columns = ['co2', '14C', 'n2o']\n",
    "# all data objects have the same column and value for the quality flag \n",
    "quality_flag = 'Flag'\n",
    "value_accept_quality = 'O'\n",
    "\n",
    "# Save the names of the data_columns that are found in the object dataframes\n",
    "# Their associated metadata is saved in y_axis labels for use in later plots.\n",
    "renamed_data_columns = []\n",
    "y_axis_labels = []\n",
    "\n",
    "# initiate the final df\n",
    "merged_df = pd.DataFrame(columns=[time_column])\n",
    "\n",
    "for dobj, arrs in data.batch_get_columns_as_arrays(station_data_objects):\n",
    "\n",
    "    # Convert the arrays into a DataFrame\n",
    "    df = pd.DataFrame(arrs)\n",
    "    print(df.columns)\n",
    "\n",
    "    # apply flag to excluded poor data (maked \"U\" in column \"Flag\")\n",
    "    df_quality = df[df[quality_flag] == value_accept_quality].copy()\n",
    "\n",
    "    # Check if the time_column is available in the dataframe columns associated with the data object\n",
    "    # If not, the users need to look at available columns and find correct column names\n",
    "    if time_column not in df_quality.columns:\n",
    "        print(f\"The column given for time ('{time_column}') is not found in {dobj.filename}. Skipping this object.\")\n",
    "        print(f\"Available columnns are '{list(df_quality.columns)}'\")\n",
    "        continue\n",
    "\n",
    "    # New column names for the final df_quality (to distinuigh between the different data objects)\n",
    "    # based on station's id and sampling height (if available)\n",
    "    station_id = dobj.station_uri.split('_')[-1]\n",
    "\n",
    "    if dobj.sampling_height:\n",
    "        suffix = f\"_{station_id}_{dobj.sampling_height}\"\n",
    "\n",
    "    else:\n",
    "        suffix = f\"_{station_id}\"\n",
    "\n",
    "    # See which of the desired data_columns are available in this data object\n",
    "    # Rename these for unique column names in the final merged_df that is updated with each iteration of the data objects\n",
    "    # Save metadata associated with the found columns\n",
    "    found_columns = []\n",
    "\n",
    "    for data_column in data_columns:\n",
    "        if data_column in df_quality.columns:\n",
    "\n",
    "            found_columns.append(data_column)\n",
    "\n",
    "            # Rename the column with the suffix\n",
    "            df_quality.rename(columns={data_column: data_column + suffix}, inplace=True)\n",
    "            \n",
    "            if data_column + suffix not in renamed_data_columns:\n",
    "                renamed_data_columns.append(data_column + suffix)\n",
    "                \n",
    "                # find y-axis label for column (used in graph)\n",
    "                # dobj_meta accessed in \"Access data\" section\n",
    "                dobj_meta = meta.get_dobj_meta(dobj)\n",
    "                columns_meta = dobj_meta.specificInfo.columns\n",
    "                dobj_value_type = [col for col in columns_meta if col.label==data_column][0].valueType\n",
    "                y_axis_labels.append(f\"{dobj_value_type.self.label} [{dobj_value_type.unit}]\")\n",
    "\n",
    "    # If any of the columns were found, merge them with the merged DataFrame\n",
    "    if found_columns:\n",
    "        # Select only the relevant columns (timestamp + renamed columns)\n",
    "        columns_to_merge = [time_column] + [col + suffix for col in found_columns]\n",
    "        merged_df = pd.merge(merged_df, df_quality[columns_to_merge], on=time_column, how='outer')\n",
    "\n",
    "    else:\n",
    "        print(f\"None of '{data_columns}' found for {dobj.filename}. Skipping this object.\")\n",
    "        print(f\"Available columns are '{list(df_quality.columns)}'\")\n",
    "\n",
    "# time_column should be in datetime format. If not alrady, it will be convert to it here:\n",
    "merged_df[time_column] = pd.to_datetime(merged_df[time_column])\n",
    "\n",
    "# Make sure it is in the right order\n",
    "merged_df = merged_df.sort_values(time_column)\n",
    "\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce662b-155d-4ef7-b10d-9d836c3747a7",
   "metadata": {},
   "source": [
    "### Make a plot: multiple data columns\n",
    "\n",
    "Not suitable for plotting of different species, as they often have different value ranges. A better plot for our example selection will follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bb134-c7e1-4708-90e4-11c953b0fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_labels = [f\"{col} ({unit})\" for col, unit in zip(renamed_data_columns, y_axis_labels)]\n",
    "\n",
    "# Plot the data\n",
    "ax = merged_df.plot(x=time_column, y=renamed_data_columns, grid=True, style='o', markersize=3)\n",
    "\n",
    "# Update the legend with the new labels\n",
    "ax.legend(legend_labels)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e82739-642f-40e3-81a1-81fbbf7ded88",
   "metadata": {},
   "source": [
    "#### Zoomed in to latest year of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0cca8-7612-4991-98aa-19b931397ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest year based on the time_column\n",
    "latest_year = merged_df[time_column].dt.year.max()\n",
    "\n",
    "# Filter the DataFrame to include only rows from the latest year\n",
    "merged_df_latest_year = merged_df[merged_df[time_column].dt.year == latest_year]\n",
    "\n",
    "# Plot the data\n",
    "ax = merged_df_latest_year.plot(x=time_column, y=renamed_data_columns, grid=True, style='o', markersize=3)\n",
    "\n",
    "# Update the legend with the new labels\n",
    "ax.legend(legend_labels)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4852d7d6-de2d-43d7-be29-93e8599ded97",
   "metadata": {},
   "source": [
    "### Make a plot: two data columns on different axes\n",
    "\n",
    "Possible for two of the data columns. Even if more are given, only the first two in the list \"selected_data_columns\" will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f08eb-5ab6-4df6-8e80-f040c742c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column = 'SamplingStart'\n",
    "\n",
    "# Select two of the data column in dataframe \"merged_df\"\n",
    "selected_data_columns = ['14C_HTM_150.0', 'co2_HTM_150.0']\n",
    "\n",
    "# Check if all selected columns are in renamed_data_columns\n",
    "missing_columns = set(selected_data_columns) - set(renamed_data_columns)\n",
    "\n",
    "if missing_columns or time_column not in merged_df.columns:\n",
    "    \n",
    "    print(f\"One or more of the columns ({selected_data_columns}), or the time_column ({time_column}), are not in merged_df.\")\n",
    "    print(f\"Available columns are: {merged_df.columns}\")  \n",
    "    \n",
    "else:\n",
    "\n",
    "    # Set up the plot with the first variable\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot the first variable on the primary y-axis\n",
    "\n",
    "    # Find the unit \n",
    "    col_index_1 = renamed_data_columns.index(selected_data_columns[0])\n",
    "    y_axis_label_1 = y_axis_labels[col_index_1]\n",
    "\n",
    "    # b stands for blue and \".\" for circle markers\n",
    "    ax1.plot(merged_df[time_column], merged_df[selected_data_columns[0]], 'b.', markersize = 3)\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel(y_axis_label_1, color='b')\n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "    # Set the title with the station name\n",
    "    ax1.set_title(station)\n",
    "\n",
    "    if len(selected_data_columns) > 1:\n",
    "        \n",
    "        # Create a secondary y-axis for the second variable\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "        # Plot the second variable on the secondary y-axis\n",
    "        col_index_2 = renamed_data_columns.index(selected_data_columns[1])\n",
    "        y_axis_label_2 = y_axis_labels[col_index_2]\n",
    "\n",
    "        # r stands for red and \".\" for circle markers\n",
    "        ax2.plot(merged_df[time_column], merged_df[selected_data_columns[1]], 'r.', markersize = 3)\n",
    "        ax2.set_ylabel(y_axis_label_2, color='r')\n",
    "        ax2.tick_params(axis='y', labelcolor='r')\n",
    "        \n",
    "    # show the dates in this specific format (YYYY-MM-DD)\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    \n",
    "    # Rotate the dates to fit better\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Add grid\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.tight_layout()  # to make sure labels/axes don't overlap\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
