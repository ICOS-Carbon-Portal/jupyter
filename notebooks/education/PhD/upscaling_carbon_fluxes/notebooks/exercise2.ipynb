{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../ancillarydata/logos/LundUniversity_C2line_RGB.png\" width=\"150\" align=\"left\"/>\n",
    "<br>\n",
    "<img src=\"../ancillarydata/logos/Icos_Logo_CMYK_Regular_SMpng.png\" width=\"327\" align=\"right\"/>\n",
    "<br>\n",
    "<a id='introduction'></a>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# <font color=#B98F57>Exercises taken from a PhD course titled</font>\n",
    "### <font color=#000083>From CO$_2$ in situ measurements to carbon balance maps as a tool to support national carbon accounting</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "<meta content=\"text/html; charset=UTF-8\">\n",
    "\n",
    "<style>td{padding: 3px;}\n",
    "</style>\n",
    "\n",
    "<table style=\"width: 100%\">\n",
    "    <colgroup>\n",
    "        <col span=\"1\" style=\"width: 17%;\">\n",
    "        <col span=\"1\" style=\"width: 83%;\">\n",
    "    </colgroup>\n",
    "    <tr>\n",
    "        <th><font size=\"2\">Organized by:</font></th>\n",
    "        <td>\n",
    "            <div style=\"float:left;\">\n",
    "                <font size=\"2\">\n",
    "                    The PhD course was held by the dept. of Physcial Geography and Ecosystem Science at Lund University and<br>supported by ICOS Carbon Portal, ICOS Sweden and Lund University ClimBEco Graduate Research School.\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th><font size=\"2\">Course dates:</font></th>\n",
    "        <td><div style=\"float:left;\"><font size=\"2\">March 9th 2020 - March 13th 2020</font></div></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th><font size=\"2\">Location:</font></th>\n",
    "        <td><div style=\"float:left;\"><font size=\"2\">Lund, Sweden</font></div></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th><font size=\"2\">Exercise developed by:</font></th>\n",
    "        <td><div style=\"float:left;\"><font size=\"2\">Ute Karstens, Paul Miller, Marko Scholze & Karolina Pantazatou</font></div></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th><font size=\"2\">Data references:</font></th>\n",
    "        <td><div style=\"float:left;\"><font size=\"2\">For more information regarding the datasets used in this exercise please click on the <a href=\"#data_ref\">link</a>.</font></div></td>\n",
    "    </tr>\n",
    "</table>\n",
    "</font>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<a id=\"intro\"></a>\n",
    "\n",
    "# <font color=#800000> Exercise 2</font>  \n",
    "## _Vegetation modelling & inverse modelling_\n",
    "\n",
    "In this exercise you will analyse carbon flux estimates from different types of models and compare them with the observed fluxes in the FLUXNET dataset.\n",
    "\n",
    "You will complete tasks based on:\n",
    "\n",
    "1. Vegetation model results from an [LPJ-GUESS run for the FLUXNET stations](#lpj_st).\n",
    "2. Vegetation model results from an [LPJ-GUESS run on a grid](#lpj_map) for Europe.\n",
    "3. Atmospheric [inversion](#lumia_map) results for Europe from the LUMIA inversion system.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lpj_st\"></a>\n",
    "## <font color=#800000> Task 1</font> - Compare vegetation model output to observations\n",
    "\n",
    "\n",
    "1. Read LPJ-GUESS output data for a specific station into a Pandas DataFrame.\n",
    "\n",
    "2. Read FLUXNET data (real observations) for the same station into a Pandas DataFrame.\n",
    "\n",
    "3. Plot both datasets in the same matplotlib plot (see exercise1).\n",
    "\n",
    "4. Calculate mean and st dev. Include [envelope -- > fill_between](https://stackoverflow.com/questions/12957582/plot-yerr-xerr-as-shaded-region-rather-than-error-bars) for e.g. standard deviation? \n",
    "\n",
    "<img src=\"../ancillarydata/images/exercise2/exercise2.png\" width='750'></img>\n",
    "\n",
    "5. Compare vegetation-model output & observations by computing the correlation. This step is optional and requires data harmonization. Both datasets should have the same temporal resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation I - Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tools import read_fluxnet_dd, read_fluxnet_hh\n",
    "%run ./tools.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation II - Create  a Station Object\n",
    "Possible properties you get from station:\n",
    "- info (Station Information as List)\n",
    "- code (the station code, useful to extract information)\n",
    "- eco_var_name (The name of data you store in the object) &nbsp;&nbsp; <b>You</b> are responsible to be consistent in what you store.\n",
    "- lon (longitude, useful to extract information from maps)\n",
    "- lat (latitude, useful to extract information from maps)\n",
    "\n",
    "\n",
    "For the following variables, you need to store data first to the station, before you can access it.\n",
    "- lpj (LPJ-Guess data)\n",
    "- lpjmap (LPJ-Guess Map data)\n",
    "- fluxnet (FLUXNET data from exercise 1)\n",
    "- lumia (LUMIA inversion results)\n",
    "\n",
    "For example the python code for creating a station object for Hyltemossa is the following:\n",
    "```python\n",
    "myStation = Station('Htm', 'gpp')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a station object for Hyltemossa:\n",
    "myStation = Station('Htm', 'gpp')\n",
    "\n",
    "# Show station info with:\n",
    "# an item of info can be extracted with the index. For example the country with:\n",
    "# myStation.info[1]\n",
    "myStation.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the station name from your station object:\n",
    "myStation.info[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the station latitude from your station object:\n",
    "myStation.info[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <font color=#800000> Task 1.1 </font> - Import LPJGUESS model output to your station object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import LPJ-GUESS model results:\n",
    "LPJ-GUESS was run for the individual [stations](../ancillarydata/docs/climbeco_course_station_list.png) using as input the observed meteorological data from FLUXNET\n",
    "- air temperature\n",
    "- incoming shortwave radiation\n",
    "- precipitation\n",
    "<br>\n",
    "\n",
    "Output is daily values of the following fluxes in units of kgC/m2/day\n",
    "- gpp  (gross primary productivity)\n",
    "- nee  (net ecosystem exchange)\n",
    "- rtot  (total ecosystem respiration)\n",
    "<br>\n",
    "\n",
    "The model was run twice for each station. \n",
    "The first run, called ***pnv*** below, had no restrictions or adaptations to the site conditions apart from using the observed meteorological data from FLUXNET.\n",
    "All the model's potential Plant Functional Types (PFTs) could establish and compete. This is <font color='green'> Potential Natural Vegetation (PNV)</font>.\n",
    "\n",
    "The second run for each station restricted the PFTs that could potentially establish to PFTs similar to those observed near the stations.<br>\n",
    "There are three categories:\n",
    "\n",
    "|           | coniferous    |deciduous  |grass_wet_crop|\n",
    "|:---------|:---------|:---------|:---------|\n",
    "|**PFT simulated:**|Spruce, Pine and grasses|Birch, Hornbeam, Hazel, Beech, Ash, Poplar, Oak, Lime, Elm and grasses|Grasses only (because the version of the model used does not have wetland, cropland and pasture stands)|\n",
    "||||\n",
    "|**Stations:**| NL-Loo | DK-Sor | FI-Let |\n",
    "|             | SE-Htm | DE-Hai | FI-Sii |\n",
    "|             | SE-Nor | DE-HoH | DE-Akm |\n",
    "|             | SE-Ros |        | DE-Geb |\n",
    "|             | SE-Svb |        | DE-Gri |\n",
    "|             |        |        | DE-Hte |\n",
    "|             |        |        | DE-RuR |\n",
    "|             |        |        | DE-RuS |\n",
    "|             |        |        | SE-Deg |\n",
    "|             |        |        | SE-Lnn  |\n",
    "\n",
    " \n",
    "\n",
    "<br>\n",
    "\n",
    "#### How to select from different LPJ-GUESS model results:\n",
    "Use the following variables as input parameters to the function that reads LPJ-GUESS output:\n",
    "\n",
    "LPJ-GUES Ecosystem Variables:\n",
    "- gpp\n",
    "- nee\n",
    "- rtot\n",
    "\n",
    "LPJ-GUESS Vegetation Types:\n",
    "- pnv\n",
    "- conif\n",
    "- decid\n",
    "- grass_wet_crop\n",
    "\n",
    "Use ***pnv*** to begin with. \n",
    "\n",
    "For example the python code to read LPJ_GUESS gpp from the pnv run is the following:\n",
    "```python\n",
    "myStation.lpj=read_lpjguess_st('pnv', 'gpp', myStation.code)\n",
    "```\n",
    "\n",
    "<br>\n",
    "Pick two stations for your analysis. Choose one station dominated by forests (one of the coniferous or deciduous) sites, and one from the grass_wet_crop category.\n",
    "<br>\n",
    "<br>\n",
    "*Confer with your course colleagues to avoid overlap!*\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read LPJ-data to a Pandas DataFrame and store in station obj:\n",
    "myStation.lpj=read_lpjguess_st('pnv', 'gpp', myStation.code)\n",
    "\n",
    "#Show DataFrame:\n",
    "myStation.lpj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set 'time' as index:\n",
    "myStation.lpj.set_index('time', drop=False, inplace=True)\n",
    "\n",
    "#Show dataframe:\n",
    "myStation.lpj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#800000> Task 1.2 </font> - Read FLUXNET data\n",
    "From exercise 1 we already know that the fluxes in the FLUXNET dataset are in gC/m2/d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read FLUXNET-data:\n",
    "myStation.fluxnet=read_fluxnet_dd(\"/data/project/climbeco/data/fluxnet/obs_dd/\" , myStation.code)\n",
    "\n",
    "#Set 'time' as index:\n",
    "myStation.fluxnet.set_index('TIMESTAMP', drop=False, inplace=True)\n",
    "\n",
    "#Show DataFrame:\n",
    "myStation.fluxnet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <font color=#800000> Task 1.3 </font> - Plot datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>OBS! What about units? The GPP-unit for FLUXNET-data is gC/m2/d. LPJ-GUESS GPP-output is in kgC/m2/d.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update your lpjguess-gpp value:\n",
    "myStation.lpj.Value=myStation.lpj.Value*1000 #conversion from kgC to gC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot (i.e. \"figure\") object and set the size of your plot:\n",
    "ax = myStation.lpj.plot('time','Value', figsize=(12,6))\n",
    "myStation.fluxnet.plot('TIMESTAMP','GPP_DT_VUT_MEAN', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <font color=#800000> Task 1.4 </font> - Calculate Mean & Std Deviation (plot results)\n",
    "You need to harmonize your datasets before you can compare them. Here we provide an example of how you can aggregate a dataset to monthly means and then compute standard deviation as a first measure of uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate montly mean:\n",
    "myStation_lpj_monthly_mean = myStation.lpj.Value.resample('M').mean().dropna()\n",
    "\n",
    "#Assign monthly mean value to mid of month:\n",
    "myStation_lpj_monthly_mean.index = myStation_lpj_monthly_mean.index - pd.offsets.MonthBegin(1) + to_offset(pd.Timedelta(14, 'd'))\n",
    "\n",
    "\n",
    "#Calculate standard deviation per month:\n",
    "myStation_lpj_monthly_std = myStation.lpj.Value.resample('M').std().dropna()\n",
    "\n",
    "#Assign standard deviation value to mid of month:\n",
    "myStation_lpj_monthly_std.index = myStation_lpj_monthly_std.index - pd.offsets.MonthBegin(1) + to_offset(pd.Timedelta(14, 'd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create plot with std dev of monthly means\n",
    "\n",
    "#Set variables:\n",
    "x = myStation_lpj_monthly_mean.index\n",
    "y = myStation_lpj_monthly_mean\n",
    "error = myStation_lpj_monthly_std\n",
    "\n",
    "#Add grid:\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "#Create a plot (i.e. \"figure\") object and set the size of your plot:\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "#Add plot title:\n",
    "plt.title(\" \".join([myStation.info[0],myStation.info[1],myStation.eco_var_name]))\n",
    "\n",
    "#Plot values for Hyltemossa:\n",
    "plt.plot(x, y,\n",
    "         linestyle = '-.', linewidth = 2.5, color = 'black',\n",
    "         label = 'LPJ-GUESS '+myStation.info[0])\n",
    "\n",
    "#Add envelope:\n",
    "plt.fill_between(x, y-error, y+error, alpha=0.5)\n",
    "\n",
    "#Add x-axis label:\n",
    "plt.xlabel('Time')\n",
    "\n",
    "#Add y-axis label:\n",
    "plt.ylabel('GPP (gC / m2 / d)')\n",
    "\n",
    "#Add legend:\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to calculate monthly mean and standard deviation of fluxnet data and add to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your own code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <font color=#800000> Task 1.5 </font> - Compute correlation and RMSE of the hourly time series\n",
    "Compare vegetation-model output & observations by computing the correlation and RMSE (Root Mean Square Error). <br>\n",
    "This step requires data harmonization. Both datasets should have the same temporal resolution (i.e. time index). To compute the correlation between the time series, you need to put both datasets in the same dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate dataframes:\n",
    "df_combined = pd.concat([myStation.fluxnet['GPP_DT_VUT_MEAN'], myStation.lpj['Value']], axis=1)\n",
    "\n",
    "#Show dataframe:\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute correlation:\n",
    "df_combined.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that computes RMSE between two Pandas Series or two NumPy arrays:\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(np.nanmean((predictions - targets) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to compute RMSE between LPJ-GUESS GPP model output & GPP observations:\n",
    "rmse(df_combined['Value'], df_combined['GPP_DT_VUT_MEAN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Questions to answer:  </font>\n",
    "\n",
    "1. How well does the model represent the observed biospheric fluxes, i.e. NEE, GPP, RTOT?\n",
    "\n",
    "2. Does the model capture observed flux anomalies from the drought event in 2018? \n",
    "\n",
    "3. How is the seasonal performance? Are summers better represented than winter months?\n",
    "\n",
    "4. Compare the results from pnv to those from the second run for each station you considered. Do the restrictions placed on the PFTs improve the results?\n",
    " \n",
    "5. How to quantitatively evaluate model performance?\n",
    "\n",
    "6. Are some time scales represented by the model better than others? <br>\n",
    "e.g. seasonal cycle vs. variability within a month\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue writing your own code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lpj_map\"></a>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "    <a href=\"#intro\">Back to top</a>\n",
    "</div>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## <font color=#800000> Task 2 </font> - Add vegetation-model output on a map to the comparison\n",
    "In this part you will inspect LPJ-GUESS fluxes on a map. The model was run on a grid covering Europe. <br>\n",
    "In these runs the meteorological and biophysical input data are no longer direct observations. Instead objective reanalysis of meteorological observations provided by meteorological services like [ECMWF](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5) (European Centre for Medium-Range Weather Forecast) or [NCEP](https://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html) (National Certers for Environmental Prediction).\n",
    "\n",
    "LPJ-GUESS fluxes are stored in netCDF-files and read into a multi-dimensional array (NumPy array).\n",
    "The netCDF-file also includes sepparate data with the latitudes and longitudes of the fluxes.\n",
    "You will use an already existent function to plot the fluxes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#800000> Task 2.1 </font> - Inspect the LPJ-GUESS maps\n",
    "\n",
    "Compare NEE, GPP and Respiration for different seasons and different times of day. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to display widget-form:\n",
    "create_widget_form_multi_maps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <font color=#800000> Task 2.2 </font> -  Extract time-series from netCDF with vegetation-model output \n",
    "This exercises focuses on how to extract time-series of values for a specific location (given in lat/lon) from the map. <br> \n",
    "You will use already prepared functions to:\n",
    "\n",
    "1. Read netCDF with LPJ-GUESS model output\n",
    "\n",
    "2. Extract time-series of fluxes for a given station in lat/lon stored in your myStation object (read this [file](../ancillarydata/docs/climbeco_course_station_list.pdf) to get station location info).\n",
    "\n",
    "And finally add the extracted time-series as Pandas DataFrame to your station object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPJ-GUESS maps 6-hourly fluxes\n",
    "lon_LPJmap, lat_LPJmap, time_LPJmap, nee_LPJmap, gpp_LPJmap, rtot_LPJmap, cell_area_LPJmap, flux_units_LPJmap, description_LPJmap = read_LPJ_fluxmap_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The extracted data contains all Europe. Extract the values for your station\n",
    "# extract time series for station / grid cell\n",
    "i,j = lonlat_2_ixjy(myStation.lon,myStation.lat ,lon_LPJmap,lat_LPJmap)\n",
    "\n",
    "#Extract time series for given index:\n",
    "myStation_nee = nee_LPJmap[:,j,i]\n",
    "\n",
    "# we need area of this specific grid cell later for the conversion from per gridcell to per m2\n",
    "myStation_area = cell_area_LPJmap[j,i]\n",
    "\n",
    "# create a pandas dataframe and store this into your station\n",
    "myStation.lpjmap = pd.DataFrame({'LPJGUESS_NEE':myStation_nee, 'time':time_LPJmap})\n",
    "myStation.lpjmap.set_index('time', drop=False, inplace=True)\n",
    "myStation.lpjmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ! STOP did you do the right thing?<br>\n",
    "- If you just followed all the examples, you probably want to compare GPP, but you have stored NEE in your station..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get LPJGUESS-map data for selected index:\n",
    "myStation_gpp = gpp_LPJmap[:,j,i]\n",
    "\n",
    "# we need area of this specific grid cell later for the conversion from per gridcell to per m2\n",
    "myStation_area = cell_area_LPJmap[j,i]\n",
    "\n",
    "# create a pandas dataframe and store this into your station\n",
    "myStation.lpjmap = pd.DataFrame({'LPJGUESS_GPP':myStation_gpp, 'time':cftime_to_datetime(time_LPJmap)})\n",
    "myStation.lpjmap.set_index('time', drop=False, inplace=True)\n",
    "myStation.lpjmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "### <font color=#800000> Task 2.2 </font> -  Harmonize vegetation-model output (time-series) with observations\n",
    "Before you plot the time series that you extracted from the LPJ-GUESS map with the FLUXNET observations, you need to make sure that both datasets have the same temporal resolution. The LPJ-GUESS map has a temporal resolution of 6 hours. The FLUXNET observations includes daily values.\n",
    "\n",
    "Pandas DataFrames in Python include a wide range of built-in functions for aggregating data based on time (e.g. ```df.resample('M').mean()```, if the Pandas DataFrame has a column of dateTime objects as index).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate daily means for LPJ-GUESS map and convert from gC/cell/s to kg/m2/s\n",
    "myStation_lpjmap_daily_mean = myStation.lpjmap.resample('D').mean().dropna()*(-1)*1000.*12/44.*4./myStation_area\n",
    "\n",
    "myStation_lpjmap_daily_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue writing your own code based on examples in previous tasks...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "### <font color=#800000> Task 2.3 </font> -  Plot vegetation-model output time-series with observations\n",
    "In this exercise you will choose a station and create a matplotlib plot containing:\n",
    "\n",
    "1. LPJ-GUESS model output - specific station model output\n",
    "\n",
    "2. LPJ-GUESS model output - extracted time-series from map\n",
    "\n",
    "3. Fluxnet observations\n",
    "\n",
    "<br>\n",
    "\n",
    "go to the station_example or exercise1 notebook to see how to use the matplotlib library\n",
    "\n",
    "in the following a quick and dirty plot which is missing the title, and the units...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot (i.e. \"figure\") object and set the size of your plot:\n",
    "ax = myStation.lpj.plot('time','Value', figsize=(12,6))\n",
    "myStation.fluxnet.plot('TIMESTAMP','GPP_DT_VUT_MEAN', ax=ax)\n",
    "myStation_lpjmap_daily_mean.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your own code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lumia_map\"></a>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align: right\"><a href=\"#intro\">Back to top</a></div>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## <font color=#800000> Task 3 </font> - Add inverse modelling output from LUMIA inversions in the comparison\n",
    "Regional carbon sources and sinks can also be derived from variations in observed atmospheric CO2 concentrations via inverse modelling. Atmospheric transport inversions rely on transport models and statistical methodologies to derive the most likely estimates of CO2 fluxes given large datasets of observed atmospheric CO2 concentrations and a prior information provided by ecosystem models.\n",
    "\n",
    "This example shows results of the LUMIA inversion system ([Monteil et al, 2019](https://doi.org/10.5194/acp-2019-1008)) using the LPJ-GUESS NEE maps as prior information. So the LUMIA prior is exactly the same as the LPJ-GUESS NEE map. The LUMIA posterior is then the result of the inversion.\n",
    "\n",
    "The LUMIA inverse modelling output has a temporal resolution of one month.\n",
    "\n",
    "1. Look at LUMIA maps. Inspect prior, posterior and difference.\n",
    "\n",
    "2. Read netCDF-files with LUMIA posterior info (code is provided).\n",
    "\n",
    "3. Extract time-series for given location (lat/lon) (code is provided).\n",
    "\n",
    "4. Read extracted time-series into Pandas DataFrames.\n",
    "\n",
    "5. Harmonize Pandas DataFrame with LUMIA time-series to comply with the temporal resolution of the other datasets.\n",
    "\n",
    "6. Plot LPJ-GUESS model ouput, LPJ-GUESS time-series from maps, FLUXNET observations and LUMIA time-series using matplotlib.\n",
    "\n",
    "7. Consider ways of calculating the difference between the datasets and reflect on why differences occur.\n",
    " \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <font color=#800000> Task 3.1 </font> - Inspect the LUMIA prior and posterior flux maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to display LUMIA maps:\n",
    "create_widget_form_multi_maps_lumia()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#800000> Task 3.2 </font> -  Extract time-series from LUMIA output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get LUMIA monthly fluxes (read netcdf):\n",
    "lon_LUMIA,lat_LUMIA,time_LUMIA,bio_prior_LUMIA_map,bio_poste_LUMIA_map,oce_LUMIA_map,ff_LUMIA_map,cell_area_LUMIA_map,flux_units_LUMIA,comment = read_EUROCOM_drought_fluxmap(path_lumia+'co2flux_monthly_lumia_core_2009_2018.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imported data contains all Europe.\n",
    "Now, we will extract LUMIA values for one station (lat/lon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the lat/lon of your station in lonlat_2_ixjy()\n",
    "#and get the index-values for the corresponding grid-cell in the LUMIA array:\n",
    "lumia_i,lumia_j = lonlat_2_ixjy(myStation.lon, myStation.lat ,lon_LUMIA, lat_LUMIA)\n",
    "\n",
    "#Call function to extracting time series for your station/grid-cell:\n",
    "myStation_lumia = bio_poste_LUMIA_map[:,lumia_j,lumia_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#800000> Task 3.3 </font> - Store extracted LUMIA time series to Pandas DataFrame in your station object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the extracted LUMIA time series in a Pandas DataFrame and store this into your station object:\n",
    "myStation.lumia = pd.DataFrame({'LUMIA_POSTERIOR':myStation_lumia, 'time':cftime_to_datetime(time_LUMIA)})\n",
    "\n",
    "#Set \"time\" as index:\n",
    "myStation.lumia.set_index('time', drop=False, inplace=True)\n",
    "\n",
    "#Show dataframe:\n",
    "myStation.lumia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#800000> Task 3.4 </font> - Finally compare and analyse all NEE time series \n",
    "Now that you have explored the different datasets we will start a final comparison of all of them. For this purpose a new myStation object will be created to make sure that the same station and the same variable is being compared.\n",
    "\n",
    "### <font color='blue'> Question:</font>\n",
    "Compare the results from the inversion to those from LPJ-GUESS for each station you considered. Does the inversion improve the fit against the observations? Find reasons for the mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new myStation object and store all model results for this station.\n",
    "#This example is for nee only.\n",
    "\n",
    "#Create a station object for your station:\n",
    "myStation_obj = Station('Htm', 'nee')\n",
    "\n",
    "#Read LPJ-data to a Pandas DataFrame and store in station obj:\n",
    "myStation_obj.lpj=read_lpjguess_st('pnv', 'nee', myStation_obj.code)\n",
    "myStation_obj.lpj.set_index('time', drop=False, inplace=True)\n",
    "myStation_obj.lpj.rename(columns={\"Value\": \"LPJGUESSst_NEE\"}, inplace=True)\n",
    "\n",
    "#Read FLUXNET-data to a Pandas DataFrame and store in station obj:\n",
    "myStation_obj.fluxnet=read_fluxnet_dd(\"/data/project/climbeco/data/fluxnet/obs_dd/\" , myStation_obj.code)\n",
    "myStation_obj.fluxnet.set_index('TIMESTAMP', drop=False, inplace=True)\n",
    "\n",
    "#create a pandas dataframe and store LPJ-GUESS map results into your station\n",
    "i,j = lonlat_2_ixjy(myStation_obj.lon,myStation_obj.lat ,lon_LPJmap,lat_LPJmap)\n",
    "myStation_nee = nee_LPJmap[:,j,i]\n",
    "myStation_area = cell_area_LPJmap[j,i]\n",
    "myStation_obj.lpjmap = pd.DataFrame({'LPJGUESSmap_NEE':myStation_nee, 'time':cftime_to_datetime(time_LPJmap)})\n",
    "myStation_obj.lpjmap.set_index('time', drop=False, inplace=True)\n",
    "\n",
    "#create a pandas dataframe and store LUMIA results into your station\n",
    "lumia_i,lumia_j = lonlat_2_ixjy(myStation_obj.lon, myStation_obj.lat ,lon_LUMIA, lat_LUMIA)\n",
    "myStation_obj.lumia = pd.DataFrame({'LUMIA_POSTERIOR':bio_poste_LUMIA_map[:,lumia_j,lumia_i], 'time':cftime_to_datetime(time_LUMIA)})\n",
    "myStation_obj.lumia.set_index('time', drop=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resample FLUXNET-values to monthly means (assign monthly mean value to mid of month):\n",
    "nee_flux_monthly_means = myStation_obj.fluxnet.NEE_VUT_MEAN.resample('M').mean()\n",
    "nee_flux_monthly_means.index = nee_flux_monthly_means.index - pd.offsets.MonthBegin(1) + to_offset(pd.Timedelta(14, 'd'))\n",
    "\n",
    "#Resample LPJ-GUESS model output to monthly means (assign monthly mean value to mid of month): \n",
    "nee_lpj_monthly_means = myStation_obj.lpj.LPJGUESSst_NEE.resample('M').mean()\n",
    "nee_lpj_monthly_means.index = nee_lpj_monthly_means.index - pd.offsets.MonthBegin(1) + to_offset(pd.Timedelta(14, 'd'))\n",
    "\n",
    "#Resample LPJ-GUESS map to monthly means (assign monthly mean value to mid of month): \n",
    "nee_lpjmap_monthly_means = myStation_obj.lpjmap.LPJGUESSmap_NEE.resample('M').mean()\n",
    "nee_lpjmap_monthly_means.index = nee_lpjmap_monthly_means.index - pd.offsets.MonthBegin(1) + to_offset(pd.Timedelta(14, 'd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add grid:\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "#Create a plot (i.e. \"figure\") object and set the size of your plot:\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "#Add plot title:\n",
    "plt.title(myStation_obj.info[0].upper()+' (monthly values)')\n",
    "\n",
    "#Plot values for FLUXNET:\n",
    "plt.plot(nee_flux_monthly_means.index, nee_flux_monthly_means,\n",
    "         linestyle = '-.', linewidth = 1.5, color = 'orange',\n",
    "         label = myStation_obj.info[0]+'(FLUXNET)')\n",
    "\n",
    "#Plot values for LPJ-GUESS:\n",
    "plt.plot(nee_lpj_monthly_means.index, nee_lpj_monthly_means*1000*(-1),#need to switch sign here to follow the same convention as in the other datsets (positive flux = into the atmosphere)\n",
    "         linestyle = '-', linewidth = 1.7, color = 'darkgreen',\n",
    "         label = 'LPJ-GUESS')\n",
    "\n",
    "#Plot values for LPJ-GUESS map:\n",
    "plt.plot(nee_lpjmap_monthly_means.index, nee_lpjmap_monthly_means*1000.*12/44.*4./myStation_area, #conversion from gC/cell/s to kg/m2/s\n",
    "         linestyle = '-', linewidth = 1.7, color = 'blue',\n",
    "         label = 'LPJ-GUESS map')\n",
    "\n",
    "#Plot values for LUMIA:\n",
    "plt.plot(myStation.lumia[datetime(2014,12,31):datetime(2018,12,31)].index.values, myStation.lumia[datetime(2014,12,31):datetime(2018,12,31)].LUMIA_POSTERIOR*1000.*24.,\n",
    "         linestyle = '-', linewidth = 1.7, color = 'firebrick',\n",
    "         label = 'LUMIA')\n",
    "\n",
    "#Add x-axis label:\n",
    "plt.xlabel('Time')\n",
    "\n",
    "#Add y-axis label:\n",
    "plt.ylabel('NEE (gC / m2 / d)')\n",
    "\n",
    "#Add legend:\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "#Show plot:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harmonize all four datasets\n",
    "\n",
    "#Concatenate dataframes:\n",
    "df_combined = pd.concat([nee_flux_monthly_means, \n",
    "                         nee_lpj_monthly_means*1000.*(-1), \n",
    "                         nee_lpjmap_monthly_means*1000.*12/44.*4./myStation_area, \n",
    "                         myStation.lumia[datetime(2014,12,31):datetime(2018,12,31)].LUMIA_POSTERIOR*1000.*24.], axis=1)\n",
    "\n",
    "#Show dataframe:\n",
    "df_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot harmonized datasets:\n",
    "df_combined.plot(figsize=(17,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute correlation:\n",
    "df_combined.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue writing your own code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_ref'></a>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "    <a href=\"#intro\">Back to top</a>\n",
    "</div>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Data references\n",
    "\n",
    "### FLUXNET\n",
    "Drought 2018 Team & ICOS Ecosystem Thematic Centre (2020). Drought-2018 ecosystem eddy covariance flux product in FLUXNET-Archive format - release 2019-2 (Version 1.0). ICOS Carbon Portal. https://doi.org/10.18160/yvr0-4898\n",
    "\n",
    "\n",
    "### LPJGUESS    \n",
    "Site runs with LPJ-GUESS (http://iis4.nateko.lu.se/lpj-guess/) were carried out with version 4.0 of the model (Smith et al. 2014), but without site-specific calibration. To mimic local conditions, the model was forced with daily surface air temperature, precipitation and incoming shortwave radiation measured at the sites (for years 2015-2018), but inputs of nitrogen deposition and soil properties were taken from global datasets. In certain cases, the plant functional types and species that can establish in the model were restricted to match site conditions, but neither site management history nor disturbances were considered. Finally, no wetland features were activated.\n",
    "\n",
    "The model output is strictly for educational purposes, and not to be used for research publications or commercial applications.\n",
    "\n",
    "Smith, B., WÃ¥rlind, D., Arneth, A., Hickler, T., Leadley, P., Siltberg, J. & Zaehle, S. 2014. Implications of incorporating N cycling and N limitations on primary production in an individual-based dynamic vegetation model. Biogeosciences 11: 2027-2054.\n",
    "\n",
    "### LUMIA\n",
    "LUMIA inverse modelling estimates of European CO2 fluxes for 2009-2018 as part of the inversion intercomparison for the 2018 drought, using only atmospheric sites with nearly continuous records (LU-select); monthly fluxes; 0.5 deg. x 0.5 deg.; NEE prior: LPJ-GUESS; Anthropogenic emissions: EDGARv3.2 + TNO profiles + BP statistics, http://doi.org/10.18160/y9qv-s113; Model description in Monteil and Scholze, 2019, https://doi.org/10.5194/gmd-2019-227; Supplementary material for Thompson et al.: Changes in Net ecosystem exchange over Europe during the 2018 drought based on atmospheric observations, Phil. Trans. R. Soc. B 20190512, 2020, http://dx.doi.org/10.1098/rstb.2019.0512 \n",
    "\n",
    "The dataset is available on [ICOS Carbon Portal](https://data.icos-cp.eu/portal) using the following PID: <br>\n",
    "**Dataset PID:** https://hdl.handle.net/11676/mP7Syr2esEs2-0lImmOFNHae\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}