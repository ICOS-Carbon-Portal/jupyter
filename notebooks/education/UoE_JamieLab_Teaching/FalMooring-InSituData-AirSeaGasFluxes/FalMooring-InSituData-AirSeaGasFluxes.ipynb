{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a518ef",
   "metadata": {},
   "source": [
    "# Using the Fal mooring in situ data to calculate air-sea CO$_2$ gas fluxes #\n",
    "\n",
    "## Introduction\n",
    "This notebook explains how we can use the Fal mooring data to calculate air-sea CO$_2$ gas fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e35f11",
   "metadata": {},
   "source": [
    "### Load Relevant Modules\n",
    "To begin with the required Python packages are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0382b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset\n",
    "# Install basemap-data-hires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80327b",
   "metadata": {},
   "source": [
    "### Loading the mooring data\n",
    "Now we need to load the mooring data which is provided as a tab separated variable file (.tsv). And we can then view the first 5 rows of the dataset using the .head(5) command. Alternatively you can view the last 5 rows of the dataset using .tail(5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4e599",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data file\n",
    "region_data = pd.read_csv('Fal_mooring_flux.tsv', sep='\\t', index_col=0)\n",
    "# Show small proportion of the data\n",
    "region_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c53d4",
   "metadata": {},
   "source": [
    "### Preparing to Plot the Recorded Data\n",
    "We want to plot a 'time series' of the data that was recorded. One way to show this is to plot 'Days since [first recording]' along the x-axis and the data along the y-axis. The cell below finds the number of days since the first measurement (technically it finds the number of seconds since the first recording and divides this by 86,400) and creates a new column in the Dataframe to show these values.\n",
    "\n",
    "Note: if your own dataset doesn't have columns for 'Year', 'Month', 'Day', etc. then the below won't work and you need to add this to your dataset. This can be done in Excel (but better to do it Pythonically if possible to prevent Excel making changes to it's own formatting), and see example datasets for the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7722e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise the new Dataframe column and fill with a hold value\n",
    "region_data['Days_since'] = 'hold value'\n",
    "\n",
    "# Produce a datetime object for the first recording \n",
    "# - the zeros in the line below show it's the first row (index starts at zero)\n",
    "start_date = dt.datetime(region_data.loc[0,'Year'],region_data.loc[0,'Month'],region_data.loc[0,'Day'],\n",
    "                            region_data.loc[0,'Hour'],region_data.loc[0,'Minute'],region_data.loc[0,'Second'])\n",
    "\n",
    "# Loop over all rows in the Dataframe - i.e from 0 to the length of the Dataframe\n",
    "for i in range(0,len(region_data)):\n",
    "    # Get the date time object for the currently indexed recording - indexed by i\n",
    "    future_date = dt.datetime(region_data.loc[i,'Year'],region_data.loc[i,'Month'],region_data.loc[i,'Day'],\n",
    "                              region_data.loc[i,'Hour'],region_data.loc[i,'Minute'],region_data.loc[i,'Second'])\n",
    "    \n",
    "    # Find difference between current datetime and inital datetime\n",
    "    day_diff = future_date - start_date\n",
    "    \n",
    "    # Fill Dataframe column with time difference in seconds (found using .total_seconds()) \n",
    "    # divided by 86400 (proportion of days that have passed)\n",
    "    region_data.loc[i,'Days_since'] = day_diff.total_seconds()/(60*60*24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2dd95",
   "metadata": {},
   "source": [
    "We can filter the Dataframe to show just the 'Datetime' and 'Days_since' columns. Showing the head can give an idea if the previous cell worked - although a more thorough check is advised if possible depending on Dataframe size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb24cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter data to 'Datetime' and 'Days_since' columns and show first 5 rows.\n",
    "region_data[['Datetime', 'Days_since']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea18f8",
   "metadata": {},
   "source": [
    "### Plotting the Time Series  \n",
    "\n",
    "The Matplotlib .subplots() function is ideal for this and I have used Seaborn to do the actual plotting - these two packages work well together as Seaborn is built on top of Matplotlib, and Seaborn also integrates easily with Pandas Dataframes. \n",
    "\n",
    "Producing nice looking plots with lovely axes labels and colors etc. can be fiddly, but you can refer to the documentation (and StackOverflow!) for hints and tips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf66c222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "\n",
    "# Set up a figure with 4 axes on it. Sharex=True means all axes will share the bottom axes (can help with clarity)\n",
    "fig,ax = plt.subplots(3,2, sharex=True)\n",
    "# Set figure height and width\n",
    "fig.set_figheight(15), fig.set_figwidth(15)\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### PLOTTING THE DATA ### (- *s indicate a plot keyword below)\n",
    "# These Seaborn commands state that we want a *lineplot*, where the *data* is coming \n",
    "# from our region_data Dataframe, and we chose the *x* & *y* columns that we want, as well\n",
    "# as the axis (*ax*) we want to plot on (indexed by 0 at the top and 3 at the bottom)\n",
    "sns.lineplot(data=region_data, x='Date', y='salinity', color='turquoise', ax=ax[0,0])\n",
    "sns.lineplot(data=region_data, x='Date', y='sstskin_k', color='red', ax=ax[0,1])\n",
    "sns.lineplot(data=region_data, x='Date', y='windu10', color='green', ax=ax[1,0])\n",
    "sns.lineplot(data=region_data, x='Date', y='pco2sw_corr_split', color='orange', ax=ax[1,1], hue=region_data[\"pco2sw_corr_split\"].isna().cumsum(), palette=[\"blue\"]*sum(region_data[\"pco2sw_corr_split\"].isna()), legend=False, markers=True)\n",
    "sns.lineplot(data=region_data, x='Date', y='pressure_met', color='purple', ax=ax[2, 0])\n",
    "sns.lineplot(data=region_data, x='Date', y='pco2_air_noaa_2018', color='black', ax=ax[2, 1])\n",
    "\n",
    "# Use WeekdayLocator and DateFormatter to show only weekly dates on x-axis\n",
    "date_fmt = mdates.DateFormatter('%d-%m-%Y')\n",
    "week_locator = mdates.WeekdayLocator(byweekday=mdates.MO)\n",
    "ax[2,0].xaxis.set_major_locator(week_locator)\n",
    "ax[2,0].xaxis.set_major_formatter(date_fmt)\n",
    "ax[2,1].xaxis.set_major_locator(week_locator)\n",
    "ax[2,1].xaxis.set_major_formatter(date_fmt)\n",
    "\n",
    "# Set x axis label\n",
    "ax[2,0].set_xlabel('Date', fontsize = 20) \n",
    "ax[2,1].set_xlabel('Date', fontsize = 20) \n",
    "ax[2,0].set_xticklabels(region_data['Date'], rotation='vertical')\n",
    "ax[2,1].set_xticklabels(region_data['Date'], rotation='vertical')\n",
    "\n",
    "# Set x-axis tick labels\n",
    "tick_locs = ax[2,0].get_xticks() # Get the current tick locations\n",
    "ax[2,0].set_xticks(tick_locs) # Set the same tick locations\n",
    "ax[2,0].set_xticklabels(region_data['Date'][::len(region_data['Date'])//len(tick_locs)][:-1], rotation='vertical')\n",
    "tick_locs = ax[2,1].get_xticks() # Get the current tick locations\n",
    "ax[2,1].set_xticks(tick_locs) # Set the same tick locations\n",
    "ax[2,1].set_xticklabels(region_data['Date'][::len(region_data['Date'])//len(tick_locs)][:-1], rotation='vertical')\n",
    "\n",
    "# Set y label for each axis\n",
    "ax[0,0].set_ylabel('Salinity', fontsize = 20) \n",
    "ax[0,1].set_ylabel('SST (K)', fontsize = 20)\n",
    "ax[1,0].set_ylabel('Windspeed (m/s)', fontsize = 20)\n",
    "ax[1,1].set_ylabel('Est.pCO2 (Âµ atm)', fontsize = 20)\n",
    "ax[2, 0].set_ylabel('Atm.Pressure (mbar)', fontsize = 20)\n",
    "ax[2, 1].set_ylabel('Atm.pCO2 (ppm)', fontsize = 20)\n",
    "\n",
    "# Changes how axis ticks are displayed for last two axes\n",
    "# - you can comment these out with # to see the effect when removed\n",
    "ax[0,0].yaxis.set_major_formatter('{x:9<5.2f}')\n",
    "ax[0,1].yaxis.set_major_formatter('{x:9<5.2f}')\n",
    "ax[1,0].yaxis.set_major_formatter('{x:9<5.2f}')\n",
    "ax[1,1].yaxis.set_major_formatter('{x:9<5.2f}')\n",
    "ax[2,0].yaxis.set_major_formatter('{x:9<5.2f}')\n",
    "ax[2,1].yaxis.set_major_formatter('{x:9<5.2f}')\n",
    "\n",
    "# Set a tight layout to remove extra space around the plots\n",
    "fig.tight_layout()\n",
    "# Reduce gap between top of figure and the title\n",
    "fig.subplots_adjust(top=0.95)\n",
    "\n",
    "# Show figure!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe158ba8",
   "metadata": {},
   "source": [
    "### Using FluxEngine\n",
    "To calculate the air-sea gas fluxes we are going to be using a bulk formulation of the calculation and using the FluxEngine python module toolbox. So lets check to see which version of the FluxEngine we have installed. It should be at least version 4.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa1846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We primarily use FluxEngine from the command line, but here we can import it just to check the version\n",
    "import fluxengine as fe\n",
    "import fluxengine.tools.lib_text2ncdf as nc\n",
    "print(fe.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de293d1d",
   "metadata": {},
   "source": [
    "Now we need to convert our .tsv data file in the filetype that the FluxEngine uses which is NetCDF. NetCDF is a standard file format used by many scientific and engineering communities and it allows the data to be compressed and the file can contain the metadata that describes how the data were collected, created and processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743c623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting to netCDF\n",
    "nc.convert_text_to_netcdf(['Fal_mooring_flux.tsv'],startTime='2018-09-14 00:00:00',endTime='2018-11-30 08:00:00',ncOutPath='Fal_mooring.nc',temporalResolution='0 01:00',\n",
    "    colNames=['salinity', 'sstskin_c', 'sstskin_k', 'windu10', 'windu10_moment2', 'pco2sw_corr_split', 'pressure_met', 'pco2_air_noaa_2018', 'pco2_sst'],\n",
    "    latProd='Lat',lonProd='Lon',dateIndex=3,parseUnits=False,temporalChunking=1857,limits=[50,51,-6,-5],dateFormatDayFirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3456d7ae",
   "metadata": {},
   "source": [
    "We now have our NetCDF (version 3) file and we can now use the FluxEngine to calculate the air-sea gas fluxes. \n",
    "\n",
    "Note: We have had to suppress the output of the code section below due to a recent problem in Jupyter Notebook. Look for the [*] to the left of the block to know its still running, and a number in brackets when it's complete.\n",
    "\n",
    "This section can take up to ~15 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca79ea99-2765-498f-86a2-b11126a627ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# Line above suppressing the console output that causes issues for Jupyter Notebook currently, which we will save to a file later\n",
    "# Running FluxEngine - we first import FluxEngine run tool then run the \"Fal_mooring.conf\" config file\n",
    "\n",
    "from fluxengine.core import fe_setup_tools as fe_run\n",
    "fe_run.run_fluxengine(\"Fal_mooring.conf\", \"2018-09-14 00:00\", \"2018-11-30 08:00\", singleRun = False, processLayersOff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d98733-a1b3-4733-abb5-9c709ad740c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the console output, that we suppressed to a file\n",
    "with open('fluxengine_log.txt', 'w') as file:\n",
    "    file.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2237b09",
   "metadata": {},
   "source": [
    "The [*] to the left of the code block changing to a [number] indicates FluxEnigne has run and we now have the air-sea gas fluxes calculated from the Fal mooring data. The output is currently in a NetCDF file. You can view this using Panoply which is data viewer developed and provided for free by NASA. Alternatively we can extract the data from the NetCDF file and store it back into our original .tsv file as additional columns of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81625c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Appending FluxEngine results\n",
    "\n",
    "region_data = pd.read_csv('Fal_mooring_flux.tsv', sep='\\t', index_col=0)\n",
    "region_data =region_data.drop([0])\n",
    "\n",
    "vars = ['OF','OK3','OSFC','OIC1']\n",
    "c = Dataset('FalEstuary_output.nc','r')\n",
    "for v in vars:\n",
    "    a = np.squeeze(np.array(c[v])) # Load the data and remove the extra dataset dimensions (i.e lon=1, lat=1, time=1857 - np.squeeze removes the lon/lat dimensions)\n",
    "    a[a ==c[v]._FillValue] = np.nan # Remove data that is the fill value\n",
    "    region_data[v+' ['+c[v].units+']'] = a #Append back to the table, with the units (as is done in append2insitu\n",
    "c.close()\n",
    "region_data.to_csv('flux_final.tsv',sep='\\t') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791577bb",
   "metadata": {},
   "source": [
    "We can easily view and plot the air-sea CO 2  gas flux results using some simple python plotting routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96221dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load merged data\n",
    "merged_data = pd.read_csv('flux_final.tsv', sep='\\t',index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cdc099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View top of merged data\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820d142",
   "metadata": {},
   "source": [
    "We need to add out 'Days_since' to this new merged dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16263b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise the new Dataframe column and fill with a hold value\n",
    "merged_data['Days_since'] = 'hold value'\n",
    "\n",
    "# Produce a datetime object for the first recording \n",
    "# - the zeros in the line below show it's the first row (index starts at zero)\n",
    "start_date = dt.datetime(merged_data.loc[0,'Year'],merged_data.loc[0,'Month'],merged_data.loc[0,'Day'],\n",
    "                            merged_data.loc[0,'Hour'],merged_data.loc[0,'Minute'],merged_data.loc[0,'Second'])\n",
    "\n",
    "# Loop over all rows in the Dataframe - i.e from 0 to the length of the Dataframe\n",
    "for i in range(0,len(merged_data)):\n",
    "    # Get the date time object for the currently indexed recording - indexed by i\n",
    "    future_date = dt.datetime(merged_data.loc[i,'Year'],merged_data.loc[i,'Month'],merged_data.loc[i,'Day'],\n",
    "                              merged_data.loc[i,'Hour'],merged_data.loc[i,'Minute'],merged_data.loc[i,'Second'])\n",
    "    \n",
    "    # Find difference between current datetime and inital datetime\n",
    "    day_diff = future_date - start_date\n",
    "    \n",
    "    # Fill Dataframe column with time difference in seconds (found using .total_seconds()) \n",
    "    # divided by 86400 (proportion of days that have passed)\n",
    "    merged_data.loc[i,'Days_since'] = day_diff.total_seconds()/(60*60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92801b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show section of 'Days_since' column for visual check\n",
    "merged_data[['Datetime', 'Days_since']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59263f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(merged_data.iloc[570])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918720d",
   "metadata": {},
   "source": [
    "### Plot the Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1b31c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up a figure with 1 axes\n",
    "fig, ax = plt.subplots(1, 1, sharex=True, figsize=(20, 10))\n",
    "\n",
    "# Plot data on the ax object\n",
    "sns.lineplot(data=merged_data, x='Date', y='OF [g C m-2 day-1]', hue=merged_data[\"OF [g C m-2 day-1]\"].isna().cumsum(), palette=[\"blue\"]*sum(merged_data[\"OF [g C m-2 day-1]\"].isna()), legend=False, markers=True, ax=ax)\n",
    "\n",
    "# Set plot features \n",
    "plt.xlabel(f'Days since {merged_data.loc[0,\"Datetime\"]}', fontdict={'size':20})\n",
    "plt.ylabel('Flux [g C m-2 day-1]', fontdict={'size':20})\n",
    "plt.tick_params(labelsize=15)\n",
    "\n",
    "# Use WeekdayLocator and DateFormatter to show only weekly dates on x-axis\n",
    "date_fmt = mdates.DateFormatter('%d-%m-%Y')\n",
    "week_locator = mdates.WeekdayLocator(byweekday=mdates.MO)\n",
    "ax.xaxis.set_major_locator(week_locator)\n",
    "ax.xaxis.set_major_formatter(date_fmt)\n",
    "\n",
    "# Set x-axis tick labels\n",
    "tick_locs = ax.get_xticks() # Get the current tick locations\n",
    "ax.set_xticks(tick_locs) # Set the same tick locations\n",
    "ax.set_xticklabels(merged_data['Date'][::len(merged_data['Date'])//len(tick_locs)][:-1], rotation='vertical')\n",
    "\n",
    "# Set x axis label\n",
    "ax.set_xlabel('Date', fontsize=20) \n",
    "\n",
    "# Show figure!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2702d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Set up a figure with 7 axes on it.\n",
    "fig, ax = plt.subplots(7, 1, sharex=True, figsize=(15, 25))\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Plotting data for the first 6 subplots\n",
    "sns.lineplot(data=region_data, x='Date', y='salinity', color='turquoise', ax=ax[0])\n",
    "sns.lineplot(data=region_data, x='Date', y='sstskin_k', color='red', ax=ax[1])\n",
    "sns.lineplot(data=region_data, x='Date', y='windu10', color='green', ax=ax[2])\n",
    "sns.lineplot(data=region_data, x='Date', y='pco2sw_corr_split', color='orange', ax=ax[3], hue=region_data[\"pco2sw_corr_split\"].isna().cumsum(), palette=[\"blue\"]*sum(region_data[\"pco2sw_corr_split\"].isna()), legend=False, markers=True)\n",
    "sns.lineplot(data=region_data, x='Date', y='pressure_met', color='purple', ax=ax[4])\n",
    "sns.lineplot(data=region_data, x='Date', y='pco2_air_noaa_2018', color='black', ax=ax[5])\n",
    "\n",
    "# Use WeekdayLocator and DateFormatter to show only weekly dates on x-axis\n",
    "date_fmt = mdates.DateFormatter('%d-%m-%Y')\n",
    "week_locator = mdates.WeekdayLocator(byweekday=mdates.MO)\n",
    "for i in range(6):\n",
    "    ax[i].xaxis.set_major_locator(week_locator)\n",
    "    ax[i].xaxis.set_major_formatter(date_fmt)\n",
    "\n",
    "    # Set x-axis tick labels\n",
    "    tick_locs = ax[i].get_xticks()  # Get the current tick locations\n",
    "    ax[i].set_xticks(tick_locs)  # Set the same tick locations\n",
    "    ax[i].set_xticklabels(region_data['Date'][::len(region_data['Date'])//len(tick_locs)][:-1], rotation='vertical')\n",
    "\n",
    "    # Set x axis label\n",
    "    ax[i].set_xlabel('Date', fontsize=15) \n",
    "\n",
    "# Set y labels for each subplot\n",
    "for i, ylabel in enumerate(['Salinity', 'SST (K)', 'Windspeed (m/s)', 'Est.pCO2 (Âµ atm)', 'Atm.Pressure (mbar)', 'Atm.pCO2 (ppm)']):\n",
    "    ax[i].set_ylabel(ylabel, fontsize=15)\n",
    "\n",
    "# Changes how axis ticks are displayed for the last two axes\n",
    "for i in range(5, 7):\n",
    "    ax[i].yaxis.set_major_formatter('{x:9<5.2f}')\n",
    "\n",
    "# Set a tight layout to remove extra space around the plots\n",
    "fig.tight_layout()\n",
    "# Reduce gap between top of figure and the title\n",
    "fig.subplots_adjust(top=0.95)\n",
    "\n",
    "# Create a new subplot for the air-sea gas flux\n",
    "ax_flux = plt.subplot2grid((7, 1), (6, 0))\n",
    "# Plot data on the ax_flux object\n",
    "sns.lineplot(data=merged_data, x='Date', y='OF [g C m-2 day-1]', hue=merged_data[\"OF [g C m-2 day-1]\"].isna().cumsum(), palette=[\"blue\"]*sum(merged_data[\"OF [g C m-2 day-1]\"].isna()), legend=False, markers=True, ax=ax_flux)\n",
    "\n",
    "# Set plot features \n",
    "ax_flux.set_xlabel('Date', fontsize=15)\n",
    "ax_flux.set_ylabel('Flux [g C m-2 day-1]', fontsize=15)\n",
    "\n",
    "# Use WeekdayLocator and DateFormatter to show only weekly dates on x-axis\n",
    "ax_flux.xaxis.set_major_locator(week_locator)\n",
    "ax_flux.xaxis.set_major_formatter(date_fmt)\n",
    "\n",
    "# Set x-axis tick labels\n",
    "tick_locs_flux = ax_flux.get_xticks()  # Get the current tick locations\n",
    "ax_flux.set_xticks(tick_locs_flux)  # Set the same tick locations\n",
    "ax_flux.set_xticklabels(merged_data['Date'][::len(merged_data['Date'])//len(tick_locs_flux)][:-1], rotation='vertical')\n",
    "\n",
    "# Show the combined figure!\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2398f-81a4-4435-8b88-f9dfe3bf6734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
