{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebook with a collection of all functions for processing STILT results\n",
    "\n",
    "### Import this notebook with \n",
    "### %run '~/ICOSstations/STILT_modules_v1.3.ipynb'\n",
    "\n",
    "#### The notebook contains modules to \n",
    "- import all required tools and libraries\n",
    "\n",
    "- get list of ICOS class 1 and class 2 stations from Carbon Portal\n",
    "    - `get_station_class()`\n",
    "\n",
    "\n",
    "- store and update STILT station information in a dictionary \n",
    "    - `create_STILT_dictionary()`\n",
    "\n",
    "\n",
    "- read STILT station information\n",
    "    - `read_STILT_dictionary()`\n",
    "    \n",
    "    \n",
    "- list available footprints and store them in a dictionary\n",
    "    - `available_STILT_dictionary()`\n",
    "\n",
    "\n",
    "- plot table with availability of STILT results\n",
    "    - `plot_available_STILT()`\n",
    "    \n",
    "    \n",
    "- read slot-specific csv files from stiltweb (new directory structure)\n",
    "    - `read_stilt_timeseries(station,date_range)`\n",
    "    \n",
    "    \n",
    "- read and aggregate footprints in netcdf format (new directory structure) \n",
    "    - `read_aggreg_footprints(date_range, timeselect='all')`\n",
    "\n",
    "\n",
    "- read annual anthropogenic emissions EDBARv4.3_BP2015 \n",
    "    - `read_emissions(filename)` \n",
    "    \n",
    "    \n",
    "- plot maps (emissions or footprints)\n",
    "    - `plot_maps(field, lon, lat, title='', label='', unit='', linlog='linear', station=[''], zoom='', vmin=None, vmax=None, pngfile='')`\n",
    "\n",
    "\n",
    "- plot time series (example only - needs to be adjusted)\n",
    "    - `plot_stilt_timeseries(station,df,obs=None,meteo=None,title2='',linestyle = '.',pngfile='')`\n",
    "    \n",
    "    \n",
    "- convert station longitude and latitude (slat, slon) to indices of STILT model grid (ix,jy)\n",
    "    - `def lonlat_2_ixjy(slon,slat,mlon,mlat)`\n",
    "    \n",
    "    \n",
    "\n",
    "#### Outdated modules to\n",
    "- read yearly csv files (old directory structure)\n",
    "\n",
    "- read footprints in netcdf format (old directory structure)\n",
    "\n",
    "- add old STILT id to stations directory\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tools and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import required libraries\n",
    "#%pylab inline\n",
    "import netCDF4 as cdf\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import fnmatch\n",
    "import requests\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as p\n",
    "import matplotlib.colors as mcolors\n",
    "from cartopy import config\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import NaturalEarthFeature, LAND, COASTLINE\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "#UPDATE\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from IPython.core.display import display, HTML \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# define colors\n",
    "orange='#ff8c00'\n",
    "lime='#00ff00'\n",
    "aqua='#00ffff'\n",
    "brown='#663300'\n",
    "lightgray=\"#C0C0C0\"\n",
    "gray=\"#808080\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of ICOS class 1 and class 2 stations from Carbon Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_class():\n",
    "    # Query the ICOS SPARQL endpoint for a station list\n",
    "    # query stationId, class, lng name and country\n",
    "    # output is an object \"data\" containing the results in JSON\n",
    "\n",
    "    url = 'https://meta.icos-cp.eu/sparql'\n",
    "\n",
    "    query = \"\"\"\n",
    "    prefix st: <http://meta.icos-cp.eu/ontologies/stationentry/>\n",
    "    select distinct ?stationId ?stationClass ?country ?longName\n",
    "    from <http://meta.icos-cp.eu/resources/stationentry/>\n",
    "    where{\n",
    "      ?s a st:AS .\n",
    "      ?s st:hasShortName ?stationId .\n",
    "      ?s st:hasStationClass ?stationClass .\n",
    "      ?s st:hasCountry ?country .\n",
    "      ?s st:hasLongName ?longName .\n",
    "      filter (?stationClass = \"1\" || ?stationClass = \"2\")\n",
    "    }\n",
    "    ORDER BY ?stationClass ?stationId \n",
    "    \"\"\"\n",
    "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "    data = r.json()\n",
    "\n",
    "    # convert the the result into a table\n",
    "    # output is an array, where each row contains \n",
    "    # information about the station\n",
    "\n",
    "    cols = data['head']['vars']\n",
    "    datatable = []\n",
    "\n",
    "    for row in data['results']['bindings']:\n",
    "        item = []\n",
    "        for c in cols:\n",
    "            item.append(row.get(c, {}).get('value'))\n",
    "        \n",
    "        datatable.append(item)\n",
    "\n",
    "    # print the table \n",
    "    df_datatable = pd.DataFrame(datatable, columns=cols)\n",
    "    #df_datatable.head(5)\n",
    "    return df_datatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all STILT station information in a dictionary\n",
    "Dictionary contains information on\n",
    "- STILT station id\n",
    "- Station coordinates (latitude, longitude)\n",
    "- Altitude of tracer release in STILT simultation\n",
    "- STILT location identifier\n",
    "- Station name - if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_STILT_dictionary():\n",
    "    # store all STILT station information in a dictionary \n",
    "\n",
    "    # get all ICOS station IDs by listing subdirectories in stiltweb\n",
    "    # extract location from filename of link\n",
    "    \n",
    "    #UPDATE\n",
    "    pathStations='/data/stiltweb/stations/'\n",
    "    #pathStations='/opt/stiltdata/fsicos2/stiltweb/stations/'\n",
    "    allStations = os.listdir(pathStations)\n",
    "\n",
    "    # empty dictionary\n",
    "    stations = {}\n",
    "\n",
    "    # fill dictionary with ICOS station id, latitude, longitude and altitude\n",
    "    for ist in sorted(list(set(allStations))):\n",
    "        stations[ist] = {}\n",
    "        # get filename of link (original stiltweb directory structure) \n",
    "        # and extract location information\n",
    "        if os.path.exists(pathStations+ist):\n",
    "            loc_ident = os.readlink(pathStations+ist)\n",
    "            clon = loc_ident[-13:-6]\n",
    "            lon = np.float(clon[:-1])\n",
    "            if clon[-1:] == 'W':\n",
    "                lon = -lon\n",
    "            clat = loc_ident[-20:-14]\n",
    "            lat = np.float(clat[:-1])\n",
    "            if clat[-1:] == 'S':\n",
    "                lat = -lat\n",
    "            alt = np.int(loc_ident[-5:])\n",
    "\n",
    "            stations[ist]['lat']=lat\n",
    "            stations[ist]['lon']=lon\n",
    "            stations[ist]['alt']=alt\n",
    "            stations[ist]['locIdent']=os.path.split(loc_ident)[-1]\n",
    "\n",
    "        \n",
    "    # add information on station name (and new STILT station id) from stations.csv file used in stiltweb \n",
    "\n",
    "    url=\"https://stilt.icos-cp.eu/viewer/stationinfo\"\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "    for ist in sorted(list(set(stations))):\n",
    "        stationName = df.loc[df['STILT id'] == ist]['STILT name']\n",
    "        if len(stationName.value_counts()) > 0:\n",
    "            stations[ist]['name'] = stationName.item()\n",
    "        else:\n",
    "            stations[ist]['name'] = ''\n",
    "\n",
    "    # Get list of ICOS class 1 and class 2 stations from Carbon Portal\n",
    "    df_datatable = get_station_class()\n",
    "\n",
    "    # add information if ICOS class 1 or class 2 site\n",
    "    for ist in sorted(list(set(stations))):\n",
    "        stations[ist]['stationClass'] = np.nan\n",
    "        for istICOS in df_datatable['stationId']:\n",
    "            ic = int(df_datatable[df_datatable['stationId']==istICOS].index.values)\n",
    "            if istICOS in ist:\n",
    "                stations[ist]['stationClass'] = df_datatable['stationClass'][ic]\n",
    "\n",
    "    # print dictionary\n",
    "    #for ist in sorted(stations):\n",
    "    #    print ('station:', ist)\n",
    "    #    for k in stations[ist]:\n",
    "    #        print (k,':', stations[ist][k])\n",
    "\n",
    "    # write dictionary to pickle file for further use\n",
    "    pickle.dump( stations, open( \"stationsDict.pickle\", \"wb\" ) )\n",
    "\n",
    "    return stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dictionary with all stations\n",
    "Dictionary contains information on\n",
    "- STILT station id\n",
    "- Station coordinates (latitude, longitude)\n",
    "- Altitude of tracer release in STILT simultation\n",
    "- STILT location identifier\n",
    "- Station name - if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_STILT_dictionary():\n",
    "    # read STILT station dictionary from pickle file\n",
    "\n",
    "    filename = 'stationsDict.pickle'\n",
    "    stations = pd.read_pickle(filename)\n",
    "\n",
    "    # print dictionary\n",
    "    for ist in sorted(stations):\n",
    "        print ('station:', ist)\n",
    "        for k in stations[ist]:\n",
    "            print (k,':', stations[ist][k])\n",
    "\n",
    "    return stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available footprints and store them in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_STILT_dictionary():\n",
    "    # store availability of STILT footprints in a dictionary \n",
    "\n",
    "    # get all ICOS station IDs by listing subdirectories in stiltweb\n",
    "    # extract availability from directory structure\n",
    "    \n",
    "    #new:\n",
    "    pathStations='/data/stiltweb/stations/'\n",
    "    #pathStations='/opt/stiltdata/fsicos2/stiltweb/stations/'\n",
    "    allStations = os.listdir(pathStations)\n",
    "\n",
    "    # empty dictionary\n",
    "    available = {}\n",
    "\n",
    "    # fill dictionary with station name, years and months for each year\n",
    "    for ist in sorted(list(set(allStations))):\n",
    "        if os.path.exists(pathStations+'/'+ist):\n",
    "            #print ('directory '+pathStations+'/'+ist+' exits')\n",
    "            available[ist] = {}\n",
    "            years = os.listdir(pathStations+'/'+ist)\n",
    "            available[ist]['years'] = years\n",
    "            for yy in sorted(available[ist]['years']):\n",
    "                available[ist][yy] = {}\n",
    "                months = os.listdir(pathStations+'/'+ist+'/'+yy)\n",
    "                available[ist][yy]['months'] = months\n",
    "                available[ist][yy]['nmonths'] = len(available[ist][yy]['months'])\n",
    "        #else:\n",
    "        #    print ('directory '+pathStations+'/'+ist+' does not exit')\n",
    "\n",
    "    # Get list of ICOS class 1 and class 2 stations from Carbon Portal\n",
    "    df_datatable = get_station_class()\n",
    "\n",
    "    # add information if ICOS class 1 or class 2 site\n",
    "    for ist in sorted(available):\n",
    "        available[ist]['stationClass'] = np.nan\n",
    "        for istICOS in df_datatable['stationId']:\n",
    "            ic = int(df_datatable[df_datatable['stationId']==istICOS].index.values)\n",
    "            if istICOS in ist:\n",
    "                available[ist]['stationClass'] = df_datatable['stationClass'][ic]\n",
    "\n",
    "    # print availability\n",
    "    #for ist in sorted(available):\n",
    "    #    print ('station:', ist)\n",
    "    #    for k in available[ist]:\n",
    "    #        print (k,':', available[ist][k])\n",
    "    return available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot STILT footprint availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_available_STILT(pngfile=''):\n",
    "    \n",
    "    print ('run available_STILT_dictionary()')\n",
    "    available = available_STILT_dictionary()\n",
    "    \n",
    "    # Plot availability\n",
    "    # Each dot in the figure below represents one year. \n",
    "    # The size of the dot is proportional to the number of months per year for which footprints are available. \n",
    "\n",
    "    startyear = 2006\n",
    "    endyear = 2018\n",
    "\n",
    "    ny = endyear - startyear + 1\n",
    "    yy = np.arange(ny) + startyear\n",
    "    nm = np.zeros(ny)\n",
    "    dy = 0.5\n",
    "\n",
    "    fig = p.figure(figsize=(15, 32))\n",
    "    for i, ist in enumerate(sorted(available, reverse=True)) :\n",
    "        # available number of months per available year\n",
    "        nm = [available[ist][str(yy[j])]['nmonths'] if str(yy[j]) in available[ist].keys() else 0 for j in np.arange(ny)]\n",
    "        if available[ist]['stationClass'] == '1':\n",
    "            x = p.scatter(yy, np.ones(np.size(yy))*i+dy,c='r',marker='D', s=30*np.sqrt(np.asarray(nm)))\n",
    "            p.text(startyear-2+0.2, i+dy/2, ist, color='r', fontsize=14)         \n",
    "        elif available[ist]['stationClass'] == '2':\n",
    "            x = p.scatter(yy, np.ones(np.size(yy))*i+dy,c='b', marker='^', s=40*np.sqrt(np.asarray(nm)))\n",
    "            p.text(startyear-2+0.2, i+dy/2, ist, color='b', fontsize=14)\n",
    "        else:\n",
    "            x = p.scatter(yy, np.ones(np.size(yy))*i+dy,c='k',s=40*np.sqrt(np.asarray(nm)))\n",
    "            p.text(startyear-2+0.2, i+dy/2, ist, fontsize=14)         \n",
    "        \n",
    "    p.xticks(np.arange(startyear-2, np.max(yy)+2, 1.0))\n",
    "    p.xlim(startyear-2, np.max(yy)+1)\n",
    "    p.yticks(np.arange(0, len(available), 1.0), ())\n",
    "    p.ylim(0, len(available))\n",
    "    p.grid(axis='y')\n",
    "    p.tick_params(labeltop=True,labelsize=14)\n",
    "    p.title('Available STILT footprints (size proportional to number of months per year)\\n\\n\\n', fontsize=18)\n",
    "    p.figtext(0.4, 0.9, 'ICOS class 1 stations in red', color='r', fontsize=16, ha ='right')\n",
    "    p.figtext(0.6, 0.9, 'ICOS class 2 stations in blue', color='b', fontsize=16, ha ='left')\n",
    "    p.show()\n",
    "    p.close()\n",
    "    if len(pngfile)>0:\n",
    "        plotdir='plots'\n",
    "        if not os.path.exists(plotdir):\n",
    "            os.mkdir(plotdir)\n",
    "        fig.savefig(plotdir+'/'+pngfile+'_'+dt.datetime.now().strftime('%Y%m%d')+'.png',dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert station longitude and latitude to STILT grid indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert station longitude and latitude (slat, slon) to indices of STILT model grid (ix,jy)\n",
    "def lonlat_2_ixjy(slon,slat,mlon,mlat):\n",
    "    #slon, slat: longitude and latitude of station\n",
    "    #mlon, mlat: 1-dim. longitude and latitude of model grid\n",
    "    ix = (np.abs(mlon-slon)).argmin()\n",
    "    jy = (np.abs(mlat-slat)).argmin()\n",
    "    return ix,jy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read annual mean EDGAR emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to read annual mean EDGAR emissions\n",
    "def read_emissions(filename):\n",
    "    \n",
    "    # read annual mean anthropogenic emissions\n",
    "    # latitude and longitude are for lower left corner od grid cell\n",
    "\n",
    "    path_edgar = '/opt/stiltdata/RINGO/Emissions/'\n",
    "    #filename='EDGARv4.3_BP2015.timemean.co2.nc'\n",
    "    f = cdf.Dataset(path_edgar+filename)\n",
    "    #print (f)\n",
    "    emis=f.variables['emission'][:,:,:] # name not correct, these are total CO2 emissions\n",
    "    lon_ll=f.variables['lon'][:]\n",
    "    lat_ll=f.variables['lat'][:]\n",
    "    time=f.variables['time'][:]\n",
    "    dlon=np.abs(lon_ll[2]-lon_ll[1])\n",
    "    dlat=np.abs(lat_ll[2]-lat_ll[1])\n",
    "    emis_lon=lon_ll+0.5*dlon\n",
    "    emis_lat=lat_ll+0.5*dlat\n",
    "\n",
    "    #print (np.shape(emis))  \n",
    "\n",
    "    return emis, emis_lon, emis_lat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot maps (emissions or footprints) --- outdated basemap version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot maps (show station location if station is provided and zoom in second plot if zoom is provided)\n",
    "def plot_maps_basemap(field, lon, lat, title='', label='', unit='', linlog='linear', station=[''], zoom='', \n",
    "              vmin=None, vmax=None, colors='GnBu',pngfile=''):\n",
    "    \"\"\"Plot maps (emissions or footprints)\n",
    "    show station location if station is provided and zoom in second plot if zoom is provided\n",
    "    \"\"\"    \n",
    "\n",
    "    #https://matplotlib.org/users/colormapnorms.html#custom-normalization-two-linear-ranges\n",
    "    #http://chris35wills.github.io/matplotlib_diverging_colorbar/\n",
    "    class MidpointNormalize(mcolors.Normalize):\n",
    "        def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "            self.midpoint = midpoint\n",
    "            mcolors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "        def __call__(self, value, clip=None):\n",
    "            # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "            # simple example...\n",
    "            x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "            return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "    #print (np.shape(field))\n",
    "    \n",
    "    if np.shape(field)[0] > 1:\n",
    "        print ('More than one field: ',np.shape(field)[0],' Only the first will be plotted!!!')\n",
    "        \n",
    "    fig = p.figure(figsize=(15,8))\n",
    "\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    m = Basemap(projection='cyl', llcrnrlat=lat.min(), urcrnrlat=lat.max(), \n",
    "                llcrnrlon=lon.min(), urcrnrlon=lon.max(), resolution='l',)\n",
    "    m.drawcoastlines(linewidth=0.3)\n",
    "    m.drawmapboundary(fill_color='none',linewidth=0.3)\n",
    "    m.drawcountries(linewidth=0.3)\n",
    "    \n",
    "    #cmap = p.get_cmap('Blues')\n",
    "    #cmap = p.get_cmap('GnBu')\n",
    "    cmap = p.get_cmap(colors)\n",
    "    if linlog == 'linear':\n",
    "        im = m.imshow(field[0,:,:],interpolation='none',origin='lower',vmin=vmin,vmax=vmax,cmap=cmap)#,norm=MidpointNormalize(midpoint=0.,vmin=vmin,vmax=vmax))\n",
    "        cbar=m.colorbar(im,location='bottom',pad='5%')\n",
    "        cbar.set_label(label+'  '+unit)\n",
    "    else:\n",
    "        im = m.imshow(np.log10(field)[0,:,:],interpolation='none',origin='lower',vmin=vmin,vmax=vmax,cmap=cmap)\n",
    "        cbar=m.colorbar(im,location='bottom',pad='5%')\n",
    "        cbar.set_label(label+'  log$_{10}$ '+unit)\n",
    "    p.title(title)\n",
    "    ax.text(0.01, -0.25, 'min: %.5f' % np.min(field[0,:,:]), horizontalalignment='left',transform=ax.transAxes)\n",
    "    ax.text(0.99, -0.25, 'max: %.5f' % np.max(field[0,:,:]), horizontalalignment='right',transform=ax.transAxes)\n",
    "    \n",
    "    if station[0] != '':\n",
    "        for ist in station:\n",
    "            #show station location if station is provided\n",
    "            m.plot(stations[ist]['lon'],stations[ist]['lat'],'m+',ms=8)\n",
    "\n",
    "    #zoom   \n",
    "    if zoom != '':\n",
    "        #grid cell index of station \n",
    "        ix,jy = lonlat_2_ixjy(stations[zoom]['lon'],stations[zoom]['lat'],lon,lat)\n",
    "        #print (stations[zoom]['lon'],stations[zoom]['lat'],ix,jy)\n",
    "\n",
    "        # define zoom area \n",
    "        i1 = np.max([ix-35,0])\n",
    "        i2 = np.min([ix+35,400])\n",
    "        j1 = np.max([jy-42,0])\n",
    "        j2 = np.min([jy+42,480])\n",
    "\n",
    "        #print (i1,i2,j1,j2)\n",
    "\n",
    "        ax = fig.add_subplot(1,2,2)\n",
    "        m = Basemap(projection='cyl', llcrnrlat=lat[j1:j2].min(), urcrnrlat=lat[j1:j2].max(),\n",
    "                    llcrnrlon=lon[i1:i2].min(), urcrnrlon=lon[i1:i2].max(), resolution='i',)\n",
    "        m.drawcoastlines(linewidth=0.3)\n",
    "        m.drawmapboundary(fill_color='none',linewidth=0.3)\n",
    "        m.drawcountries(linewidth=0.3)\n",
    "    \n",
    "        if linlog == 'linear':\n",
    "            im = m.imshow(field[0,j1:j2,i1:i2],interpolation='none',origin='lower',vmin=vmin,vmax=vmax,cmap=cmap)\n",
    "            cbar=m.colorbar(im,location='bottom',pad='5%')\n",
    "            cbar.set_label(label+'  '+unit)\n",
    "        else:\n",
    "            im = m.imshow(np.log10(field)[0,j1:j2,i1:i2],interpolation='none',origin='lower',vmin=vmin,vmax=vmax,cmap=cmap)\n",
    "            cbar=m.colorbar(im,location='bottom',pad='5%')\n",
    "            cbar.set_label(label+'  log$_{10}$ '+unit)\n",
    "        for ist in list(set([zoom] + station)):\n",
    "            m.plot(stations[ist]['lon'],stations[ist]['lat'],'m+',ms=8)\n",
    "        p.title(title)\n",
    "        ax.text(0.01, -0.25, 'min: %.5f' % np.min(field[0,j1:j2,i1:i2]), horizontalalignment='left',transform=ax.transAxes)\n",
    "        ax.text(0.99, -0.25, 'max: %.5f' % np.max(field[0,j1:j2,i1:i2]), horizontalalignment='right',transform=ax.transAxes)\n",
    "    #p.tight_layout()\n",
    "    p.show()\n",
    "    if len(pngfile)>0:\n",
    "        plotdir='plots'\n",
    "        if not os.path.exists(plotdir):\n",
    "            os.mkdir(plotdir)\n",
    "        fig.savefig(plotdir+'/'+pngfile+'.png',dpi=100)\n",
    "    p.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to plot maps (show station location if station is provided and zoom in second plot if zoom is provided)\n",
    "def plot_maps(field, lon, lat, title='', label='', unit='', linlog='linear', station=[''], zoom='', \n",
    "              vmin=None, vmax=None, colors='GnBu',pngfile=''):\n",
    "    \"\"\"Plot maps (emissions or footprints)\n",
    "    show station location if station is provided and zoom in second plot if zoom is provided\n",
    "    \"\"\"    \n",
    "\n",
    "    mcolor='m'\n",
    "    \n",
    "    # Set scale for features from Natural Earth\n",
    "    #NEscale = '110m'\n",
    "    NEscale = '50m'\n",
    "    #NEscale = '10m'\n",
    "    \n",
    "    # Create a feature for Countries at 1:50m from Natural Earth\n",
    "    countries = cfeature.NaturalEarthFeature(\n",
    "        category='cultural',\n",
    "        name='admin_0_countries',\n",
    "        scale=NEscale,\n",
    "        facecolor='none')\n",
    "\n",
    "    #print (np.shape(field))\n",
    "    \n",
    "    if np.shape(field)[0] > 1:\n",
    "        print ('More than one field: ',np.shape(field)[0],' Only the first will be plotted!!!')\n",
    "        \n",
    "    fig = p.figure(figsize=(15,15))\n",
    "\n",
    "    # set up a map\n",
    "    ax = p.subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "    img_extent = (lon.min(), lon.max(), lat.min(), lat.max())\n",
    "    ax.set_extent([lon.min(), lon.max(), lat.min(), lat.max()],crs=ccrs.PlateCarree())\n",
    "    ax.add_feature(countries, edgecolor='black', linewidth=0.3)\n",
    "\n",
    "    cmap = p.get_cmap(colors)\n",
    "    if linlog == 'linear':\n",
    "        im = ax.imshow(field[0,:,:],interpolation='none',origin='lower', extent=img_extent,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        cbar=p.colorbar(im,orientation='horizontal',pad=0.03,fraction=0.055,extend='both')\n",
    "        cbar.set_label(label+'  '+unit)\n",
    "    else:\n",
    "        im = ax.imshow(np.log10(field)[0,:,:],interpolation='none',origin='lower', extent=img_extent,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        cbar=p.colorbar(im,orientation='horizontal',pad=0.03,fraction=0.055,extend='both')\n",
    "        cbar.set_label(label+'  log$_{10}$ '+unit)\n",
    "    p.title(title)\n",
    "    ax.text(0.01, -0.25, 'min: %.5f' % np.min(field[0,:,:]), horizontalalignment='left',transform=ax.transAxes)\n",
    "    ax.text(0.99, -0.25, 'max: %.5f' % np.max(field[0,:,:]), horizontalalignment='right',transform=ax.transAxes)\n",
    "    \n",
    "    #show station location if station is provided\n",
    "    if station[0] != '':\n",
    "        station_lon=[]\n",
    "        station_lat=[]\n",
    "        for ist in station:\n",
    "            station_lon.append(stations[ist]['lon'])\n",
    "            station_lat.append(stations[ist]['lat'])\n",
    "        ax.plot(station_lon,station_lat,'+',color=mcolor,ms=10,markeredgewidth=1,transform=ccrs.PlateCarree())\n",
    "\n",
    "    #zoom   \n",
    "    if zoom != '':\n",
    "        #grid cell index of station \n",
    "        ix,jy = lonlat_2_ixjy(stations[zoom]['lon'],stations[zoom]['lat'],lon,lat)\n",
    "        #print (stations[zoom]['lon'],stations[zoom]['lat'],ix,jy)\n",
    "\n",
    "        # define zoom area \n",
    "        i1 = np.max([ix-35,0])\n",
    "        i2 = np.min([ix+35,400])\n",
    "        j1 = np.max([jy-42,0])\n",
    "        j2 = np.min([jy+42,480])\n",
    "\n",
    "        lon_z=lon[i1:i2]\n",
    "        lat_z=lat[j1:j2]\n",
    "        field_z=field[0,j1:j2,i1:i2]\n",
    "\n",
    "        #print (i1,i2,j1,j2)\n",
    "\n",
    "        # set up a map\n",
    "        ax = p.subplot(1, 2, 2, projection=ccrs.PlateCarree())\n",
    "        img_extent = (lon_z.min(), lon_z.max(), lat_z.min(), lat_z.max())\n",
    "        ax.set_extent([lon_z.min(), lon_z.max(), lat_z.min(), lat_z.max()],crs=ccrs.PlateCarree())\n",
    "        ax.add_feature(countries, edgecolor='black', linewidth=0.3)\n",
    "    \n",
    "        if linlog == 'linear':\n",
    "            im = ax.imshow(field_z,interpolation='none',origin='lower', extent=img_extent,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "            cbar=p.colorbar(im,orientation='horizontal',pad=0.03,fraction=0.055,extend='both')\n",
    "            #im = m.imshow(field[0,j1:j2,i1:i2],interpolation='none',origin='lower',vmin=vmin,vmax=vmax,cmap=cmap)\n",
    "            #cbar=m.colorbar(im,location='bottom',pad='5%')\n",
    "            cbar.set_label(label+'  '+unit)\n",
    "        else:\n",
    "            im = ax.imshow(np.log10(field_z),interpolation='none',origin='lower', extent=img_extent,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "            cbar=p.colorbar(im,orientation='horizontal',pad=0.03,fraction=0.055,extend='both')\n",
    "            #im = m.imshow(np.log10(field)[0,j1:j2,i1:i2],interpolation='none',origin='lower',vmin=vmin,vmax=vmax,cmap=cmap)\n",
    "            #cbar=m.colorbar(im,location='bottom',pad='5%')\n",
    "            cbar.set_label(label+'  log$_{10}$ '+unit)\n",
    "\n",
    "        #show station location if station is provided\n",
    "        if station[0] != '':\n",
    "            station_lon=[]\n",
    "            station_lat=[]\n",
    "            for ist in list(set([zoom] + station)):\n",
    "                station_lon.append(stations[ist]['lon'])\n",
    "                station_lat.append(stations[ist]['lat'])\n",
    "            ax.plot(station_lon,station_lat,'+',color=mcolor,ms=10,markeredgewidth=1,transform=ccrs.PlateCarree())\n",
    "        p.title(title)\n",
    "        ax.text(0.01, -0.25, 'min: %.5f' % np.min(field[0,j1:j2,i1:i2]), horizontalalignment='left',transform=ax.transAxes)\n",
    "        ax.text(0.99, -0.25, 'max: %.5f' % np.max(field[0,j1:j2,i1:i2]), horizontalalignment='right',transform=ax.transAxes)\n",
    "    #p.tight_layout()\n",
    "    p.show()\n",
    "    if len(pngfile)>0:\n",
    "        plotdir='plots'\n",
    "        if not os.path.exists(plotdir):\n",
    "            os.mkdir(plotdir)\n",
    "        fig.savefig(plotdir+'/'+pngfile+'.png',dpi=100)\n",
    "    p.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and aggregate STILT footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read and aggregate footprints for given time range\n",
    "def read_aggreg_footprints(station, date_range, timeselect='all'):\n",
    "    \n",
    "    # loop over all dates and read netcdf files\n",
    "\n",
    "    # path to footprint files in new stiltweb directory structure\n",
    "    pathFP='/data/stiltweb/stations/'\n",
    "    \n",
    "\n",
    "    # print ('date range: ',date_range)\n",
    "    fp=[]\n",
    "    nfp=0\n",
    "    first = True\n",
    "    for date in date_range:\n",
    "        filename=(pathFP+station+'/'+str(date.year)+'/'+str(date.month).zfill(2)+'/'\n",
    "             +str(date.year)+'x'+str(date.month).zfill(2)+'x'+str(date.day).zfill(2)+'x'+str(date.hour).zfill(2)+'/foot')\n",
    "        #print (filename)\n",
    "        if os.path.isfile(filename):\n",
    "            f_fp = cdf.Dataset(filename)\n",
    "            if (first):\n",
    "                fp=f_fp.variables['foot'][:,:,:]\n",
    "                lon=f_fp.variables['lon'][:]\n",
    "                lat=f_fp.variables['lat'][:]\n",
    "                first = False\n",
    "            else:\n",
    "                fp=fp+f_fp.variables['foot'][:,:,:]\n",
    "            f_fp.close()\n",
    "            nfp+=1\n",
    "        #else:\n",
    "            #print ('file does not exist: ',filename)\n",
    "    if nfp > 0:\n",
    "        fp=fp/nfp\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print ('no footprints found')\n",
    "        \n",
    "\n",
    "    #print (np.shape(fp))\n",
    "    #print (np.max(fp))\n",
    "    title = 'not used'\n",
    "    #title = (start_date.strftime('%Y-%m-%d')+' - '+end_date.strftime('%Y-%m-%d')+'\\n'+\n",
    "     #        'time selection: '+timeselect)\n",
    "    \n",
    "    return nfp, fp, lon, lat, title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read STILT time series (new format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated --> take the timeselect list and returns the \"correct\" dataframe\n",
    "#otherwise - not correct hours!\n",
    "# function to read STILT concentration time series (new format of STILT results)\n",
    "def read_stilt_timeseries_upd(station,date_range,timeselect_list):\n",
    "    url = 'https://stilt.icos-cp.eu/viewer/stiltresult'\n",
    "    headers = {'Content-Type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "    # check if STILT results exist\n",
    "    pathFP='/data/stiltweb/stations/'\n",
    "    new_range=[]\n",
    "    \n",
    "    for date in date_range:\n",
    "        #--> new : pathStations='/data/stiltweb/stations/'\n",
    "        #pathStations='/opt/stiltdata/fsicos2/stiltweb/stations/'\n",
    "        if os.path.exists(pathFP+station+'/'+str(date.year)+'/'+str(date.month).zfill(2)+'/'\n",
    "             +str(date.year)+'x'+str(date.month).zfill(2)+'x'+str(date.day).zfill(2)+'x'+str(date.hour).zfill(2)+'/'):\n",
    "            new_range.append(date)\n",
    "        #if os.path.exists('/opt/stiltdata/fsicos2/stiltweb/slots/'+stations[station]['locIdent']+'/'+str(zDate.year)+'/'+str(zDate.month).zfill(2)+'/'\n",
    "         #           +str(zDate.year)+'x'+str(zDate.month).zfill(2)+'x'+str(zDate.day).zfill(2)+'x'+str(zDate.hour).zfill(2)+'/'):\n",
    "          #  \n",
    "        \n",
    "        \n",
    "        #filename=(pathFP+station+'/'+str(date.year)+'/'+str(date.month).zfill(2)+'/'\n",
    "         #    +str(date.year)+'x'+str(date.month).zfill(2)+'x'+str(date.day).zfill(2)+'x'+str(date.hour).zfill(2)+'/foot')\n",
    "        \n",
    "    if len(new_range) > 0:\n",
    "        date_range = new_range\n",
    "        fromDate = date_range[0].strftime('%Y-%m-%d')\n",
    "        toDate = date_range[-1].strftime('%Y-%m-%d')\n",
    "        columns = ('[\"isodate\",\"co2.stilt\",\"co2.fuel\",\"co2.bio\",\"co2.bio.gee\",\"co2.bio.resp\",\"co2.fuel.coal\",\"co2.fuel.oil\",'+\n",
    "                   '\"co2.fuel.gas\",\"co2.fuel.bio\",\"co2.energy\",\"co2.transport\", \"co2.industry\",'+\n",
    "                   '\"co2.others\", \"co2.cement\", \"co2.background\",'+\n",
    "                   '\"co.stilt\",\"co.fuel\",\"co.bio\",\"co.fuel.coal\",\"co.fuel.oil\",'+\n",
    "                   '\"co.fuel.gas\",\"co.fuel.bio\",\"co.energy\",\"co.transport\", \"co.industry\",'+\n",
    "                   '\"co.others\", \"co.cement\", \"co.background\",'+\n",
    "                   '\"rn\", \"rn.era\",\"rn.noah\",\"wind.dir\",\"wind.u\",\"wind.v\",\"latstart\",\"lonstart\"]')\n",
    "        data = '{\"columns\": '+columns+', \"fromDate\": \"'+fromDate+'\", \"toDate\": \"'+toDate+'\", \"stationId\": \"'+station+'\"}'\n",
    "        #print (data)\n",
    "        response = requests.post(url, headers=headers, data=data)\n",
    "        if response.status_code != 500:\n",
    "            #print (response.json())\n",
    "            output=np.asarray(response.json())\n",
    "            df = pd.DataFrame(output[:,:], columns=eval(columns))\n",
    "            df = df.replace('null',np.NaN)\n",
    "            df = df.astype(float)\n",
    "            df['date'] = pd.to_datetime(df['isodate'], unit='s')\n",
    "            df.set_index(['date'],inplace=True)\n",
    "            df['name'] = station\n",
    "            df['model'] = 'STILT'\n",
    "            df['wind.speed']=np.sqrt((df['wind.u']**2)+(df['wind.v']**2))\n",
    "            #print (df.columns)\n",
    "    else:\n",
    "        df=pd.DataFrame({'A' : []})\n",
    "        \n",
    "    df=df[(df['co2.fuel'].index.hour.isin(timeselect_list))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read STILT concentration time series (new format of STILT results)\n",
    "def read_stilt_timeseries(station,date_range):\n",
    "    url = 'https://stilt.icos-cp.eu/viewer/stiltresult'\n",
    "    headers = {'Content-Type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "    # check if STILT results exist\n",
    "    pathFP='/data/stiltweb/stations/'\n",
    "    new_range=[]\n",
    "    \n",
    "    for date in date_range:\n",
    "        #--> new : pathStations='/data/stiltweb/stations/'\n",
    "        #pathStations='/opt/stiltdata/fsicos2/stiltweb/stations/'\n",
    "        if os.path.exists(pathFP+station+'/'+str(date.year)+'/'+str(date.month).zfill(2)+'/'\n",
    "             +str(date.year)+'x'+str(date.month).zfill(2)+'x'+str(date.day).zfill(2)+'x'+str(date.hour).zfill(2)+'/'):\n",
    "            new_range.append(date)\n",
    "        #if os.path.exists('/opt/stiltdata/fsicos2/stiltweb/slots/'+stations[station]['locIdent']+'/'+str(zDate.year)+'/'+str(zDate.month).zfill(2)+'/'\n",
    "         #           +str(zDate.year)+'x'+str(zDate.month).zfill(2)+'x'+str(zDate.day).zfill(2)+'x'+str(zDate.hour).zfill(2)+'/'):\n",
    "          #  \n",
    "        \n",
    "        \n",
    "        #filename=(pathFP+station+'/'+str(date.year)+'/'+str(date.month).zfill(2)+'/'\n",
    "         #    +str(date.year)+'x'+str(date.month).zfill(2)+'x'+str(date.day).zfill(2)+'x'+str(date.hour).zfill(2)+'/foot')\n",
    "        \n",
    "    if len(new_range) > 0:\n",
    "        date_range = new_range\n",
    "        fromDate = date_range[0].strftime('%Y-%m-%d')\n",
    "        toDate = date_range[-1].strftime('%Y-%m-%d')\n",
    "        columns = ('[\"isodate\",\"co2.stilt\",\"co2.fuel\",\"co2.bio\",\"co2.bio.gee\",\"co2.bio.resp\",\"co2.fuel.coal\",\"co2.fuel.oil\",'+\n",
    "                   '\"co2.fuel.gas\",\"co2.fuel.bio\",\"co2.energy\",\"co2.transport\", \"co2.industry\",'+\n",
    "                   '\"co2.others\", \"co2.cement\", \"co2.background\",'+\n",
    "                   '\"co.stilt\",\"co.fuel\",\"co.bio\",\"co.fuel.coal\",\"co.fuel.oil\",'+\n",
    "                   '\"co.fuel.gas\",\"co.fuel.bio\",\"co.energy\",\"co.transport\", \"co.industry\",'+\n",
    "                   '\"co.others\", \"co.cement\", \"co.background\",'+\n",
    "                   '\"rn\", \"rn.era\",\"rn.noah\",\"wind.dir\",\"wind.u\",\"wind.v\",\"latstart\",\"lonstart\"]')\n",
    "        data = '{\"columns\": '+columns+', \"fromDate\": \"'+fromDate+'\", \"toDate\": \"'+toDate+'\", \"stationId\": \"'+station+'\"}'\n",
    "        #print (data)\n",
    "        response = requests.post(url, headers=headers, data=data)\n",
    "        if response.status_code != 500:\n",
    "            #print (response.json())\n",
    "            output=np.asarray(response.json())\n",
    "            df = pd.DataFrame(output[:,:], columns=eval(columns))\n",
    "            df = df.replace('null',np.NaN)\n",
    "            df = df.astype(float)\n",
    "            df['date'] = pd.to_datetime(df['isodate'], unit='s')\n",
    "            df.set_index(['date'],inplace=True)\n",
    "            df['name'] = station\n",
    "            df['model'] = 'STILT'\n",
    "            df['wind.speed']=np.sqrt((df['wind.u']**2)+(df['wind.v']**2))\n",
    "            #print (df.columns)\n",
    "    else:\n",
    "        df=pd.DataFrame({'A' : []})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read STILT time series with all components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read STILT concentration time series (new format of STILT results)\n",
    "def read_stilt_raw_timeseries(station,date_range):\n",
    "    url = 'https://stilt.icos-cp.eu/viewer/stiltrawresult'\n",
    "    headers = {'Content-Type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "    # check if STILT results exist\n",
    "    new_range=[]\n",
    "    for zDate in date_range:\n",
    "        if os.path.exists('/opt/stiltdata/fsicos2/stiltweb/slots/'+stations[station]['locIdent']+'/'+str(zDate.year)+'/'+str(zDate.month).zfill(2)+'/'\n",
    "                    +str(zDate.year)+'x'+str(zDate.month).zfill(2)+'x'+str(zDate.day).zfill(2)+'x'+str(zDate.hour).zfill(2)+'/'):\n",
    "            new_range.append(zDate)\n",
    "    if len(new_range) > 0:\n",
    "        date_range = new_range\n",
    "        fromDate = date_range[0].strftime('%Y-%m-%d')\n",
    "        toDate = date_range[-1].strftime('%Y-%m-%d')\n",
    "        columns = ('[\"isodate\",\"co2.1a1bcr.coal_hard\", \"co2.1a1bcr.coal_peat\", \"co2.1a1bcr.gas_der\"]')\n",
    "        data = '{\"columns\": '+columns+', \"fromDate\": \"'+fromDate+'\", \"toDate\": \"'+toDate+'\", \"stationId\": \"'+station+'\"}'\n",
    "        print(data)\n",
    "        response = requests.post(url, headers=headers, data=data)\n",
    "        if response.status_code != 500:\n",
    "            #print response.json()\n",
    "            output=np.asarray(response.json())\n",
    "            df = pd.DataFrame(output[:,:], columns=eval(columns))\n",
    "            df = df.replace('null',np.NaN)\n",
    "            df = df.astype(float)\n",
    "            df['date'] = pd.to_datetime(df['isodate'], unit='s')\n",
    "            df.set_index(['date'],inplace=True)\n",
    "            df['name'] = station\n",
    "            df['model'] = 'STILT'\n",
    "            #df['wind.speed']=np.sqrt((df['wind.u']**2)+(df['wind.v']**2))\n",
    "            #print df.columns\n",
    "    else:\n",
    "        df=pd.DataFrame({'A' : []})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot STILT time series (basic example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot STILT time series (new format of STILT results)\n",
    "def plot_stilt_timeseries(station,df,obs=None,meteo=None,title2='',linestyle = '.',pngfile='',add_tracer=[]):\n",
    "    #plot time series\n",
    "    tracer = add_tracer + ['co2']\n",
    "    tracer = [x.lower() for x in tracer]\n",
    "    fig = p.figure(figsize=(15,15.5))\n",
    "    ax = fig.add_subplot(6,1,1)\n",
    "    p.plot(df.index,df['co2.stilt'],linestyle,color='b',label='STILT co2.stilt')\n",
    "    p.plot(df.index,df['co2.background'],linestyle,color='c',label='STILT co2.background')\n",
    "    if obs is not None:\n",
    "        if 'DateTime' in obs:\n",
    "            p.plot(obs.DateTime,obs['CO2'],linestyle,color='k',label='observation')\n",
    "        else:\n",
    "            p.plot(obs.index,obs['co2'].astype(np.float32),linestyle,color='k',label='observation')\n",
    "    p.title(df.name[0]+'  '+str(df['latstart'][0])+'$^\\circ$N'+'  '+str(df['lonstart'][0])+'$^\\circ$E'+'    '+title2)\n",
    "    ax.set_xlim(start_date,end_date)\n",
    "    ax.set_ylabel('CO$_2$  [ppm]')\n",
    "    ax.grid(axis='x')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax = fig.add_subplot(6,1,2)\n",
    "    p.plot(df.index,df['co2.fuel'],linestyle,color='r',label=df.model[0]+' co2.fuel')\n",
    "    p.plot(df.index,df['co2.bio'],linestyle,color='g',label=df.model[0]+' co2.bio')\n",
    "    ax.set_xlim(start_date,end_date)\n",
    "    #ax.set_ylim(-50,200)\n",
    "    ax.set_ylabel('CO$_2$ components  [ppm]')\n",
    "    ax.grid(axis='x')\n",
    "    ax.legend(loc='upper right')\n",
    "    if ('co.stilt' in df) and ('co' in tracer):\n",
    "        ax = fig.add_subplot(6,1,3)\n",
    "        p.plot(df.index,df['co.stilt'],linestyle,color='m',label='STILT co.stilt')\n",
    "        if obs is not None and 'co' in obs:\n",
    "            p.plot(obs.index,obs['CO'],linestyle,color='k',label='observation')\n",
    "        p.title(df.name[0]+'  '+str(df['latstart'][0])+'$^\\circ$N'+'  '+str(df['lonstart'][0])+'$^\\circ$E'+'    '+title2)\n",
    "        ax.set_xlim(start_date,end_date)\n",
    "        ax.set_ylabel('CO  [ppb]')\n",
    "        ax.grid(axis='x')\n",
    "        ax.legend(loc='upper right')\n",
    "    if ('rn' in df) and ('rn' in tracer):\n",
    "        ax = fig.add_subplot(6,1,4)\n",
    "        p.plot(df.index,df['rn'],linestyle,color='y',label='STILT rn')\n",
    "        if obs is not None and 'rn' in obs:\n",
    "            p.plot(obs.index,obs['rn'],linestyle,color='k',label='observation')\n",
    "        p.title(df.name[0]+'  '+str(df['latstart'][0])+'$^\\circ$N'+'  '+str(df['lonstart'][0])+'$^\\circ$E'+'    '+title2)\n",
    "        ax.set_xlim(start_date,end_date)\n",
    "        ax.set_ylabel('222RN  [???]')\n",
    "        ax.grid(axis='x')\n",
    "        ax.legend(loc='upper right')\n",
    "    p.tight_layout()\n",
    "    p.show()\n",
    "    if len(pngfile)>0:\n",
    "        plotdir='plots'\n",
    "        if not os.path.exists(plotdir):\n",
    "            os.mkdir(plotdir)\n",
    "        fig.savefig(plotdir+'/'+pngfile+'.png',dpi=100)\n",
    "    p.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot STILT time series together with ICOS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot ICOS (or other measurement) data together with STILT time series (new format of STILT results)\n",
    "def plot_icos_stilt_timeseries(station,df,obs=None,meteo=None,title2='',linestyle='.',pngfile='',add_tracer=[]):\n",
    "    # call basic function plot_stilt_timeseries, which allows to add observation data frame \n",
    "    plot_stilt_timeseries(station,df,obs=obs,meteo=meteo,title2=title2,linestyle=linestyle,pngfile=pngfile,add_tracer=add_tracer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outdated modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read old STILT time series (in Results_1A4 directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read STILT time series\n",
    "def read_stilt_ts(station,locIdent,year):\n",
    "    filename='/opt/stiltdata/Results_1A4/'+station+'/stiltresult'+str(year)+'x'+locIdent+'.csv'\n",
    "    if os.path.isfile(filename):\n",
    "        #print (filename)\n",
    "        df= pd.read_csv(filename,delim_whitespace=True)\n",
    "        df.date = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
    "        df.name = station\n",
    "        df.model = 'oldSTILT'\n",
    "        #df['wind.speed']=np.sqrt((df['wind.u']**2)+(df['wind.v']**2))\n",
    "        #print (df.columns)\n",
    "        df.set_index(['date'],inplace=True)\n",
    "    else:\n",
    "        df=pd.DataFrame({'A' : []})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read very old STILT time series, emissionsector 1A4 missing (in Results directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read STILT time series\n",
    "def read_stilt_ts_old(station,locIdent,year):\n",
    "    filename='/opt/stiltdata/Results/'+station+'/stiltresults'+str(year)+'.csv'\n",
    "    if os.path.isfile(filename):\n",
    "        #print (filename)\n",
    "        df= pd.read_csv(filename,delim_whitespace=True)\n",
    "        df.date = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
    "        df.name = station\n",
    "        df.model = 'oldSTILT'\n",
    "        #df['wind.speed']=np.sqrt((df['wind.u']**2)+(df['wind.v']**2))\n",
    "        #print (df.columns)\n",
    "        df.set_index(['date'],inplace=True)\n",
    "    else:\n",
    "        df=pd.DataFrame({'A' : []})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_old_STILTid(stations):\n",
    "    \n",
    "    filename='stations_oldSTILTids_20181106.csv'\n",
    "    df= pd.read_csv(filename,delimiter=';')\n",
    "\n",
    "    for ist in sorted(list(set(stations))):\n",
    "    \n",
    "        oldId = df.loc[df['new STILT id'] == ist]['old STILT id']\n",
    "\n",
    "        if len(oldId.value_counts()) > 0:\n",
    "            stations[ist]['old id'] = oldId.item()\n",
    "        else:\n",
    "            stations[ist]['old id'] = ist\n",
    "\n",
    "    # print dictionary\n",
    "    for ist in sorted(stations):\n",
    "        print ('station:', ist)\n",
    "        for k in stations[ist]:\n",
    "            print (k,':', stations[ist][k])\n",
    "            \n",
    "    return stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all defined functions\n",
    "#func = %who_ls function\n",
    "#print (\"\\033[1m\" + \"Functions defined for handling STILT output:\" + \"\\033[0;0m\")\n",
    "#for ff in func:\n",
    "    #print (ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all loaded modules\n",
    "#modu = %who_ls module\n",
    "#print (\"\\033[1m\" + \"Modules loaded:\" + \"\\033[0;0m\")\n",
    "#for mm in modu:\n",
    " #   print (mm)\n",
    "#print (\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
